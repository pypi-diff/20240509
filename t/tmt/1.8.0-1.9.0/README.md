# Comparing `tmp/tmt-1.8.0-py3-none-any.whl.zip` & `tmp/tmt-1.9.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,42 +1,43 @@
-Zip file size: 128703 bytes, number of entries: 40
--rw-r--r--  2.0 unx      325 b- defN 21-Sep-30 14:24 tmt/__init__.py
--rw-r--r--  2.0 unx       31 b- defN 21-Sep-30 14:24 tmt/__main__.py
--rw-r--r--  2.0 unx    72381 b- defN 21-Sep-30 14:24 tmt/base.py
--rw-r--r--  2.0 unx    11753 b- defN 21-Sep-30 14:24 tmt/beakerlib.py
--rw-r--r--  2.0 unx    36709 b- defN 21-Sep-30 14:24 tmt/cli.py
--rw-r--r--  2.0 unx    29264 b- defN 21-Sep-30 14:24 tmt/convert.py
--rw-r--r--  2.0 unx    25782 b- defN 21-Sep-30 14:24 tmt/export.py
--rw-r--r--  2.0 unx     5608 b- defN 21-Sep-30 14:24 tmt/options.py
--rw-r--r--  2.0 unx     1540 b- defN 21-Sep-30 14:24 tmt/plugins.py
--rw-r--r--  2.0 unx     3091 b- defN 21-Sep-30 14:24 tmt/templates.py
--rw-r--r--  2.0 unx    57652 b- defN 21-Sep-30 14:24 tmt/utils.py
--rw-r--r--  2.0 unx    22080 b- defN 21-Sep-30 14:24 tmt/steps/__init__.py
--rw-r--r--  2.0 unx     7284 b- defN 21-Sep-30 14:24 tmt/steps/discover/__init__.py
--rw-r--r--  2.0 unx     9443 b- defN 21-Sep-30 14:24 tmt/steps/discover/fmf.py
--rw-r--r--  2.0 unx     3149 b- defN 21-Sep-30 14:24 tmt/steps/discover/shell.py
--rw-r--r--  2.0 unx    12581 b- defN 21-Sep-30 14:24 tmt/steps/execute/__init__.py
--rw-r--r--  2.0 unx     5717 b- defN 21-Sep-30 14:24 tmt/steps/execute/detach.py
--rw-r--r--  2.0 unx    12739 b- defN 21-Sep-30 14:24 tmt/steps/execute/internal.py
--rw-r--r--  2.0 unx     7445 b- defN 21-Sep-30 14:24 tmt/steps/execute/run.sh
--rw-r--r--  2.0 unx     3528 b- defN 21-Sep-30 14:24 tmt/steps/finish/__init__.py
--rw-r--r--  2.0 unx     1789 b- defN 21-Sep-30 14:24 tmt/steps/finish/shell.py
--rw-r--r--  2.0 unx     4410 b- defN 21-Sep-30 14:24 tmt/steps/prepare/__init__.py
--rw-r--r--  2.0 unx     2140 b- defN 21-Sep-30 14:24 tmt/steps/prepare/ansible.py
--rw-r--r--  2.0 unx    10115 b- defN 21-Sep-30 14:24 tmt/steps/prepare/install.py
--rw-r--r--  2.0 unx     1997 b- defN 21-Sep-30 14:24 tmt/steps/prepare/shell.py
--rw-r--r--  2.0 unx    20514 b- defN 21-Sep-30 14:24 tmt/steps/provision/__init__.py
--rw-r--r--  2.0 unx     3694 b- defN 21-Sep-30 14:24 tmt/steps/provision/connect.py
--rw-r--r--  2.0 unx     2584 b- defN 21-Sep-30 14:24 tmt/steps/provision/local.py
--rw-r--r--  2.0 unx     7608 b- defN 21-Sep-30 14:24 tmt/steps/provision/podman.py
--rw-r--r--  2.0 unx    19292 b- defN 21-Sep-30 14:24 tmt/steps/provision/testcloud.py
--rw-r--r--  2.0 unx     2595 b- defN 21-Sep-30 14:24 tmt/steps/report/__init__.py
--rw-r--r--  2.0 unx     1560 b- defN 21-Sep-30 14:24 tmt/steps/report/display.py
--rw-r--r--  2.0 unx     4918 b- defN 21-Sep-30 14:24 tmt/steps/report/html.py
--rw-r--r--  2.0 unx     3082 b- defN 21-Sep-30 14:24 tmt/steps/report/junit.py
--rwxr-xr-x  2.0 unx      970 b- defN 21-Sep-30 14:24 tmt-1.8.0.data/scripts/tmt
--rw-r--r--  2.0 unx     1071 b- defN 21-Sep-30 14:24 tmt-1.8.0.dist-info/LICENSE
--rw-r--r--  2.0 unx    12428 b- defN 21-Sep-30 14:24 tmt-1.8.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 21-Sep-30 14:24 tmt-1.8.0.dist-info/WHEEL
--rw-r--r--  2.0 unx      123 b- defN 21-Sep-30 14:24 tmt-1.8.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     3177 b- defN 21-Sep-30 14:24 tmt-1.8.0.dist-info/RECORD
-40 files, 432261 bytes uncompressed, 123751 bytes compressed:  71.4%
+Zip file size: 132737 bytes, number of entries: 41
+-rw-r--r--  2.0 unx      325 b- defN 21-Dec-01 13:22 tmt/__init__.py
+-rw-r--r--  2.0 unx       31 b- defN 21-Dec-01 13:22 tmt/__main__.py
+-rw-r--r--  2.0 unx    75231 b- defN 21-Dec-01 13:22 tmt/base.py
+-rw-r--r--  2.0 unx    11753 b- defN 21-Dec-01 13:22 tmt/beakerlib.py
+-rw-r--r--  2.0 unx    37553 b- defN 21-Dec-01 13:22 tmt/cli.py
+-rw-r--r--  2.0 unx    29264 b- defN 21-Dec-01 13:22 tmt/convert.py
+-rw-r--r--  2.0 unx    25782 b- defN 21-Dec-01 13:22 tmt/export.py
+-rw-r--r--  2.0 unx     5608 b- defN 21-Dec-01 13:22 tmt/options.py
+-rw-r--r--  2.0 unx     3091 b- defN 21-Dec-01 13:22 tmt/templates.py
+-rw-r--r--  2.0 unx    60026 b- defN 21-Dec-01 13:22 tmt/utils.py
+-rw-r--r--  2.0 unx     1694 b- defN 21-Dec-01 13:22 tmt/plugins/__init__.py
+-rw-r--r--  2.0 unx    22587 b- defN 21-Dec-01 13:22 tmt/steps/__init__.py
+-rw-r--r--  2.0 unx     8448 b- defN 21-Dec-01 13:22 tmt/steps/discover/__init__.py
+-rw-r--r--  2.0 unx    11362 b- defN 21-Dec-01 13:22 tmt/steps/discover/fmf.py
+-rw-r--r--  2.0 unx     3076 b- defN 21-Dec-01 13:22 tmt/steps/discover/shell.py
+-rw-r--r--  2.0 unx    12402 b- defN 21-Dec-01 13:22 tmt/steps/execute/__init__.py
+-rw-r--r--  2.0 unx     5667 b- defN 21-Dec-01 13:22 tmt/steps/execute/detach.py
+-rw-r--r--  2.0 unx    13059 b- defN 21-Dec-01 13:22 tmt/steps/execute/internal.py
+-rw-r--r--  2.0 unx     7445 b- defN 21-Dec-01 13:22 tmt/steps/execute/run.sh
+-rw-r--r--  2.0 unx     3528 b- defN 21-Dec-01 13:22 tmt/steps/finish/__init__.py
+-rw-r--r--  2.0 unx      997 b- defN 21-Dec-01 13:22 tmt/steps/finish/ansible.py
+-rw-r--r--  2.0 unx     1750 b- defN 21-Dec-01 13:22 tmt/steps/finish/shell.py
+-rw-r--r--  2.0 unx     4410 b- defN 21-Dec-01 13:22 tmt/steps/prepare/__init__.py
+-rw-r--r--  2.0 unx     2312 b- defN 21-Dec-01 13:22 tmt/steps/prepare/ansible.py
+-rw-r--r--  2.0 unx    10027 b- defN 21-Dec-01 13:22 tmt/steps/prepare/install.py
+-rw-r--r--  2.0 unx     1958 b- defN 21-Dec-01 13:22 tmt/steps/prepare/shell.py
+-rw-r--r--  2.0 unx    21170 b- defN 21-Dec-01 13:22 tmt/steps/provision/__init__.py
+-rw-r--r--  2.0 unx     3642 b- defN 21-Dec-01 13:22 tmt/steps/provision/connect.py
+-rw-r--r--  2.0 unx     2736 b- defN 21-Dec-01 13:22 tmt/steps/provision/local.py
+-rw-r--r--  2.0 unx     7617 b- defN 21-Dec-01 13:22 tmt/steps/provision/podman.py
+-rw-r--r--  2.0 unx    20162 b- defN 21-Dec-01 13:22 tmt/steps/provision/testcloud.py
+-rw-r--r--  2.0 unx     2595 b- defN 21-Dec-01 13:22 tmt/steps/report/__init__.py
+-rw-r--r--  2.0 unx     1560 b- defN 21-Dec-01 13:22 tmt/steps/report/display.py
+-rw-r--r--  2.0 unx     4961 b- defN 21-Dec-01 13:22 tmt/steps/report/html.py
+-rw-r--r--  2.0 unx     3103 b- defN 21-Dec-01 13:22 tmt/steps/report/junit.py
+-rwxr-xr-x  2.0 unx      970 b- defN 21-Dec-01 13:22 tmt-1.9.0.data/scripts/tmt
+-rw-r--r--  2.0 unx     1056 b- defN 21-Dec-01 13:22 tmt-1.9.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx    12491 b- defN 21-Dec-01 13:22 tmt-1.9.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 21-Dec-01 13:22 tmt-1.9.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx      135 b- defN 21-Dec-01 13:22 tmt-1.9.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     3270 b- defN 21-Dec-01 13:22 tmt-1.9.0.dist-info/RECORD
+41 files, 444946 bytes uncompressed, 127637 bytes compressed:  71.3%
```

## zipnote {}

```diff
@@ -18,23 +18,23 @@
 
 Filename: tmt/export.py
 Comment: 
 
 Filename: tmt/options.py
 Comment: 
 
-Filename: tmt/plugins.py
-Comment: 
-
 Filename: tmt/templates.py
 Comment: 
 
 Filename: tmt/utils.py
 Comment: 
 
+Filename: tmt/plugins/__init__.py
+Comment: 
+
 Filename: tmt/steps/__init__.py
 Comment: 
 
 Filename: tmt/steps/discover/__init__.py
 Comment: 
 
 Filename: tmt/steps/discover/fmf.py
@@ -54,14 +54,17 @@
 
 Filename: tmt/steps/execute/run.sh
 Comment: 
 
 Filename: tmt/steps/finish/__init__.py
 Comment: 
 
+Filename: tmt/steps/finish/ansible.py
+Comment: 
+
 Filename: tmt/steps/finish/shell.py
 Comment: 
 
 Filename: tmt/steps/prepare/__init__.py
 Comment: 
 
 Filename: tmt/steps/prepare/ansible.py
@@ -96,26 +99,26 @@
 
 Filename: tmt/steps/report/html.py
 Comment: 
 
 Filename: tmt/steps/report/junit.py
 Comment: 
 
-Filename: tmt-1.8.0.data/scripts/tmt
+Filename: tmt-1.9.0.data/scripts/tmt
 Comment: 
 
-Filename: tmt-1.8.0.dist-info/LICENSE
+Filename: tmt-1.9.0.dist-info/LICENSE
 Comment: 
 
-Filename: tmt-1.8.0.dist-info/METADATA
+Filename: tmt-1.9.0.dist-info/METADATA
 Comment: 
 
-Filename: tmt-1.8.0.dist-info/WHEEL
+Filename: tmt-1.9.0.dist-info/WHEEL
 Comment: 
 
-Filename: tmt-1.8.0.dist-info/top_level.txt
+Filename: tmt-1.9.0.dist-info/top_level.txt
 Comment: 
 
-Filename: tmt-1.8.0.dist-info/RECORD
+Filename: tmt-1.9.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## tmt/__init__.py

```diff
@@ -1,10 +1,10 @@
 """ Test Management Tool """
 
 # Version is replaced before building the package
-__version__ = '1.8.0 (d0146d9)'
+__version__ = '1.9.0 (599b9a1)'
 
 __all__ = ['Tree', 'Test', 'Plan', 'Story', 'Run', 'Guest', 'Result',
            'Status', 'Clean']
 
 from tmt.base import Clean, Plan, Result, Run, Status, Story, Test, Tree
 from tmt.steps.provision import Guest
```

## tmt/base.py

```diff
@@ -226,14 +226,37 @@
         # Summary is advised with a resonable length
         if self.summary is None:
             verdict(None, "summary is very useful for quick inspection")
         elif len(self.summary) > 50:
             verdict(None, "summary should not exceed 50 characters")
         return True
 
+    def has_link(self, link_object):
+        """ Whether object contains specified link """
+        def get_relation(from_link):
+            # keys() = relation and optional note
+            return list(set(from_link.keys()) - set(['note']))[0]
+        if isinstance(link_object, Link):
+            relation = get_relation(link_object)
+            target = link_object[relation]
+        else:
+            # User text input
+            parts = link_object.split(':', maxsplit=1)
+            if len(parts) == 1:
+                relation, target = ".*", parts[0]
+            else:
+                relation, target = parts
+        for candidate in self.link:
+            candidate_relation = get_relation(candidate)
+            candidate_target = candidate[candidate_relation]
+            if (re.search(relation, candidate_relation)
+                    and re.search(target, candidate_target)):
+                return True
+        return False
+
 
 Node = Core
 
 
 class Test(Core):
     """ Test object (L1 Metadata) """
 
@@ -1090,15 +1113,15 @@
 
     def _fmf_context(self):
         """ Use custom fmf context if provided, default otherwise """
         if self._custom_context is not None:
             return self._custom_context
         return super()._fmf_context()
 
-    def _filters_conditions(self, nodes, filters, conditions):
+    def _filters_conditions(self, nodes, filters, conditions, links):
         """ Apply filters and conditions, return pruned nodes """
         result = []
         for node in nodes:
             filter_vars = copy.deepcopy(node._metadata)
             cond_vars = node._metadata
             # Add a lowercase version of bool variables for filtering
             bool_vars = {
@@ -1121,14 +1144,23 @@
             try:
                 if not all([fmf.utils.filter(filter_, filter_vars, regexp=True)
                             for filter_ in filters]):
                     continue
             except fmf.utils.FilterError as error:
                 # Handle missing attributes as if filter failed
                 continue
+            # Links
+            try:
+                # Links are in OR relation
+                if links and all([not node.has_link(link_)
+                                 for link_ in links]):
+                    continue
+            except BaseException:
+                # Handle broken link as not matching
+                continue
             result.append(node)
         return result
 
     @property
     def tree(self):
         """ Initialize tree only when accessed """
         if self._tree is None:
@@ -1149,56 +1181,78 @@
         self._tree = new_tree
 
     @property
     def root(self):
         """ Metadata root """
         return self.tree.root
 
-    def tests(self, keys=None, names=None, filters=None, conditions=None):
+    def tests(self, keys=None, names=None, filters=None, conditions=None,
+              unique=True, links=None):
         """ Search available tests """
         # Handle defaults, apply possible command line options
         keys = (keys or []) + ['test']
-        names = (names or []) + list(Test._opt('names', []))
+        names = names or []
         filters = (filters or []) + list(Test._opt('filters', []))
         conditions = (conditions or []) + list(Test._opt('conditions', []))
+        links = (links or []) + list(Test._opt('links', []))
 
-        # Build the list and convert to objects
+        # First let's build the list of fmf nodes based on keys & names.
+        # If duplicate test names are allowed, match test name/regexp
+        # one-by-one and preserve the order of tests within a plan.
+        if not unique and names:
+            nodes = []
+            for name in names:
+                nodes.extend(self.tree.prune(keys=keys, names=[name]))
+        # Otherwise just perform a regular key/name filtering
+        else:
+            nodes = self.tree.prune(keys=keys, names=names)
+
+        # Apply possible additional name filters from the command line
+        # (Used in: tmt run test --name NAME, tmt test ls NAME...)
+        cli_names = list(Test._opt('names', []))
+        if cli_names:
+            nodes = [
+                node for node in nodes
+                if any([re.search(name, node.name) for name in cli_names])]
+
+        # Convert into Test objects and apply filters & conditions
         return self._filters_conditions(
-            [Test(test) for test in self.tree.prune(keys=keys, names=names)],
-            filters, conditions)
+            [Test(node) for node in nodes], filters, conditions, links)
 
     def plans(self, keys=None, names=None, filters=None, conditions=None,
-              run=None):
+              run=None, links=None):
         """ Search available plans """
         # Handle defaults, apply possible command line options
         keys = (keys or []) + ['execute']
         names = (names or []) + list(Plan._opt('names', []))
         filters = (filters or []) + list(Plan._opt('filters', []))
         conditions = (conditions or []) + list(Plan._opt('conditions', []))
+        links = (links or []) + list(Plan._opt('links', []))
 
         # Build the list and convert to objects
         return self._filters_conditions(
             [Plan(plan, run=run)
                 for plan in self.tree.prune(keys=keys, names=names)],
-            filters, conditions)
+            filters, conditions, links)
 
     def stories(self, keys=None, names=None, filters=None, conditions=None,
-                whole=False):
+                whole=False, links=None):
         """ Search available stories """
         # Handle defaults, apply possible command line options
         keys = (keys or []) + ['story']
         names = (names or []) + list(Story._opt('names', []))
         filters = (filters or []) + list(Story._opt('filters', []))
         conditions = (conditions or []) + list(Story._opt('conditions', []))
+        links = (links or []) + list(Story._opt('links', []))
 
         # Build the list and convert to objects
         return self._filters_conditions(
             [Story(story) for story in self.tree.prune(
                 keys=keys, names=names, whole=whole)],
-            filters, conditions)
+            filters, conditions, links)
 
     @staticmethod
     def init(path, template, force, **kwargs):
         """ Initialize a new tmt tree, optionally with a template """
         path = os.path.realpath(path)
         dry = Tree._opt('dry')
 
@@ -1265,15 +1319,16 @@
         # Do not create workdir now, postpone it until later, as options
         # have not been processed yet and we do not want commands such as
         # tmt run discover --how fmf --help to create a new workdir.
         super().__init__(context=context)
         self._workdir_path = id_ or True
         self._tree = tree
         self._plans = None
-        self._environment = dict()
+        self._environment_from_workdir = dict()
+        self._environment_from_options = None
         self.remove = self.opt('remove')
 
     def _use_default_plan(self):
         """ Prepare metadata tree with only the default plan """
         default_plan = tmt.utils.yaml_to_dict(tmt.templates.DEFAULT_PLAN)
         # The default discover method for this case is 'shell'
         default_plan['/plans/default']['discover']['how'] = 'shell'
@@ -1299,22 +1354,29 @@
         # Create an empty default plan if no fmf metadata found
         except tmt.utils.MetadataError:
             self._use_default_plan()
 
     @property
     def environment(self):
         """ Return environment combined from wake up and command line """
-        combined = self._environment.copy()
-        # Merge variables gathered from 'environment-file' options
-        combined.update(tmt.utils.environment_file_to_dict(
-            (self.opt('environment-file') or []), root=self.tree.root))
-        # Merge variables from 'environment' options (highest priority)
-        combined.update(tmt.utils.environment_to_dict(
-            self.opt('environment')))
-
+        # Gather environment variables from options only once
+        if self._environment_from_options is None:
+            self._environment_from_options = dict()
+            # Variables gathered from 'environment-file' options
+            self._environment_from_options.update(
+                tmt.utils.environment_file_to_dict(
+                    (self.opt('environment-file') or []),
+                    root=self.tree.root))
+            # Variables from 'environment' options (highest priority)
+            self._environment_from_options.update(
+                tmt.utils.environment_to_dict(self.opt('environment')))
+
+        # Combine workdir and command line
+        combined = self._environment_from_workdir.copy()
+        combined.update(self._environment_from_options)
         return combined
 
     def save(self):
         """ Save list of selected plans and enabled steps """
         data = {
             'root': self.tree.root,
             'plans': [plan.name for plan in self._plans],
@@ -1336,15 +1398,15 @@
         self._save_tree(self._tree)
         self._workdir_load(self._workdir_path)
         try:
             data = tmt.utils.yaml_to_dict(self.read('run.yaml'))
         except tmt.utils.FileError:
             self.debug('Run data not found.')
             return
-        self._environment = data.get('environment')
+        self._environment_from_workdir = data.get('environment')
         self._context.obj.steps = set(data['steps'])
         plans = []
         # The root directory of the tree may not be available, create
         # a partial Core object that only contains the necessary
         # attributes required for plan/step loading.
         for plan in data.get('plans'):
             node = type('Core', (), {
@@ -1374,29 +1436,31 @@
                 self._save_tree(tmt.Tree(data['root']))
             else:
                 # The run was used without any metadata, default plan
                 # was used, load it
                 self._use_default_plan()
 
         # Filter plans by name unless specified on the command line
-        plan_options = ['names', 'filters', 'conditions', 'default']
+        plan_options = ['names', 'filters', 'conditions', 'links', 'default']
         if not any([Plan._opt(option) for option in plan_options]):
             self._plans = [
                 plan for plan in self.tree.plans(run=self)
                 if plan.name in data['plans']]
 
         # Initialize steps only if not selected on the command line
         step_options = 'all since until after before skip'.split()
         selected = any([self.opt(option) for option in step_options])
         if not selected and not self._context.obj.steps:
             self._context.obj.steps = set(data['steps'])
 
         # Store loaded environment
-        self._environment = data.get('environment')
-        self.debug(f"Loaded environment: '{self._environment}'.", level=3)
+        self._environment_from_workdir = data.get('environment')
+        self.debug(
+            f"Loaded environment: '{self._environment_from_workdir}'.",
+            level=3)
 
         # If the remove was enabled, restore it, option overrides
         self.remove = self.remove or data.get('remove', 'False')
         self.debug(f"Remove workdir when finished: {self.remove}", level=3)
 
     @property
     def plans(self):
```

## tmt/cli.py

```diff
@@ -81,14 +81,18 @@
             'names', nargs=-1, metavar='[REGEXP|.]'),
         click.option(
             '-f', '--filter', 'filters', metavar='FILTER', multiple=True,
             help="Apply advanced filter (see 'pydoc fmf.filter')."),
         click.option(
             '-c', '--condition', 'conditions', metavar="EXPR", multiple=True,
             help="Use arbitrary Python expression for filtering."),
+        click.option(
+            '--link', 'links', metavar="RELATION:TARGET", multiple=True,
+            help="Filter by linked objects (regular expressions are "
+                 "supported for both relation and target)."),
         ]
 
     for option in reversed(options):
         function = option(function)
     return function
 
 
@@ -99,14 +103,18 @@
             'names', nargs=-1, metavar='[REGEXP|.]'),
         click.option(
             '--filter', 'filters', metavar='FILTER', multiple=True,
             help="Apply advanced filter (see 'pydoc fmf.filter')."),
         click.option(
             '--condition', 'conditions', metavar="EXPR", multiple=True,
             help="Use arbitrary Python expression for filtering."),
+        click.option(
+            '--link', 'links', metavar="RELATION:TARGET", multiple=True,
+            help="Filter by linked objects (regular expressions are "
+                 "supported for both relation and target)."),
         ]
 
     for option in reversed(options):
         function = option(function)
     return function
 
 
@@ -265,14 +273,18 @@
 @click.option(
     '-f', '--filter', 'filters', metavar='FILTER', multiple=True,
     help="Apply advanced filter (see 'pydoc fmf.filter').")
 @click.option(
     '-c', '--condition', 'conditions', metavar="EXPR", multiple=True,
     help="Use arbitrary Python expression for filtering.")
 @click.option(
+    '--link', 'links', metavar="RELATION:TARGET", multiple=True,
+    help="Filter by linked objects (regular expressions are "
+         "supported for both relation and target).")
+@click.option(
     '--default', is_flag=True,
     help="Use default plans even if others are available.")
 @verbose_debug_quiet
 def plans(context, **kwargs):
     """
     Select plans which should be executed.
 
@@ -289,14 +301,18 @@
     help="Regular expression to match test name or '.' for current directory.")
 @click.option(
     '-f', '--filter', 'filters', metavar='FILTER', multiple=True,
     help="Apply advanced filter (see 'pydoc fmf.filter').")
 @click.option(
     '-c', '--condition', 'conditions', metavar="EXPR", multiple=True,
     help="Use arbitrary Python expression for filtering.")
+@click.option(
+    '--link', 'links', metavar="RELATION:TARGET", multiple=True,
+    help="Filter by linked objects (regular expressions are "
+         "supported for both relation and target).")
 @verbose_debug_quiet
 def tests(context, **kwargs):
     """
     Select tests which should be executed.
 
     Regular expression can be used to filter tests by name.
     Use '.' to select tests under the current working directory.
```

## tmt/utils.py

```diff
@@ -1,25 +1,24 @@
 
 """ Test Metadata Utilities """
 
 import contextlib
 import datetime
-import fcntl
+import glob
 import io
 import os
 import pprint
 import re
-import select
 import shlex
 import shutil
 import subprocess
 import unicodedata
 from collections import OrderedDict
 from pathlib import Path
-from threading import Timer
+from threading import Thread
 from typing import Dict, Iterable
 
 import fmf
 import requests
 from click import echo, style, wrap_text
 from requests.adapters import HTTPAdapter
 from requests.packages.urllib3.util.retry import Retry
@@ -90,14 +89,44 @@
                     f"Unable to save last run '{self.path}'.\n{error}")
             return run_id
         if os.path.islink(symlink):
             return os.path.realpath(symlink)
         return None
 
 
+class StreamLogger(Thread):
+    """
+    Reading pipes of running process in threads.
+
+    Code based on:
+    https://github.com/packit/packit/blob/main/packit/utils/logging.py#L10
+    """
+
+    def __init__(self, stream, log_header, logger):
+        super().__init__(daemon=True)
+        self.stream = stream
+        self.output = []
+        self.log_header = log_header
+        self.logger = logger
+
+    def run(self):
+        for line in self.stream:
+            line = line.decode('utf-8', errors='replace')
+            if line != '':
+                self.logger(
+                    self.log_header,
+                    line.rstrip('\n'),
+                    'yellow',
+                    level=3)
+            self.output.append(line)
+
+    def get_output(self):
+        return "".join(self.output)
+
+
 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 #  Common
 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 class Common(object):
     """
     Common shared stuff
@@ -318,86 +347,45 @@
             process = subprocess.Popen(
                 command, cwd=cwd, shell=shell, env=environment,
                 stdin=subprocess.DEVNULL, stdout=subprocess.PIPE,
                 stderr=subprocess.STDOUT if join else subprocess.PIPE)
         except FileNotFoundError as error:
             raise RunError(
                 f"File '{error.filename}' not found.", command, 127)
-        if join:
-            descriptors = [process.stdout.fileno()]
-        else:
-            descriptors = [process.stdout.fileno(), process.stderr.fileno()]
-        stdout = ''
-        stderr = ''
-
-        # Prepare kill function for the timer
-        def kill():
-            """ Kill the process and adjust the return code """
-            process.kill()
-            process.returncode = PROCESS_TIMEOUT
 
+        stdout_thread = StreamLogger(
+            process.stdout, log_header='out', logger=log)
+        stderr_thread = stdout_thread
+        if not join:
+            stderr_thread = StreamLogger(
+                process.stderr, log_header='err', logger=log)
+        stdout_thread.start()
+        if not join:
+            stderr_thread.start()
         try:
-            # Start the timer
-            timer = Timer(timeout, kill)
-            timer.start()
-
-            # Make sure that the read operation on the file descriptors
-            # never blocks
-            for fd in descriptors:
-                fcntl.fcntl(fd, fcntl.F_SETFL, os.O_NONBLOCK)
-
-            # Capture the output
-            while process.poll() is None:
-                # Check which file descriptors are ready for read
-                selected = select.select(
-                    descriptors, [], [], DEFAULT_SELECT_TIMEOUT)
-
-                for descriptor in selected[0]:
-                    # Handle stdout
-                    if descriptor == process.stdout.fileno():
-                        line = process.stdout.readline().decode(
-                            'utf-8', errors='replace')
-                        stdout += line
-                        if line != '':
-                            log('out', line.rstrip('\n'), 'yellow', level=3)
-                    # Handle stderr
-                    if not join and descriptor == process.stderr.fileno():
-                        line = process.stderr.readline().decode(
-                            'utf-8', errors='replace')
-                        stderr += line
-                        if line != '':
-                            log('err', line.rstrip('\n'), 'yellow', level=3)
-
-        finally:
-            # Cancel the timer
-            timer.cancel()
-
-        # Check for possible additional output
-        selected = select.select(descriptors, [], [], DEFAULT_SELECT_TIMEOUT)
-        for descriptor in selected[0]:
-            if descriptor == process.stdout.fileno():
-                for line in process.stdout.readlines():
-                    line = line.decode('utf-8', errors='replace')
-                    stdout += line
-                    log('out', line.rstrip('\n'), 'yellow', level=3)
-            if not join and descriptor == process.stderr.fileno():
-                for line in process.stderr.readlines():
-                    line = line.decode('utf-8', errors='replace')
-                    stderr += line
-                    log('err', line.rstrip('\n'), 'yellow', level=3)
+            process.wait(timeout=timeout)
+        except subprocess.TimeoutExpired:
+            process.kill()
+            process.returncode = PROCESS_TIMEOUT
+        stdout_thread.join()
+        if not join:
+            stderr_thread.join()
 
         # Handle the exit code, return output
         if process.returncode != 0:
             if isinstance(command, (list, tuple)):
                 command = ' '.join(command)
             raise RunError(
                 message=f"Command returned '{process.returncode}'.",
-                command=command, returncode=process.returncode,
-                stdout=stdout, stderr=stderr)
-        return stdout if join else (stdout, stderr)
+                command=command,
+                returncode=process.returncode,
+                stdout=stdout_thread.get_output(),
+                stderr=stderr_thread.get_output())
+        return stdout_thread.get_output() if join else (
+            stdout_thread.get_output(), stderr_thread.get_output())
 
     def run(
             self, command, message=None, cwd=None, dry=False, shell=True,
             env=None, interactive=False, join=False, log=None, timeout=None):
         """
         Run command, give message, handle errors
 
@@ -690,14 +678,18 @@
     try:
         with open(filepath[1:], 'r') as content:
             file_vars = yaml_to_dict(content)
     except Exception as exception:
         raise GeneralError(
             f"Failed to load variables from '{filepath}': {exception}")
 
+    # Handle empty file as an empty environment
+    if file_vars is None:
+        log.warn(f"Empty environment file '{filepath}'.")
+        return
     for name, value in file_vars.items():
         result[name] = str(value)
 
 
 def shell_to_dict(variables):
     """
     Convert shell-like variables into a dictionary
@@ -806,15 +798,18 @@
                     f"The 'environment-file' path '{full_path}' is outside "
                     f"of the metadata tree root '{root}'.")
             if not Path(full_path).is_file():
                 raise GeneralError(f"File '{full_path}' doesn't exist.")
             content = Path(full_path).read_text()
         # Parse yaml file
         if re.match(r".*\.ya?ml$", env_file):
-            result.update(parse_yaml(content))
+            environment = parse_yaml(content)
+            if not environment:
+                log.warn(f"Empty environment file '{env_file}'.")
+            result.update(environment)
         # Parse dotenv file
         else:
             try:
                 result.update(parse_dotenv(content))
             except ValueError:
                 raise GeneralError(
                     f"Failed to extract variables from environment file "
@@ -1165,14 +1160,17 @@
     return dict([line.split("=", maxsplit=1)
                 for line in shlex.split(content, comments=True)])
 
 
 def parse_yaml(content: str) -> Dict[str, str]:
     """ Parse variables from yaml, ensure flat dictionary format """
     yaml_as_dict = YAML(typ="safe").load(content)
+    # Handle empty file as an empty environment
+    if yaml_as_dict is None:
+        return dict()
     if any(isinstance(val, dict) for val in yaml_as_dict.values()):
         raise GeneralError(
             "Can't set the environment from the nested yaml config. The "
             "config should be just key, value pairs.")
     return {key: str(value) for key, value in yaml_as_dict.items()}
 
 
@@ -1683,7 +1681,89 @@
                 dictionary = self._read_section(self._sections[section])
                 del(dictionary[item])
             except KeyError:
                 raise StructuredFieldError(
                     "Unable to remove '{0}' from section '{1}'".format(
                         ascii(item), ascii(section)))
             self._sections[section] = self._write_section(dictionary)
+
+
+class DistGitHandler(object):
+    """ Common functionality for DistGit handlers """
+    sources_file_name = 'sources'
+    uri = "/rpms/{name}/{filename}/{hashtype}/{hash}/{filename}"
+    remote_substring = None
+    usage_name = "Name to use for dist-git-type"
+
+    def url_and_name(self, cwd='.'):
+        """
+        Return list of urls and basenames of the used source
+
+        The 'cwd' parameter has to be a DistGit directory.
+        """
+        # Assumes <package>.spec
+        globbed = glob.glob(os.path.join(cwd, '*.spec'))
+        if len(globbed) != 1:
+            raise GeneralError(f"No .spec file is present in '{cwd}'.")
+        package = os.path.basename(globbed[0])[:-len('.spec')]
+        ret_values = []
+        try:
+            with open(os.path.join(cwd, self.sources_file_name)) as f:
+                for line in f.readlines():
+                    match = self.re_source.match(line)
+                    used_hash, source_name, hash_value = match.groups()
+                    ret_values.append((self.lookaside_server + self.uri.format(
+                        name=package,
+                        filename=source_name,
+                        hash=hash_value,
+                        hashtype=used_hash.lower()
+                        ), source_name))
+        except Exception as error:
+            raise GeneralError(
+                f"Couldn't read '{self.sources_file_name}' file.",
+                original=error)
+        if not ret_values:
+            raise GeneralError(
+                "No sources found in '{self.sources_file_name}' file.")
+        return ret_values
+
+    def its_me(self, remotes):
+        """ True if self can work with remotes """
+        return any([self.remote_substring.search(item) for item in remotes])
+
+
+class FedoraDistGit(DistGitHandler):
+    """ Fedora Handler """
+    usage_name = "fedora"
+    re_source = re.compile(r"^(\w+) \(([^)]+)\) = ([0-9a-fA-F]+)$")
+    lookaside_server = "https://src.fedoraproject.org/repo/pkgs"
+    remote_substring = re.compile(r'fedoraproject\.org')
+
+
+class CentOSDistGit(DistGitHandler):
+    """ CentOS Handler """
+    usage_name = "centos"
+    re_source = re.compile(r"^(\w+) \(([^)]+)\) = ([0-9a-fA-F]+)$")
+    lookaside_server = "https://sources.stream.centos.org/sources"
+    remote_substring = re.compile(r'redhat/centos')
+
+
+def get_distgit_handler(remotes=None, usage_name=None):
+    """
+    Return the right DistGitHandler
+
+    Pick the DistGitHandler class which understands specified
+    remotes or by usage_name.
+    """
+    for candidate_class in DistGitHandler.__subclasses__():
+        if usage_name is not None and usage_name == candidate_class.usage_name:
+            return candidate_class()
+        if remotes is not None:
+            ret_val = candidate_class()
+            if ret_val.its_me(remotes):
+                return ret_val
+    raise GeneralError(f"No known remote in '{remotes}'.")
+
+
+def get_distgit_handler_names():
+    """ All known distgit handlers """
+    return [i.usage_name for i in DistGitHandler.__subclasses__()]
```

## tmt/steps/__init__.py

```diff
@@ -53,15 +53,17 @@
         # Final sanity checks
         for data in self.data:
             # Set 'how' to the default if not specified
             if data.get('how') is None:
                 data['how'] = self.how
             # Ensure that each config has a name
             if 'name' not in data and len(self.data) > 1:
-                raise GeneralError(f"Missing '{self}' name in '{self.plan}'.")
+                raise GeneralError(
+                    f"Missing 'name' in the {self} step config "
+                    f"of the '{self.plan}' plan.")
 
     @property
     def enabled(self):
         """ True if the step is enabled """
         try:
             return self.name in self.plan.my_run._context.obj.steps
         except AttributeError:
@@ -244,20 +246,28 @@
 class Plugin(tmt.utils.Common, metaclass=PluginIndex):
     """ Common parent of all step plugins """
 
     # Default implementation for all steps is shell
     # except for provision (virtual) and report (display)
     how = 'shell'
 
+    # Common keys for all plugins of given step
+    _common_keys = []
+
+    # Keys specific for given plugin
+    _keys = []
+
     def __init__(self, step, data):
         """ Store plugin name, data and parent step """
 
         # Ensure that plugin data contains name
         if 'name' not in data:
-            raise GeneralError("Missing 'name' in plugin data.")
+            raise GeneralError(
+                f"Missing 'name' in the {step} step config "
+                f"of the '{step.plan}' plan.")
 
         # Store name, data and parent step
         super().__init__(parent=step, name=data['name'])
         self.data = data
         self.step = step
 
         # Initialize plugin order
@@ -349,39 +359,45 @@
         # Step name (and optional summary)
         echo(tmt.utils.format(
             self.step, self.get('summary', ''),
             key_color='blue', value_color='blue'))
         # Show all or requested step attributes
         base_keys = ['name', 'how']
         if keys is None:
-            keys = [key for key in self.data.keys() if key not in base_keys]
+            keys = self._common_keys + self._keys
         for key in base_keys + keys:
             # Skip showing the default name
             if key == 'name' and self.name == tmt.utils.DEFAULT_NAME:
                 continue
             # Skip showing summary again
             if key == 'summary':
                 continue
             value = self.get(key)
             if value is not None:
                 echo(tmt.utils.format(key, value))
 
-    def wake(self, options=None):
+    def wake(self, keys=None):
         """
-        Wake up the plugin (override data with command line)
+        Wake up the plugin, process data, apply options
 
-        If a list of option names is provided, their value will be
-        checked and stored in self.data unless empty or undefined.
+        Check command line options corresponding to plugin keys
+        and store their value into the 'self.data' dictionary if
+        their value is True or non-empty.
+
+        By default, all supported options corresponding to common
+        and plugin-specific keys are processed. List of key names
+        in the 'keys' parameter can be used to override only
+        selected ones.
         """
-        if options is None:
-            return
-        for option in options:
-            value = self.opt(option)
+        if keys is None:
+            keys = self._common_keys + self._keys
+        for key in keys:
+            value = self.opt(key)
             if value:
-                self.data[option] = value
+                self.data[key] = value
 
     def go(self):
         """ Go and perform the plugin task """
         # Show the method
         self.info('how', self.get('how'), 'magenta')
         # Give summary if provided
         if self.get('summary'):
```

## tmt/steps/discover/__init__.py

```diff
@@ -1,7 +1,9 @@
+import os
+
 import click
 from fmf.utils import listed
 
 import tmt
 
 
 class Discover(tmt.steps.Step):
@@ -192,20 +194,45 @@
             help='Use specified method to discover tests.')
         def discover(context, **kwargs):
             context.obj.steps.add('discover')
             Discover._save_context(context)
 
         return discover
 
-    @classmethod
-    def options(cls, how=None):
-        """ Prepare command line options for given method """
-        return super().options(how)
-
     def tests(self):
         """
         Return discovered tests
 
         Each DiscoverPlugin has to implement this method.
         Should return a list of Test() objects.
         """
         raise NotImplementedError
+
+    def extract_distgit_source(
+            self, distgit_dir, target_dir, handler_name=None):
+        """
+        Extract source tarball into target_dir
+
+        distgit_dir is path to the DistGit repository.
+        Source tarball is discovered from the 'sources' file content.
+        """
+        if handler_name is None:
+            stdout, _ = self.run(
+                ["git", "config", "--get-regexp", '^remote\\..*.url'],
+                shell=False, cwd=distgit_dir)
+            remotes = stdout.split('\n')
+            handler = tmt.utils.get_distgit_handler(remotes=remotes)
+        else:
+            handler = tmt.utils.get_distgit_handler(usage_name=handler_name)
+        for url, source_name in handler.url_and_name(distgit_dir):
+            if source_name.endswith('.sign'):
+                continue
+            self.debug(f"Download sources from '{url}'.")
+            session = tmt.utils.retry_session()
+            response = session.get(url)
+            response.raise_for_status()
+            os.makedirs(target_dir, exist_ok=True)
+            with open(os.path.join(target_dir, source_name), 'wb') as tarball:
+                tarball.write(response.content)
+            self.run(
+                f"tar --auto-compress --extract -f {source_name}",
+                cwd=target_dir)
```

## tmt/steps/discover/fmf.py

```diff
@@ -28,14 +28,31 @@
             ref: main
             path: /fmf/root
             test: /tests/basic
             filter: 'tier: 1'
 
     If no 'ref' is provided, the default branch from the origin is used.
 
+    For DistGit repo one can extract source tarball first and discover
+    tests from it by using 'distgit-source: true'. It can be used
+    together with 'ref', 'path' and 'url'.
+
+        discover:
+            how: fmf
+            dist-git-source: true
+
+    Selecting tests containting specified link is possible using 'link'
+    option accepting RELATION:TARGET format of values. Regular
+    expressions are supported for both relation and target part of the
+    value. Relation can be omitted to target match any relation.
+
+        discover:
+            how: fmf
+            link: verifies:.*issue/850$
+
     It is also possible to limit tests only to those that have changed
     in git since a given revision. This can be particularly useful when
     testing changes to tests themselves (e.g. in a pull request CI).
 
     Related config options (all optional):
     * modified-only - set to True if you want to filter modified tests
     * modified-url - fetched as "reference" remote in the test dir
@@ -53,14 +70,20 @@
     specified via 'test', so those tests will also be selected even if
     not modified.
     """
 
     # Supported methods
     _methods = [tmt.steps.Method(name='fmf', doc=__doc__, order=50)]
 
+    # Supported keys
+    _keys = [
+        "url", "ref", "path", "test", "link", "filter",
+        "modified-only", "modified-url", "modified-ref",
+        "dist-git-source", "dist-git-type"]
+
     @classmethod
     def options(cls, how=None):
         """ Prepare command line options for given method """
         return [
             click.option(
                 '-u', '--url', metavar='REPOSITORY',
                 help='URL of the git repository with fmf metadata.'),
@@ -81,76 +104,83 @@
             click.option(
                 '-p', '--path', metavar='ROOT',
                 help='Path to the metadata tree root.'),
             click.option(
                 '-t', '--test', metavar='NAMES', multiple=True,
                 help='Select tests by name.'),
             click.option(
+                '--link', metavar="RELATION:TARGET", multiple=True,
+                help="Filter by linked objects (regular expressions are "
+                     "supported for both relation and target)."),
+            click.option(
                 '-F', '--filter', metavar='FILTERS', multiple=True,
                 help='Include only tests matching the filter.'),
+            click.option(
+                '--dist-git-source', is_flag=True,
+                help='Extract DistGit sources and run discover on top of it.'),
+            click.option(
+                '--dist-git-type',
+                type=click.Choice(tmt.utils.get_distgit_handler_names()),
+                help='Use the provided DistGit handler instead of detection.'),
             ] + super().options(how)
 
-    def show(self):
-        """ Show discover details """
-        super().show(['url', 'ref', 'path', 'test', 'filter'])
-
-    def wake(self):
-        """ Wake up the plugin (override data with command line) """
-
+    def wake(self, keys=None):
+        """ Wake up the plugin, process data, apply options """
         # Handle backward-compatible stuff
         if 'repository' in self.data:
             self.data['url'] = self.data.pop('repository')
         if 'revision' in self.data:
             self.data['ref'] = self.data.pop('revision')
 
         # Make sure that 'filter' and 'test' keys are lists
-        for key in ['filter', 'test']:
-            if key in self.data and not isinstance(self.data[key], list):
-                self.data[key] = [self.data[key]]
+        tmt.utils.listify(self.data, keys=["filter", "test"])
 
         # Process command line options, apply defaults
-        for option in ['url', 'ref', 'modified-url', 'modified-ref', 'path',
-                       'test', 'filter', 'modified-only']:
-            value = self.opt(option)
-            if value:
-                self.data[option] = value
+        super().wake(keys=keys)
 
     def go(self):
         """ Discover available tests """
         super(DiscoverFmf, self).go()
 
         # Check url and path, prepare test directory
         url = self.get('url')
         path = self.get('path')
         testdir = os.path.join(self.workdir, 'tests')
+        dist_git_source = self.get('dist-git-source', False)
 
         # Clone provided git repository (if url given) with disabled
         # prompt to ignore possibly missing or private repositories
         if url:
             self.info('url', url, 'green')
             self.debug(f"Clone '{url}' to '{testdir}'.")
             self.run(
                 ['git', 'clone', url, testdir],
                 shell=False, env={"GIT_ASKPASS": "echo"})
         # Copy git repository root to workdir
         else:
-            if path and not os.path.isdir(path):
+            # Path for distgit sources cannot be checked until the
+            # tarball is extracted
+            if path and not os.path.isdir(path) and not dist_git_source:
                 raise tmt.utils.DiscoverError(
                     f"Provided path '{path}' is not a directory.")
-            fmf_root = path or self.step.plan.my_run.tree.root
-            # Check git repository root (use fmf root if not found)
-            try:
-                output = self.run(
-                    'git rev-parse --show-toplevel', cwd=fmf_root, dry=True)
-                git_root = output[0].strip('\n')
-            except tmt.utils.RunError:
-                self.debug(f"Git root not found, using '{fmf_root}.'")
-                git_root = fmf_root
-            # Set path to relative path from the git root to fmf root
-            path = os.path.relpath(fmf_root, git_root)
+            if dist_git_source:
+                git_root = self.step.plan.my_run.tree.root
+            else:
+                fmf_root = path or self.step.plan.my_run.tree.root
+                # Check git repository root (use fmf root if not found)
+                try:
+                    output = self.run(
+                        'git rev-parse --show-toplevel',
+                        cwd=fmf_root, dry=True)
+                    git_root = output[0].strip('\n')
+                except tmt.utils.RunError:
+                    self.debug(f"Git root not found, using '{fmf_root}.'")
+                    git_root = fmf_root
+                # Set path to relative path from the git root to fmf root
+                path = os.path.relpath(fmf_root, git_root)
             self.info('directory', git_root, 'green')
             self.debug(f"Copy '{git_root}' to '{testdir}'.")
             if not self.opt('dry'):
                 shutil.copytree(git_root, testdir, symlinks=True)
 
         # Checkout revision if requested
         ref = self.get('ref')
@@ -164,14 +194,23 @@
         # Show current commit hash if inside a git repository
         try:
             hash_, _ = self.run('git rev-parse --short HEAD', cwd=testdir)
             self.verbose('hash', hash_.strip(), 'green')
         except (tmt.utils.RunError, AttributeError):
             pass
 
+        # Fetch and extract distgit sources
+        if dist_git_source:
+            try:
+                self.extract_distgit_source(
+                    testdir, testdir, self.get('dist-git-type'))
+            except Exception as error:
+                raise tmt.utils.DiscoverError(
+                    f"Failed to process 'dist-git-source'.", original=error)
+
         # Adjust path and optionally show
         if path is None or path == '.':
             path = ''
         else:
             self.info('path', path, 'green')
 
         # Prepare the whole tree path and test path prefix
@@ -182,18 +221,22 @@
         prefix_path = os.path.join('/tests', path.lstrip('/'))
 
         # Show filters and test names if provided
         # Check the 'test --filter' option first, then from discover
         filters = list(tmt.base.Test._opt('filters') or self.get('filter', []))
         for filter_ in filters:
             self.info('filter', filter_, 'green')
-        # Check the 'test --name' option first, then 'test' from discover
-        names = list(tmt.base.Test._opt('names') or self.get('test', []))
+        # Names of tests selected by --test option
+        names = self.get('test', [])
         if names:
-            self.info('names', fmf.utils.listed(names), 'green')
+            self.info('tests', fmf.utils.listed(names), 'green')
+        # Check the 'test --link' option first, then from discover
+        links = list(tmt.base.Test._opt('link') or self.get('link', []))
+        for link_ in links:
+            self.info('link', link_, 'green')
 
         # Filter only modified tests if requested
         modified_only = self.get('modified-only')
         modified_url = self.get('modified-url')
         if modified_url:
             self.info('modified-url', modified_url, 'green')
             self.debug(f"Fetch also '{modified_url}' as 'reference'.")
@@ -215,16 +258,20 @@
 
         # Initialize the metadata tree, search for available tests
         self.debug(f"Check metadata tree in '{tree_path}'.")
         if self.opt('dry'):
             self._tests = []
             return
         tree = tmt.Tree(path=tree_path, context=self.step.plan._fmf_context())
-        self._tests = tree.tests(filters=filters, names=names,
-                                 conditions=["manual is False"])
+        self._tests = tree.tests(
+            filters=filters,
+            names=names,
+            conditions=["manual is False"],
+            unique=False,
+            links=links)
 
         # Prefix tests and handle library requires
         for test in self._tests:
             # Prefix test path with 'tests' and possible 'path' prefix
             test.path = os.path.join(prefix_path, test.path.lstrip('/'))
             # Check for possible required beakerlib libraries
             if test.require or test.recommend:
```

## tmt/steps/discover/shell.py

```diff
@@ -28,23 +28,25 @@
           test: ./smoke.sh
           path: /tests/shell
     """
 
     # Supported methods
     _methods = [tmt.steps.Method(name='shell', doc=__doc__, order=50)]
 
-    def show(self):
+    def show(self, keys=None):
         """ Show config details """
         super().show([])
         tests = self.get('tests')
         if tests:
             test_names = [test['name'] for test in tests]
             click.echo(tmt.utils.format('tests', test_names))
 
-    def wake(self):
+    def wake(self, keys=None):
+        """ Wake up the plugin, process data, apply options """
+        super().wake(keys=keys)
         # Check provided tests, default to an empty list
         if 'tests' not in self.data:
             self.data['tests'] = []
         self._tests = []
 
     def go(self):
         """ Discover available tests """
@@ -73,23 +75,18 @@
             # Apply default test duration unless provided
             if 'duration' not in data:
                 data['duration'] = tmt.base.DEFAULT_TEST_DURATION_L2
 
             # Create a simple fmf node, adjust its name
             tests.child(name, data)
 
-        # Copy directory tree (if defined) to the workdir
-        directory = self.step.plan.my_run.tree.root
-        testdir = os.path.join(self.workdir, 'tests')
-        if directory:
-            self.info('directory', directory, 'green')
-            self.debug("Copy '{}' to '{}'.".format(directory, testdir))
-            shutil.copytree(directory, testdir, symlinks=True)
-        else:
-            os.makedirs(testdir)
+        # Symlink tests directory to the plan work tree
+        testdir = os.path.join(self.workdir, "tests")
+        relative_path = os.path.relpath(self.step.plan.worktree, self.workdir)
+        os.symlink(relative_path, testdir)
 
         # Use a tmt.Tree to apply possible command line filters
         tests = tmt.Tree(tree=tests).tests(conditions=["manual is False"])
         self._tests = tests
 
     def tests(self):
         return self._tests
```

## tmt/steps/execute/__init__.py

```diff
@@ -184,20 +184,20 @@
 
 class ExecutePlugin(tmt.steps.Plugin):
     """ Common parent of execute plugins """
 
     # List of all supported methods aggregated from all plugins
     _supported_methods = []
 
+    # Common keys for all execute plugins
+    _common_keys = ["exit-first"]
+
     # Internal executor is the default implementation
     how = 'tmt'
 
-    # List of keys supported for all execute plugins
-    _keys = ['exit-first']
-
     @classmethod
     def base_command(cls, method_class=None, usage=None):
         """ Create base click command (common for all execute plugins) """
 
         # Prepare general usage message for the step
         if method_class:
             usage = Execute.usage(method_overview=usage)
@@ -218,25 +218,19 @@
     def options(cls, how=None):
         # Add option to exit after the first test failure
         options = [click.option(
             '-x', '--exit-first', is_flag=True,
             help='Stop execution after the first test failure.')]
         return options + super().options(how)
 
-    def show(self, keys=None):
-        keys = (keys or []) + self._keys
-        super().show(keys)
-
-    def wake(self, options=None):
-        options = (options or []) + self._keys
-        super().wake(options)
-
     def go(self):
         super().go()
-        self.info('exit-first', self.get('exit-first', default=False), 'green')
+        self.verbose(
+            'exit-first', self.get('exit-first', default=False),
+            'green', level=2)
 
     def data_path(self, test, filename=None, full=False, create=False):
         """
         Prepare full/relative test data directory/file path
 
         Construct test data directory path for given test, create it
         if requested and return the full or relative path to it (if
```

## tmt/steps/execute/detach.py

```diff
@@ -25,30 +25,29 @@
     # Supported methods
     _methods = [
         tmt.steps.Method(name='detach', doc=__doc__, order=60),
         tmt.steps.Method(name='shell.detach', doc=__doc__, order=90),
         tmt.steps.Method(name='beakerlib.detach', doc=__doc__, order=90),
         ]
 
+    # Supported keys
+    _keys = ["script"]
+
     @classmethod
     def options(cls, how=None):
         """ Prepare command line options for given method """
         options = []
         options.append(click.option(
             '-s', '--script', metavar='SCRIPT', multiple=True,
             help='Shell script to be executed as a test.'))
         return options + super().options(how)
 
-    def show(self):
-        """ Show discover details """
-        super().show(['script'])
-
-    def wake(self):
-        """ Wake up the plugin (override data with command line) """
-        super().wake(options=['script'])
+    def wake(self, keys=None):
+        """ Wake up the plugin, process data, apply options """
+        super().wake(keys=keys)
         # Make sure that 'script' is a list
         tmt.utils.listify(self.data, keys=['script'])
 
     def prepare_runner(self):
         """ Place the runner script to workdir """
         # Detect location of the runner and copy it to workdir
         script_path = os.path.join(os.path.dirname(__file__), RUNNER)
```

## tmt/steps/execute/internal.py

```diff
@@ -28,14 +28,24 @@
     \\"type\\": \\"{REBOOT_TYPE}\\",\
     \\"version\\": \\"0.1\\",\
     \\"{REBOOT_VARIABLE}\\": ${REBOOT_VARIABLE}\
 }}}}"
 """
 REBOOT_TEMPLATE_NAME = "reboot_template"
 
+FILE_SUBMIT_SCRIPT = """\
+#!/bin/sh
+FILENAME="$2"
+STORE_NAME="$BEAKERLIB_DIR/submitted/"
+[ -d $STORE_NAME ] || mkdir -p $STORE_NAME
+cp $FILENAME $STORE_NAME
+echo "File $FILENAME stored to $STORE_NAME"
+"""
+FILE_SUBMIT_NAME = "tmt-file-submit"
+
 
 class ExecuteInternal(tmt.steps.execute.ExecutePlugin):
     """
     Use the internal tmt executor to execute tests
 
     The internal tmt executor runs tests on the guest one by one, shows
     testing progress and supports interactive debugging as well. Test
@@ -46,14 +56,17 @@
     # Supported methods
     _methods = [
         tmt.steps.Method(name='tmt', doc=__doc__, order=50),
         tmt.steps.Method(name='shell.tmt', doc=__doc__, order=80),
         tmt.steps.Method(name='beakerlib.tmt', doc=__doc__, order=80),
         ]
 
+    # Supported keys
+    _keys = ["script", "interactive"]
+
     @classmethod
     def options(cls, how=None):
         """ Prepare command line options for given method """
         options = []
         # Shell script as a test
         options.append(click.option(
             '-s', '--script', metavar='SCRIPT', multiple=True,
@@ -64,23 +77,17 @@
             help='Run in interactive mode, do not capture output.'))
         # Disable interactive progress bar
         options.append(click.option(
             '--no-progress-bar', is_flag=True,
             help='Disable interactive progress bar showing the current test.'))
         return options + super().options(how)
 
-    def show(self, keys=None):
-        """ Show execute details """
-        keys = (keys or []) + ['script', 'interactive']
-        super().show(keys)
-
-    def wake(self, options=None):
-        """ Wake up the plugin (override data with command line) """
-        options = (options or []) + ['script', 'interactive']
-        super().wake(options=options)
+    def wake(self, keys=None):
+        """ Wake up the plugin, process data, apply options """
+        super().wake(keys=keys)
         # Make sure that script is a list
         tmt.utils.listify(self.data, keys=['script'])
 
     def _show_progress(self, progress, test_name, finish=False):
         """
         Show an interactive progress bar in non-verbose mode.
 
@@ -135,14 +142,16 @@
 
         # Create data directory, prepare environment
         data_directory = self.data_path(test, full=True, create=True)
         environment = test.environment
         if test.framework == 'beakerlib':
             environment = environment.copy()
             environment['BEAKERLIB_DIR'] = data_directory
+            environment['BEAKERLIB_COMMAND_SUBMIT_LOG'] = (
+                f"bash {self.step.workdir}/{FILE_SUBMIT_NAME}")
 
         # Prepare the test command (use default options for shell tests)
         if test.framework == "shell":
             command = f"{tmt.utils.SHELL_OPTIONS}; {test.test}"
         else:
             command = test.test
 
@@ -278,17 +287,20 @@
         self._previous_output_length = 0
 
         # Nothing to do in dry mode
         if self.opt('dry'):
             self._results = []
             return
 
-        # For each guest execute all tests
+        # Prepare tests and helper scripts, check options
         tests = self.prepare_tests()
         exit_first = self.get('exit-first', default=False)
+        self.step.write(FILE_SUBMIT_NAME, FILE_SUBMIT_SCRIPT)
+
+        # For each guest execute all tests
         for guest in self.step.plan.provision.guests():
             with self._setup_reboot(guest):
                 # Push workdir to guest and execute tests
                 guest.push()
                 index = 0
                 while index < len(tests):
                     test = tests[index]
```

## tmt/steps/finish/shell.py

```diff
@@ -19,14 +19,17 @@
     Use the 'order' attribute to select in which order finishing tasks
     should happen if there are multiple configs. Default order is '50'.
     """
 
     # Supported methods
     _methods = [tmt.steps.Method(name='shell', doc=__doc__, order=50)]
 
+    # Supported keys
+    _keys = ["script"]
+
     @classmethod
     def options(cls, how=None):
         """ Finish command line options """
         return [
             click.option(
                 '-s', '--script', metavar='SCRIPT',
                 help='Shell script to be executed.')
@@ -34,21 +37,17 @@
 
     def default(self, option, default=None):
         """ Return default data for given option """
         if option == 'script':
             return []
         return default
 
-    def show(self):
-        """ Show provided scripts """
-        super().show(['script'])
-
-    def wake(self, data=None):
-        """ Override options and wake up the guest """
-        super().wake(['script'])
+    def wake(self, keys=None):
+        """ Wake up the plugin, process data, apply options """
+        super().wake(keys=keys)
 
         # Convert to list if single script provided
         tmt.utils.listify(self.data, keys=['script'])
 
     def go(self, guest):
         """ Perform finishing tasks on given guest """
         super().go()
```

## tmt/steps/prepare/ansible.py

```diff
@@ -17,58 +17,61 @@
 
         prepare:
             how: ansible
             playbook:
               - playbook/one.yml
               - playbook/two.yml
               - playbook/three.yml
+            extra-args: '-vvv'
 
     The playbook path should be relative to the metadata tree root.
     Use 'order' attribute to select in which order preparation should
     happen if there are multiple configs. Default order is '50'.
     Default order of required packages installation is '70'.
     """
 
     # Supported methods
     _methods = [tmt.steps.Method(name='ansible', doc=__doc__, order=50)]
 
+    # Supported keys
+    _keys = ["playbook", "extra-args"]
+
     def __init__(self, step, data):
         """ Store plugin name, data and parent step """
         super().__init__(step, data)
         # Rename plural playbooks to singular
         if 'playbooks' in self.data:
             self.data['playbook'] = self.data.pop('playbooks')
 
     @classmethod
     def options(cls, how=None):
         """ Prepare command line options """
         return [
             click.option(
                 '-p', '--playbook', metavar='PLAYBOOK', multiple=True,
-                help='Path to an ansible playbook to run.')
+                help='Path to an ansible playbook to run.'),
+            click.option(
+                '--extra-args', metavar='EXTRA-ARGS',
+                help='Optional arguments for ansible-playbook.')
             ] + super().options(how)
 
     def default(self, option, default=None):
         """ Return default data for given option """
         if option == 'playbook':
             return []
         return default
 
-    def show(self):
-        """ Show provided playbooks """
-        super().show(['playbook'])
-
-    def wake(self, data=None):
-        """ Override options and wake up the guest """
-        super().wake(['playbook'])
+    def wake(self, keys=None):
+        """ Wake up the plugin, process data, apply options """
+        super().wake(keys=keys)
 
         # Convert to list if necessary
         tmt.utils.listify(self.data, keys=['playbook'])
 
     def go(self, guest):
         """ Prepare the guests """
         super().go()
 
         # Apply each playbook on the guest
         for playbook in self.get('playbook'):
             self.info('playbook', playbook, 'green')
-            guest.ansible(playbook)
+            guest.ansible(playbook, self.get('extra-args'))
```

## tmt/steps/prepare/install.py

```diff
@@ -47,14 +47,17 @@
     happen if there are multiple configs. Default order is '50'.
     Default order of required packages installation is '70'.
     """
 
     # Supported methods
     _methods = [tmt.steps.Method(name='install', doc=__doc__, order=50)]
 
+    # Supported keys
+    _keys = ["package", "directory", "copr", "exclude", "missing"]
+
     @classmethod
     def options(cls, how=None):
         """ Prepare command line options """
         return [
             click.option(
                 '-p', '--package', metavar='PACKAGE', multiple=True,
                 help='Package name or path to rpm to be installed.'),
@@ -77,26 +80,22 @@
         """ Return default data for given option """
         if option == 'missing':
             return 'fail'
         if option == 'exclude':
             return []
         return default
 
-    def show(self):
-        """ Show provided scripts """
-        super().show(['package', 'directory', 'copr', 'exclude', 'missing'])
-
-    def wake(self, data=None):
-        """ Override options and wake up the guest """
-        super().wake(['package', 'directory', 'copr', 'exclude', 'missing'])
+    def wake(self, keys=None):
+        """ Wake up the plugin, process data, apply options """
+        super().wake(keys=keys)
 
         # Convert to list if necessary
         tmt.utils.listify(
-            self.data, split=True, keys=[
-                'package', 'directory', 'copr', 'exclude'])
+            self.data, split=True,
+            keys=['package', 'directory', 'copr', 'exclude'])
 
     def enable_copr_epel6(self, copr, guest):
         """ Manually enable copr repositories for epel6 """
         # Parse the copr repo name
         matched = re.match("^(@)?([^/]+)/([^/]+)$", copr)
         if not matched:
             raise tmt.utils.PrepareError(f"Invalid copr repository '{copr}'.")
```

## tmt/steps/prepare/shell.py

```diff
@@ -22,14 +22,17 @@
     happen if there are multiple configs. Default order is '50'.
     Default order of required packages installation is '70'.
     """
 
     # Supported methods
     _methods = [tmt.steps.Method(name='shell', doc=__doc__, order=50)]
 
+    # Supported keys
+    _keys = ["script"]
+
     @classmethod
     def options(cls, how=None):
         """ Prepare command line options """
         return [
             click.option(
                 '-s', '--script', metavar='SCRIPT',
                 help='Shell script to be executed.')
@@ -37,21 +40,17 @@
 
     def default(self, option, default=None):
         """ Return default data for given option """
         if option == 'script':
             return []
         return default
 
-    def show(self):
-        """ Show provided scripts """
-        super().show(['script'])
-
-    def wake(self, data=None):
-        """ Override options and wake up the guest """
-        super().wake(['script'])
+    def wake(self, keys=None):
+        """ Wake up the plugin, process data, apply options """
+        super().wake(keys=keys)
 
         # Convert to list if single script provided
         tmt.utils.listify(self.data, keys=['script'])
 
     def go(self, guest):
         """ Prepare the guests """
         super().go()
```

## tmt/steps/provision/__init__.py

```diff
@@ -167,22 +167,22 @@
             help='Use specified method for provisioning.')
         def provision(context, **kwargs):
             context.obj.steps.add('provision')
             Provision._save_context(context)
 
         return provision
 
-    def wake(self, options=None, data=None):
+    def wake(self, keys=None, data=None):
         """
         Wake up the plugin
 
         Override data with command line options.
         Wake up the guest based on provided guest data.
         """
-        super().wake(options)
+        super().wake(keys=keys)
 
     def guest(self):
         """
         Return provisioned guest
 
         Each ProvisionPlugin has to implement this method.
         Should return a provisioned Guest() instance.
@@ -357,14 +357,19 @@
     def _ansible_verbosity(self):
         """ Prepare verbose level based on the --debug option count """
         if self.opt('debug') < 3:
             return ''
         else:
             return ' -' + (self.opt('debug') - 2) * 'v'
 
+    @staticmethod
+    def _ansible_extra_args(extra_args):
+        """ Prepare extra arguments for ansible-playbook"""
+        return '' if extra_args is None else str(extra_args)
+
     def _ansible_summary(self, output):
         """ Check the output for ansible result summary numbers """
         if not output:
             return
         keys = 'ok changed unreachable failed skipped rescued ignored'.split()
         for key in keys:
             matched = re.search(rf'^.*\s:\s.*{key}=(\d+).*$', output, re.M)
@@ -391,22 +396,24 @@
         environment.update(self.parent.plan.environment)
         # Prepend with export and run as a separate command.
         if not environment:
             return ''
         return 'export {}; '.format(
             ' '.join(tmt.utils.shell_variables(environment)))
 
-    def ansible(self, playbook):
+    def ansible(self, playbook, extra_args=None):
         """ Prepare guest using ansible playbook """
         playbook = self._ansible_playbook_path(playbook)
         stdout, stderr = self.run(
             f'{self._export_environment()}'
             f'stty cols {tmt.utils.OUTPUT_WIDTH}; ansible-playbook '
             f'--ssh-common-args="{self._ssh_options(join=True)}" '
-            f'{self._ansible_verbosity()} -i {self._ssh_guest()}, {playbook}',
+            f'{self._ansible_verbosity()} '
+            f'{self._ansible_extra_args(extra_args)} -i {self._ssh_guest()},'
+            f' {playbook}',
             cwd=self.parent.plan.worktree)
         self._ansible_summary(stdout)
 
     def execute(self, command, **kwargs):
         """
         Execute command on the guest
 
@@ -517,15 +524,24 @@
         rebooted by way which is not clean in sense that data can be
         lost. When set to False reboot should be done gracefully.
         """
         if hard:
             raise tmt.utils.ProvisionError(
                 "Method does not support hard reboot.")
 
-        self.execute("reboot")
+        try:
+            self.execute("reboot")
+        except tmt.utils.RunError as error:
+            # Connection can be closed by the remote host even before the
+            # reboot command is completed. Let's ignore such errors.
+            if error.returncode == 255:
+                self.debug(
+                    f"Seems the connection was closed too fast, ignoring.")
+            else:
+                raise
         return self.reconnect()
 
     def reconnect(self):
         """ Ensure the connection to the guest is working after reboot """
         # Try to wait for machine to really shutdown sshd
         time.sleep(SSH_INITIAL_WAIT_TIME)
         self.debug("Wait for a connection to the guest.")
```

## tmt/steps/provision/connect.py

```diff
@@ -33,14 +33,17 @@
 
     # Guest instance
     _guest = None
 
     # Supported methods
     _methods = [tmt.steps.Method(name='connect', doc=__doc__, order=50)]
 
+    # Supported keys
+    _keys = ["guest", "key", "user", "password", "port"]
+
     @classmethod
     def options(cls, how=None):
         """ Prepare command line options for connect """
         return [
             click.option(
                 '-g', '--guest', metavar='GUEST',
                 help='Select remote host to connect to (hostname or ip).'),
@@ -62,21 +65,17 @@
         """ Return default data for given option """
         # User root as the default user
         if option == 'user':
             return 'root'
         # No other defaults available
         return default
 
-    def show(self):
-        """ Show provision details """
-        super().show(['guest', 'key', 'user', 'password', 'port'])
-
-    def wake(self, data=None):
-        """ Override options and wake up the guest """
-        super().wake(['guest', 'key', 'user', 'password', 'port'])
+    def wake(self, keys=None, data=None):
+        """ Wake up the plugin, process data, apply options """
+        super().wake(keys=keys, data=data)
         if data:
             self._guest = tmt.Guest(data, name=self.name, parent=self.step)
 
     def go(self):
         """ Prepare the connection """
         super().go()
```

## tmt/steps/provision/local.py

```diff
@@ -21,16 +21,17 @@
 
     # Guest instance
     _guest = None
 
     # Supported methods
     _methods = [tmt.steps.Method(name='local', doc=__doc__, order=50)]
 
-    def wake(self, data=None):
-        """ Override options and wake up the guest """
+    def wake(self, keys=None, data=None):
+        """ Wake up the plugin, process data, apply options """
+        super().wake(keys=keys, data=data)
         if data:
             self._guest = GuestLocal(data, name=self.name, parent=self.step)
 
     def go(self):
         """ Provision the container """
         super().go()
 
@@ -46,21 +47,23 @@
         """ List of required packages needed for workdir sync """
         return GuestLocal.requires()
 
 
 class GuestLocal(tmt.Guest):
     """ Local Host """
 
-    def ansible(self, playbook):
+    def ansible(self, playbook, extra_args=None):
         """ Prepare localhost using ansible playbook """
         playbook = self._ansible_playbook_path(playbook)
         stdout, stderr = self.run(
             f'sudo sh -c "stty cols {tmt.utils.OUTPUT_WIDTH}; '
-            f'{self._export_environment()}ansible-playbook'
-            f'{self._ansible_verbosity()} -c local -i localhost, {playbook}"')
+            f'{self._export_environment()}ansible-playbook '
+            f'{self._ansible_verbosity()} '
+            f'{self._ansible_extra_args(extra_args)} -c local -i localhost,'
+            f' {playbook}"')
         self._ansible_summary(stdout)
 
     def execute(self, command, **kwargs):
         """ Execute command on localhost """
         # Prepare the environment (plan/cli variables override)
         environment = dict()
         environment.update(kwargs.pop('env', dict()))
```

## tmt/steps/provision/podman.py

```diff
@@ -19,15 +19,15 @@
     In order to always pull the fresh container image use 'pull: true'.
     """
 
     # Guest instance
     _guest = None
 
     # Supported keys
-    _keys = ['image', 'container', 'pull']
+    _keys = ["image", "container", "pull"]
 
     # Supported methods
     _methods = [tmt.steps.Method(name='container', doc=__doc__, order=50)]
 
     @classmethod
     def options(cls, how=None):
         """ Prepare command line options for connect """
@@ -47,21 +47,17 @@
         """ Return default data for given option """
         # User 'fedora' as a default image
         if option == 'image':
             return 'fedora'
         # No other defaults available
         return default
 
-    def show(self):
-        """ Show provision details """
-        super().show(self._keys)
-
-    def wake(self, data=None):
-        """ Override options and wake up the guest """
-        super().wake(self._keys)
+    def wake(self, keys=None, data=None):
+        """ Wake up the plugin, process data, apply options """
+        super().wake(keys=keys, data=data)
         # Wake up podman instance
         if data:
             guest = GuestContainer(data, name=self.name, parent=self.step)
             guest.wake()
             self._guest = guest
 
     def go(self):
@@ -156,25 +152,26 @@
         if not hard:
             raise tmt.utils.ProvisionError(
                 "Containers do not support soft reboot, they can only be "
                 "stopped and started again (hard reboot).")
         self.podman(['container', 'restart', self.container])
         return self.reconnect()
 
-    def ansible(self, playbook):
+    def ansible(self, playbook, extra_args=None):
         """ Prepare container using ansible playbook """
         playbook = self._ansible_playbook_path(playbook)
         # As non-root we must run with podman unshare
         podman_unshare = 'podman unshare ' if os.geteuid() != 0 else ''
         stdout, stderr = self.run(
             f'stty cols {tmt.utils.OUTPUT_WIDTH}; '
             f'{self._export_environment()}'
             f'{podman_unshare}ansible-playbook '
-            f'{self._ansible_verbosity()} -c podman -i {self.container}, '
-            f'{playbook}',
+            f'{self._ansible_verbosity()} '
+            f'{self._ansible_extra_args(extra_args)} '
+            f'-c podman -i {self.container}, {playbook}',
             cwd=self.parent.plan.worktree)
         self._ansible_summary(stdout)
 
     def podman(self, command, **kwargs):
         """ Run given command via podman """
         return self.run(['podman'] + command, shell=False, **kwargs)
```

## tmt/steps/provision/testcloud.py

```diff
@@ -32,39 +32,41 @@
 
 # Testcloud cache to our tmt's workdir root
 TESTCLOUD_DATA = os.path.join(WORKDIR_ROOT, 'testcloud')
 TESTCLOUD_IMAGES = os.path.join(TESTCLOUD_DATA, 'images')
 
 # Userdata for cloud-init
 USER_DATA = """#cloud-config
-password: %s
 chpasswd:
+  list: |
+    {user_name}:%s
   expire: false
 users:
   - default
   - name: {user_name}
 ssh_authorized_keys:
   - {public_key}
 ssh_pwauth: true
 disable_root: false
 runcmd:
   - sed -i -e '/^.*PermitRootLogin/s/^.*$/PermitRootLogin yes/'
+    -e '/^.*UseDNS/s/^.*$/UseDNS no/'
+    -e '/^.*GSSAPIAuthentication/s/^.*$/GSSAPIAuthentication no/'
     /etc/ssh/sshd_config
   - systemctl reload sshd
-  - [sh, -c, 'mkdir -p /etc/systemd/network/']
-  # echo multiple times, sh echo doesn't support newline
-  - [sh, -c, 'if [ ! -f /etc/systemd/network/20-tc-usernet.network ];
-  then echo "[Match]" >> /etc/systemd/network/20-tc-usernet.network &&
+  - [sh, -c, 'if [ ! -f /etc/systemd/network/20-tc-usernet.network ] &&
+  systemctl status systemd-networkd | grep -q "enabled;\\svendor\\spreset:\\senabled";
+  then mkdir -p /etc/systemd/network/ &&
+  echo "[Match]" >> /etc/systemd/network/20-tc-usernet.network &&
   echo "Name=en*" >> /etc/systemd/network/20-tc-usernet.network &&
   echo "[Network]" >> /etc/systemd/network/20-tc-usernet.network &&
   echo "DHCP=yes" >> /etc/systemd/network/20-tc-usernet.network; fi']
   - [sh, -c, 'if systemctl status systemd-networkd |
   grep -q "enabled;\\svendor\\spreset:\\senabled"; then
   systemctl restart systemd-networkd; fi']
-  # CentOS and RHEL 8 keeps waiting before restarting sshd causing delays
   - [sh, -c, 'if cat /etc/os-release |
   grep -q platform:el8; then systemctl restart sshd; fi']
 """
 
 # Libvirt domain XML template related variables
 DOMAIN_TEMPLATE_NAME = 'domain-template.jinja'
 DOMAIN_TEMPLATE_FILE = os.path.join(TESTCLOUD_DATA, DOMAIN_TEMPLATE_NAME)
@@ -107,17 +109,18 @@
     </disk>
     <disk type='file' device='disk'>
       <driver name='qemu' type='raw' cache='unsafe'/>
       <source file="{{ seed }}"/>
       <target dev='vdb' bus='virtio'/>
       <address type='pci' domain='0x0000' bus='0x00' slot='0x08' function='0x0'/>
     </disk>
-    <interface type='user'>
+    <interface type='{{ network_type }}'>
       <mac address="{{ mac_address }}"/>
-      <ip family='ipv4' address='172.17.2.0' prefix='24'/>
+      {{ network_source }}
+      {{ ip_setup }}
       <model type='virtio'/>
       <address type='pci' domain='0x0000' bus='0x00' slot='0x03' function='0x0'/>
     </interface>
     <serial type='pty'>
       <target port='0'/>
     </serial>
     <console type='pty'>
@@ -135,14 +138,17 @@
 </domain>
 """
 
 # VM defaults
 DEFAULT_BOOT_TIMEOUT = 60      # seconds
 DEFAULT_CONNECT_TIMEOUT = 60   # seconds
 
+# SSH key type, set None for ssh-keygen default one
+SSH_KEYGEN_TYPE = "ecdsa"
+
 
 class ProvisionTestcloud(tmt.steps.provision.ProvisionPlugin):
     """
     Local virtual machine using testcloud
 
     Minimal config which uses the latest fedora image:
 
@@ -179,14 +185,17 @@
     _guest = None
 
     # Supported methods
     _methods = [
         tmt.steps.Method(name='virtual.testcloud', doc=__doc__, order=50),
         ]
 
+    # Supported keys
+    _keys = ["image", "user", "memory", "disk", "connection"]
+
     @classmethod
     def options(cls, how=None):
         """ Prepare command line options for testcloud """
         return [
             click.option(
                 '-i', '--image', metavar='IMAGE',
                 help='Select image to be used. Provide a short name, '
@@ -196,35 +205,36 @@
                 help='Set available memory in MB, 2048 MB by default.'),
             click.option(
                 '-D', '--disk', metavar='MEMORY',
                 help='Specify disk size in GB, 10 GB by default.'),
             click.option(
                 '-u', '--user', metavar='USER',
                 help='Username to use for all guest operations.'),
+            click.option(
+                '-c', '--connection',
+                type=click.Choice(['session', 'system']),
+                help="What session type to use, 'session' by default."),
             ] + super().options(how)
 
     def default(self, option, default=None):
         """ Return default data for given option """
         defaults = {
             'user': 'root',
             'memory': 2048,
             'disk': 10,
             'image': 'fedora',
+            'connection': 'session',
             }
         if option in defaults:
             return defaults[option]
         return default
 
-    def show(self):
-        """ Show provision details """
-        super().show(['image', 'user', 'memory', 'disk'])
-
-    def wake(self, data=None):
-        """ Override options and wake up the guest """
-        super().wake(['image', 'memory', 'disk', 'user'])
+    def wake(self, keys=None, data=None):
+        """ Wake up the plugin, process data, apply options """
+        super().wake(keys=keys, data=data)
 
         # Convert memory and disk to integers
         for key in ['memory', 'disk']:
             if isinstance(self.get(key), str):
                 self.data[key] = int(self.data[key])
 
         # Wake up testcloud instance
@@ -235,20 +245,22 @@
 
     def go(self):
         """ Provision the testcloud instance """
         super().go()
 
         # Give info about provided data
         data = dict()
-        for key in ['image', 'user', 'memory', 'disk']:
+        for key in ['image', 'user', 'memory', 'disk', 'connection']:
             data[key] = self.get(key)
             if key == 'memory':
                 self.info('memory', f"{self.get('memory')} MB", 'green')
             elif key == 'disk':
                 self.info('disk', f"{self.get('disk')} GB", 'green')
+            elif key == 'connection':
+                self.verbose(key, data[key], 'green')
             else:
                 self.info(key, data[key], 'green')
 
         # Create a new GuestTestcloud instance and start it
         self._guest = GuestTestcloud(data, name=self.name, parent=self.step)
         self._guest.start()
 
@@ -279,14 +291,15 @@
 
     The following keys are expected in the 'data' dictionary::
 
         image ...... qcov image name or url
         user ....... user name to log in
         memory ..... memory size for vm
         disk ....... disk size for vm
+        connection . either session (default) or system, to be passed to qemu
     """
 
     def _get_url(self, url, message):
         """ Get url, retry when fails, return response """
         timeout = DEFAULT_CONNECT_TIMEOUT
         wait = 1
         while True:
@@ -368,42 +381,48 @@
         super().load(data)
         self.image = None
         self.image_url = data.get('image')
         self.instance = None
         self.instance_name = data.get('instance')
         self.memory = data.get('memory')
         self.disk = data.get('disk')
+        self.connection = data.get('connection')
 
     def save(self):
         """ Save guest data for future wake up """
         data = super().save()
         data['instance'] = self.instance_name
         data['image'] = self.image_url
+        data['connection'] = self.connection
         return data
 
     def wake(self):
         """ Wake up the guest """
         self.debug(
             f"Waking up testcloud instance '{self.instance_name}'.",
             level=2, shift=0)
         self.prepare_config()
         self.image = testcloud.image.Image(self.image_url)
         self.instance = testcloud.instance.Instance(
             self.instance_name, image=self.image,
-            connection='qemu:///session')
+            connection=f"qemu:///{self.connection}")
 
-    def prepare_ssh_key(self):
+    def prepare_ssh_key(self, key_type=None):
         """ Prepare ssh key for authentication """
         # Create ssh key paths
-        self.key = os.path.join(self.workdir, 'id_rsa')
-        self.pubkey = os.path.join(self.workdir, 'id_rsa.pub')
+        key_name = "id_{}".format(key_type if key_type is not None else 'rsa')
+        self.key = os.path.join(self.workdir, key_name)
+        self.pubkey = os.path.join(self.workdir, f'{key_name}.pub')
 
         # Generate ssh key
         self.debug('Generating an ssh key.')
-        self.run(["ssh-keygen", "-f", self.key, "-N", ""], shell=False)
+        command = ["ssh-keygen", "-f", self.key, "-N", ""]
+        if key_type is not None:
+            command.extend(["-t", key_type])
+        self.run(command, shell=False)
         with open(self.pubkey, 'r') as pubkey:
             self.config.USER_DATA = USER_DATA.format(
                 user_name=self.user, public_key=pubkey.read())
 
     def prepare_config(self):
         """ Prepare common configuration """
         import_testcloud()
@@ -457,15 +476,15 @@
 
         # Create instance
         _, run_id = os.path.split(self.parent.plan.my_run.workdir)
         self.instance_name = self._random_name(
             prefix="tmt-{0}-".format(run_id[-3:]))
         self.instance = testcloud.instance.Instance(
             name=self.instance_name, image=self.image,
-            connection='qemu:///session')
+            connection=f"qemu:///{self.connection}")
         self.verbose('name', self.instance_name, 'green')
 
         # Decide which networking setup to use
         # Autodetect works with libguestfs python bindings
         # We fall back to basic heuristics based on file name
         # without that installed (eg. from pypi).
         # https://bugzilla.redhat.com/show_bug.cgi?id=1075594
@@ -476,15 +495,15 @@
                 r'(rhel|centos).*-7', self.image_url.lower())
             if match_legacy:
                 self.instance.pci_net = "e1000"
             else:
                 self.instance.pci_net = "virtio-net-pci"
 
         # Prepare ssh key
-        self.prepare_ssh_key()
+        self.prepare_ssh_key(SSH_KEYGEN_TYPE)
 
         # Boot the virtual machine
         self.info('progress', 'booting...', 'cyan')
         self.instance.ram = self.memory
         self.instance.disk_size = self.disk
         try:
             self.instance.prepare()
```

## tmt/steps/report/html.py

```diff
@@ -161,14 +161,17 @@
             how: html
             open: true
     """
 
     # Supported methods
     _methods = [tmt.steps.Method(name='html', doc=__doc__, order=50)]
 
+    # Supported keys
+    _keys = ["open"]
+
     @classmethod
     def options(cls, how=None):
         """ Prepare command line options for the html report """
         return [
             click.option(
                 '-o', '--open', is_flag=True,
                 help='Open results in your preferred web browser.'),
```

## tmt/steps/report/junit.py

```diff
@@ -40,15 +40,16 @@
     When FILE is not specified output is written to the 'junit.xml'
     located in the current workdir.
     """
 
     # Supported methods
     _methods = [tmt.steps.Method(name='junit', doc=__doc__, order=50)]
 
-    _keys = ['file']
+    # Supported keys
+    _keys = ["file"]
 
     @classmethod
     def options(cls, how=None):
         """ Prepare command line options for connect """
         return [
             click.option(
                 '--file', metavar='FILE',
```

## Comparing `tmt/plugins.py` & `tmt/plugins/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # coding: utf-8
 
-""" Handle Steps Plugins """
+""" Handle Plugins """
 
 import importlib
 import os
 import pkgutil
 import sys
 
 import fmf
@@ -18,14 +18,17 @@
     """ Explore all available plugins """
 
     # Check all tmt steps for native plugins
     root = os.path.dirname(os.path.realpath(tmt.__file__))
     for step in tmt.steps.STEPS:
         for module in discover(os.path.join(root, 'steps', step)):
             import_(f'tmt.steps.{step}.{module}')
+    # Check for possible plugins in the 'plugins' directory
+    for module in discover(os.path.join(root, 'plugins')):
+        import_(f'tmt.plugins.{module}')
 
     # Check environment variable for user plugins
     try:
         paths = [
             os.path.realpath(os.path.expandvars(os.path.expanduser(path)))
             for path in os.environ['TMT_PLUGINS'].split(' ')]
     except KeyError:
```

## Comparing `tmt-1.8.0.data/scripts/tmt` & `tmt-1.9.0.data/scripts/tmt`

 * *Files identical despite different names*

## Comparing `tmt-1.8.0.dist-info/LICENSE` & `tmt-1.9.0.dist-info/LICENSE`

 * *Files 14% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 
 MIT License
 
-Copyright (c) 2019 Red Hat, Inc.
+Copyright Red Hat
 
 Permission is hereby granted, free of charge, to any person
 obtaining a copy of this software and associated documentation
 files (the "Software"), to deal in the Software without
 restriction, including without limitation the rights to use, copy,
 modify, merge, publish, distribute, sublicense, and/or sell copies
 of the Software, and to permit persons to whom the Software is
```

## Comparing `tmt-1.8.0.dist-info/METADATA` & `tmt-1.9.0.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: tmt
-Version: 1.8.0
+Version: 1.9.0
 Summary: Test Management Tool
 Home-page: https://github.com/psss/tmt
 Author: Petr Splichal
 Author-email: psplicha@redhat.com
 Maintainer: Petr Splichal
 Maintainer-email: psplicha@redhat.com
 License: MIT
@@ -30,24 +30,24 @@
 Requires-Dist: mock ; extra == 'all'
 Requires-Dist: nitrate ; extra == 'all'
 Requires-Dist: pre-commit ; extra == 'all'
 Requires-Dist: pytest ; extra == 'all'
 Requires-Dist: python-bugzilla ; extra == 'all'
 Requires-Dist: python-coveralls ; extra == 'all'
 Requires-Dist: requre ; extra == 'all'
-Requires-Dist: sphinx ; extra == 'all'
+Requires-Dist: sphinx (>=3) ; extra == 'all'
 Requires-Dist: sphinx-rtd-theme ; extra == 'all'
 Requires-Dist: testcloud (>=0.6.1) ; extra == 'all'
 Provides-Extra: convert
 Requires-Dist: markdown ; extra == 'convert'
 Requires-Dist: nitrate ; extra == 'convert'
 Requires-Dist: python-bugzilla ; extra == 'convert'
 Provides-Extra: docs
 Requires-Dist: mock ; extra == 'docs'
-Requires-Dist: sphinx ; extra == 'docs'
+Requires-Dist: sphinx (>=3) ; extra == 'docs'
 Requires-Dist: sphinx-rtd-theme ; extra == 'docs'
 Provides-Extra: provision
 Requires-Dist: testcloud (>=0.6.1) ; extra == 'provision'
 Provides-Extra: report-html
 Requires-Dist: jinja2 ; extra == 'report-html'
 Provides-Extra: report-junit
 Requires-Dist: junit-xml ; extra == 'report-junit'
@@ -435,20 +435,21 @@
 
 Petr plchal, Miro Hronok, Alexander Sosedkin, Luk Zachar,
 Petr Menk, Leo Pol, Miroslav Vadkerti, Pavel Valena, Jakub
 Heger, Honza Hork, Rachel Sibley, Frantiek Neas, Michal
 Ruprich, Martin Kyral, Milo Prchlk, Tom Navrtil, Frantiek
 Lachman, Patrik Kis, Ondrej Mosnek, Andrea Fickov, Denis
 Karpelevich, Michal Srb, Jan otka, Artem Zhukov, Vinzenz
-Feenstra, Inessa Vasilevskaya, tpn Nmec, Robin Hack and Yulia
-Kopkova.
+Feenstra, Inessa Vasilevskaya, tpn Nmec, Robin Hack, Yulia
+Kopkova, Ondrej Mori, Martin Zelen, Karel rot and Frantiek
+Zatloukal.
 
 
 Copyright
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-Copyright (c) 2019 Red Hat, Inc.
+Copyright Red Hat
 
 This program is free software; you can redistribute it and/or
 modify it under the terms of the MIT License.
```

## Comparing `tmt-1.8.0.dist-info/RECORD` & `tmt-1.9.0.dist-info/RECORD`

 * *Files 24% similar despite different names*

```diff
@@ -1,40 +1,41 @@
-tmt/__init__.py,sha256=_2a5y3dboudsTTywEYtuk3pTvKOYDUdcBaQcXb8faqc,325
+tmt/__init__.py,sha256=-HT608ncpCmx3t5rXykhrOAIILTaI3Yr_rtzdE_oVjo,325
 tmt/__main__.py,sha256=Y0JJswjtPmHQg5XwHzYlIEG4iTSrue58wrmRnR5rKs0,31
-tmt/base.py,sha256=g_dMhxfADT4BGhIQWiM2gM2Zs7Qu0fjEiuKkjZnVXRg,72381
+tmt/base.py,sha256=u-M7EhkPv7mLqBSBYB1nszUfugBHXGemUYfzfgk-MBA,75231
 tmt/beakerlib.py,sha256=INPXVdWC0u3eaxmkkVAbGUQJJYyLmXw6yka2Kg-KRY4,11753
-tmt/cli.py,sha256=ab5d-2LecKoMnx7QLz9nV86ZM147l2IkWcxkTumoFpE,36709
+tmt/cli.py,sha256=kr2rGYu4DGQwNW7k7NxO--kMgOuZI5Kq8TcMHVEG2tE,37553
 tmt/convert.py,sha256=ksoacnqxtaCwlGAyuWYIA4z3FMIyHt-PYSfQ9lXSxz8,29264
 tmt/export.py,sha256=j0BoKnvLtZBHCiYrsEcJgkaUG8B1x9HNEJw6jO1uRlM,25782
 tmt/options.py,sha256=9-UB4y1NxjotWR0JGVLs64A8aBsi3fwB-fOsOnip6ho,5608
-tmt/plugins.py,sha256=vfR-HqNWEPx5IweAYWAauD5fNTAlDm87XHJqfkev7u8,1540
 tmt/templates.py,sha256=AjFWL3MlqHUZ7q-VwvsnGdFG2AqYiiFnvsnLm9P9i4k,3091
-tmt/utils.py,sha256=OZx6xWyIk6_3AcMs6N7_pk-sczxzPApf4QIvl7v7E4I,57652
-tmt/steps/__init__.py,sha256=-7LMhaflsKZmhe1W8nhPYigDsFuJ7XVXwdttpRmBBtw,22080
-tmt/steps/discover/__init__.py,sha256=UKyB5_yAyY34LFPIWunSYoQCrpcutDXH4V9ItD6uOdw,7284
-tmt/steps/discover/fmf.py,sha256=f_R64eLvCotn1u4mGB0mSx4TtfcUZ-ZZy8jFNV2faL0,9443
-tmt/steps/discover/shell.py,sha256=waAjGIDrbqqFmT9dhfF1IN6JaHjZEDQTdYy_5wk9dW0,3149
-tmt/steps/execute/__init__.py,sha256=inlHJXvRvFPFJaiKe_FbUzF5jQVVYOu5NW3rRo_JnQI,12581
-tmt/steps/execute/detach.py,sha256=bzGh9H9MfrK4SnYp4Hb20-SD86NgpCU1ydMNQG4aDQI,5717
-tmt/steps/execute/internal.py,sha256=xR5rlCFMLz5rxoqdFK-2NOe2FBo5ochYBGBUaH_NA9Y,12739
+tmt/utils.py,sha256=HLxhKi9zkZbeTR1W7keboPI0e2woiL2LjfrHmCyKd0o,60026
+tmt/plugins/__init__.py,sha256=kDVtw-yJ_85iqOUB3TOpuBuLX2EKdZji8OPYpeYzi3E,1694
+tmt/steps/__init__.py,sha256=-pD3h06D2cGc7hJlMNAqcDTB7QCurU9yX-JQW5sxiCw,22587
+tmt/steps/discover/__init__.py,sha256=8Lj7MK81c-dVOmsCvA0pvu3v1xLna-nA7bj629wyphk,8448
+tmt/steps/discover/fmf.py,sha256=1rr3n85cWNKbG0FN0P9aC93b3_yAd6yJXKEoEoRRUrQ,11362
+tmt/steps/discover/shell.py,sha256=KYQRnObw9v0ExrKSnQ0F25CMxU3ZAcNvPScT0DxrnS4,3076
+tmt/steps/execute/__init__.py,sha256=xLTTHmbGQTKk8LSSviIU6r4ewP5EiQCtiixc-yyp-s4,12402
+tmt/steps/execute/detach.py,sha256=D6HfmQhWbPJHVfO30QyMvqvZo16F76uV8c9scNzGvpk,5667
+tmt/steps/execute/internal.py,sha256=Gmb23wwobMsjwXzgaUXNCI_dg9-85OvcU7p-VrGP9C4,13059
 tmt/steps/execute/run.sh,sha256=YMGpwi1u19zeaccMPvjI_pBHjKVHbj-fDJkC7NQuVBw,7445
 tmt/steps/finish/__init__.py,sha256=YWJ619SPhVbR-5BNP2OkBiiHEe9mKdvgeOvMZgQxNZE,3528
-tmt/steps/finish/shell.py,sha256=aliOzG1615yr8vnjlXQkkvtcQ9u6_oFvZZkyu5GM2ds,1789
+tmt/steps/finish/ansible.py,sha256=FaQEU84lRYYLTduBSaBdJ8sTVC94SyEFmRzeIm4rYg8,997
+tmt/steps/finish/shell.py,sha256=Fw14yQxqsgKpo-b2tWDBI_pe19x-R35cihEyAKRqdzA,1750
 tmt/steps/prepare/__init__.py,sha256=ZIG-96joOirRVLMHKvuCtcFgp3hsjon7b8fIwh-dxcA,4410
-tmt/steps/prepare/ansible.py,sha256=a3j27M2cnZXk79kNhzqXaIBF38fXwYsp3MBF9LVoBf0,2140
-tmt/steps/prepare/install.py,sha256=BBQJUc80p5z2bcinLQj7uoIt0WcO2Pgbeu3F9oR7NYE,10115
-tmt/steps/prepare/shell.py,sha256=bEImZqlfNdo8HIs8NYDZP84vx4bnTEfcCT75-5h0c1g,1997
-tmt/steps/provision/__init__.py,sha256=fzoD--M9wCl9Y99DqfyzwlYYUmkQE5f0_OmE-MHvxy0,20514
-tmt/steps/provision/connect.py,sha256=KiuE81-esGpOhex1a0shEXlLb55hbeL8NAb7Kg8KA8Y,3694
-tmt/steps/provision/local.py,sha256=YCHsz-lcLs0T0z1O4GAWpDnTMK-HiTqMCAdBlpClhho,2584
-tmt/steps/provision/podman.py,sha256=y9UbO70zeu09_OzhYbkD6aUYvqP1DNK4W56jMiwpe1g,7608
-tmt/steps/provision/testcloud.py,sha256=frP83kdrWUdswZeh4pMlHc0Vc1Km7uWjzTDZqdPhA6A,19292
+tmt/steps/prepare/ansible.py,sha256=Zy-OLI1BbOTUIxww9cKkJ3VNCaRwPJOgea9-amLzRlU,2312
+tmt/steps/prepare/install.py,sha256=yX4lJUr4gBW-NK18y5-QzYSKj_NFxri-7Rf65rL2t5k,10027
+tmt/steps/prepare/shell.py,sha256=m2YESpzoVQidt5OsISHPMvt_nUzWH9USPdil5L1v3fs,1958
+tmt/steps/provision/__init__.py,sha256=42eXNuWek_3orBvIzQHqeWsWsXNzw30_dZcMeEcGlko,21170
+tmt/steps/provision/connect.py,sha256=Huj32g0G-fGjufiKEnHczR3TFrqMArCOpUqDZA7s-8g,3642
+tmt/steps/provision/local.py,sha256=MHbYbZrAbWcH8b_txmlxC7GNE7WD3ehS6qzzZE6O-dY,2736
+tmt/steps/provision/podman.py,sha256=Mt--GcP-Qm5--Sb3NHQ-Hghcb1Gv0l177-ofuX28wwc,7617
+tmt/steps/provision/testcloud.py,sha256=cbesSqT5azNlcp3HjNxiIsLEkb24xVrM1t9P9uZ2GSI,20162
 tmt/steps/report/__init__.py,sha256=pxrMlduZUnJV_fT9U3dcmM3Xye4TiVY7eAs0IyUJTfs,2595
 tmt/steps/report/display.py,sha256=tlmSFI3iS2APo3RkH56GsL3g6Eh0ou9UQOapJb1k-2c,1560
-tmt/steps/report/html.py,sha256=n_4Jgm-EWH4BdDmf8tRPJ_pB7RJpY9yKsrSRlUC668E,4918
-tmt/steps/report/junit.py,sha256=rlzug_eGV23JFF-KW7BTAJN-b4b1U241-8o-yuxEjL8,3082
-tmt-1.8.0.data/scripts/tmt,sha256=HTh-XKzHpn1t1cIFUsE6MmwncOC_-AmXjlozcNv8vr0,970
-tmt-1.8.0.dist-info/LICENSE,sha256=ID_AgqUKSVEqSakyNDN7F3se1wOY5f7gtmd3A3LWaeg,1071
-tmt-1.8.0.dist-info/METADATA,sha256=ZUYYyhkXWYaNZR7Oz18i9ND42kRdi-fvpmivJo1yUlg,12428
-tmt-1.8.0.dist-info/WHEEL,sha256=g4nMs7d-Xl9-xC9XovUrsDHGXt-FT0E17Yqo92DEfvY,92
-tmt-1.8.0.dist-info/top_level.txt,sha256=gPGXL_iwJt4DaNFWc5MwBts6bujwzu-sQ4JXtRf_Eew,123
-tmt-1.8.0.dist-info/RECORD,,
+tmt/steps/report/html.py,sha256=NnCJQpgI-aDvmmcR6D2tg7wgCpSU5Lq_rUkxOrTXvDg,4961
+tmt/steps/report/junit.py,sha256=d26ZqUzGhruoUPbFBQsu-2TNiWypI8BZNp-VrPv9dhM,3103
+tmt-1.9.0.data/scripts/tmt,sha256=HTh-XKzHpn1t1cIFUsE6MmwncOC_-AmXjlozcNv8vr0,970
+tmt-1.9.0.dist-info/LICENSE,sha256=xzkg-N55yxBT_3hY5EECVvmtHrOXE6XbIUUguPACVMs,1056
+tmt-1.9.0.dist-info/METADATA,sha256=m-vRQwxLAg8Y2pUq7hwWSre4R9V4hxKblWd-YSsQLDQ,12491
+tmt-1.9.0.dist-info/WHEEL,sha256=g4nMs7d-Xl9-xC9XovUrsDHGXt-FT0E17Yqo92DEfvY,92
+tmt-1.9.0.dist-info/top_level.txt,sha256=dlwbFBJNdkjUHIwMpL8Lqg2oJ2vWKMikoHS0PEO8nfI,135
+tmt-1.9.0.dist-info/RECORD,,
```

