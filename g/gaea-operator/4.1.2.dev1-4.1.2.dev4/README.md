# Comparing `tmp/gaea_operator-4.1.2.dev1-py3-none-any.whl.zip` & `tmp/gaea_operator-4.1.2.dev4-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,156 +1,169 @@
-Zip file size: 208700 bytes, number of entries: 154
--rw-r--r--  2.0 unx      131 b- defN 24-Apr-19 06:41 gaea_operator/__init__.py
--rw-r--r--  2.0 unx      131 b- defN 24-Apr-19 06:41 gaea_operator/components/__init__.py
--rw-r--r--  2.0 unx      131 b- defN 24-Apr-19 06:41 gaea_operator/components/eval/__init__.py
--rw-r--r--  2.0 unx     4731 b- defN 24-Apr-22 07:24 gaea_operator/components/eval/codetr.py
--rw-r--r--  2.0 unx     4600 b- defN 24-Apr-26 09:16 gaea_operator/components/eval/convnext.py
--rw-r--r--  2.0 unx     4169 b- defN 24-Apr-19 06:41 gaea_operator/components/eval/ocrnet.py
--rw-r--r--  2.0 unx     4268 b- defN 24-Apr-19 06:41 gaea_operator/components/eval/ppyoloe_plus.py
--rw-r--r--  2.0 unx     4592 b- defN 24-Apr-26 09:16 gaea_operator/components/eval/repvit.py
--rw-r--r--  2.0 unx     4153 b- defN 24-Apr-19 06:41 gaea_operator/components/eval/resnet.py
--rw-r--r--  2.0 unx      206 b- defN 24-Apr-26 09:16 gaea_operator/components/icafe/__init__.py
--rw-r--r--  2.0 unx     3738 b- defN 24-Apr-26 09:16 gaea_operator/components/icafe/icafe.py
--rw-r--r--  2.0 unx     3102 b- defN 24-Apr-19 06:41 gaea_operator/components/inference/__init__.py
--rw-r--r--  2.0 unx     4357 b- defN 24-Apr-19 06:41 gaea_operator/components/inference/inference.py
--rw-r--r--  2.0 unx     3550 b- defN 24-Apr-19 06:41 gaea_operator/components/package/__init__.py
--rw-r--r--  2.0 unx     8422 b- defN 24-Apr-19 06:41 gaea_operator/components/package/package.py
--rw-r--r--  2.0 unx      131 b- defN 24-Apr-19 06:41 gaea_operator/components/train/__init__.py
--rw-r--r--  2.0 unx     8618 b- defN 24-Apr-22 07:24 gaea_operator/components/train/codetr.py
--rw-r--r--  2.0 unx     8334 b- defN 24-Apr-26 09:16 gaea_operator/components/train/convnext.py
--rw-r--r--  2.0 unx     7519 b- defN 24-Apr-19 06:41 gaea_operator/components/train/ocrnet.py
--rw-r--r--  2.0 unx     8365 b- defN 24-Apr-19 06:41 gaea_operator/components/train/ppyoloe_plus.py
--rw-r--r--  2.0 unx     8324 b- defN 24-Apr-26 09:16 gaea_operator/components/train/repvit.py
--rw-r--r--  2.0 unx     7390 b- defN 24-Apr-19 06:41 gaea_operator/components/train/resnet.py
--rw-r--r--  2.0 unx      131 b- defN 24-Apr-19 06:41 gaea_operator/components/transform/__init__.py
--rw-r--r--  2.0 unx     6125 b- defN 24-Apr-26 08:06 gaea_operator/components/transform/change_ppyoloe_plus.py
--rw-r--r--  2.0 unx     6209 b- defN 24-Apr-22 07:24 gaea_operator/components/transform/codetr.py
--rw-r--r--  2.0 unx     6150 b- defN 24-Apr-26 09:16 gaea_operator/components/transform/convnext.py
--rw-r--r--  2.0 unx     6236 b- defN 24-Apr-19 06:41 gaea_operator/components/transform/ocrnet.py
--rw-r--r--  2.0 unx     6078 b- defN 24-Apr-19 06:41 gaea_operator/components/transform/ppyoloe_plus.py
--rw-r--r--  2.0 unx     6141 b- defN 24-Apr-26 09:16 gaea_operator/components/transform/repvit.py
--rw-r--r--  2.0 unx     6214 b- defN 24-Apr-19 06:41 gaea_operator/components/transform/resnet.py
--rw-r--r--  2.0 unx     3557 b- defN 24-Apr-19 06:41 gaea_operator/components/transform_eval/__init__.py
--rw-r--r--  2.0 unx     8001 b- defN 24-Apr-19 06:41 gaea_operator/components/transform_eval/transform_eval.py
--rw-r--r--  2.0 unx      774 b- defN 24-Apr-26 09:16 gaea_operator/config/__init__.py
--rw-r--r--  2.0 unx     4964 b- defN 24-Apr-22 07:24 gaea_operator/config/config.py
--rw-r--r--  2.0 unx    14999 b- defN 24-Apr-26 09:16 gaea_operator/config/generate_transform_config.py
--rw-r--r--  2.0 unx    14835 b- defN 24-Apr-19 06:41 gaea_operator/config/modify_package_files.py
--rw-r--r--  2.0 unx     3642 b- defN 24-Apr-19 06:41 gaea_operator/config/update_parse.py
--rw-r--r--  2.0 unx    16721 b- defN 24-Apr-19 06:41 gaea_operator/config/update_pbtxt.py
--rw-r--r--  2.0 unx      130 b- defN 24-Apr-22 07:24 gaea_operator/config/codetr/__init__.py
--rw-r--r--  2.0 unx     5343 b- defN 24-Apr-26 09:16 gaea_operator/config/codetr/codetr_config.py
--rw-r--r--  2.0 unx      130 b- defN 24-Apr-22 07:24 gaea_operator/config/codetr/template/__init__.py
--rw-r--r--  2.0 unx      590 b- defN 24-Apr-22 07:24 gaea_operator/config/codetr/template/deploy_parameter.yaml
--rw-r--r--  2.0 unx    14288 b- defN 24-Apr-26 09:16 gaea_operator/config/codetr/template/modify_parameter.py
--rw-r--r--  2.0 unx    13839 b- defN 24-Apr-26 09:16 gaea_operator/config/codetr/template/train_parameter.yaml
--rw-r--r--  2.0 unx      130 b- defN 24-Apr-22 07:24 gaea_operator/config/convnext/__init__.py
--rw-r--r--  2.0 unx     4001 b- defN 24-Apr-26 09:16 gaea_operator/config/convnext/convnext_config.py
--rw-r--r--  2.0 unx      130 b- defN 24-Apr-22 07:24 gaea_operator/config/convnext/template/__init__.py
--rw-r--r--  2.0 unx     4338 b- defN 24-Apr-26 09:16 gaea_operator/config/convnext/template/modify_train_parameter.py
--rw-r--r--  2.0 unx     1499 b- defN 24-Apr-26 09:16 gaea_operator/config/convnext/template/parameter.yaml
--rw-r--r--  2.0 unx      130 b- defN 24-Apr-19 06:41 gaea_operator/config/ocrnet/__init__.py
--rw-r--r--  2.0 unx     5599 b- defN 24-Apr-19 06:41 gaea_operator/config/ocrnet/ocrnet_config.py
--rw-r--r--  2.0 unx      130 b- defN 24-Apr-19 06:41 gaea_operator/config/ocrnet/template/__init__.py
--rw-r--r--  2.0 unx     8809 b- defN 24-Apr-19 06:41 gaea_operator/config/ocrnet/template/modify_train_parameter.py
--rwxr-xr-x  2.0 unx     1467 b- defN 24-Apr-19 06:41 gaea_operator/config/ocrnet/template/parameter.yaml
--rw-r--r--  2.0 unx     1656 b- defN 24-Apr-26 09:16 gaea_operator/config/ocrnet/template/parameter_c.yaml
--rw-r--r--  2.0 unx      130 b- defN 24-Apr-19 06:41 gaea_operator/config/ppyoloe_plus/__init__.py
--rw-r--r--  2.0 unx     4058 b- defN 24-Apr-19 06:41 gaea_operator/config/ppyoloe_plus/ppyoloeplus_config.py
--rw-r--r--  2.0 unx      130 b- defN 24-Apr-19 06:41 gaea_operator/config/ppyoloe_plus/template/__init__.py
--rw-r--r--  2.0 unx    12621 b- defN 24-Apr-19 06:41 gaea_operator/config/ppyoloe_plus/template/modify_train_parameter.py
--rw-r--r--  2.0 unx     4583 b- defN 24-Apr-19 06:41 gaea_operator/config/ppyoloe_plus/template/parameter.yaml
--rw-r--r--  2.0 unx     4666 b- defN 24-Apr-19 06:41 gaea_operator/config/ppyoloe_plus/template/parameter_c.yaml
--rw-r--r--  2.0 unx      130 b- defN 24-Apr-26 09:16 gaea_operator/config/repvit/__init__.py
--rw-r--r--  2.0 unx      620 b- defN 24-Apr-26 09:16 gaea_operator/config/repvit/repvit_config.py
--rw-r--r--  2.0 unx      130 b- defN 24-Apr-19 06:41 gaea_operator/config/resnet/__init__.py
--rw-r--r--  2.0 unx     4283 b- defN 24-Apr-19 06:41 gaea_operator/config/resnet/resnet_config.py
--rw-r--r--  2.0 unx      130 b- defN 24-Apr-19 06:41 gaea_operator/config/resnet/template/__init__.py
--rw-r--r--  2.0 unx    11498 b- defN 24-Apr-19 06:41 gaea_operator/config/resnet/template/modify_train_parameter.py
--rw-r--r--  2.0 unx     2315 b- defN 24-Apr-19 06:41 gaea_operator/config/resnet/template/parameter.yaml
--rw-r--r--  2.0 unx      370 b- defN 24-Apr-19 06:41 gaea_operator/dataset/__init__.py
--rw-r--r--  2.0 unx     4259 b- defN 24-Apr-19 06:41 gaea_operator/dataset/cityscape_dataset.py
--rw-r--r--  2.0 unx     6779 b- defN 24-Apr-23 12:54 gaea_operator/dataset/coco_dataset.py
--rw-r--r--  2.0 unx     7314 b- defN 24-Apr-21 12:43 gaea_operator/dataset/dataset.py
--rw-r--r--  2.0 unx     4311 b- defN 24-Apr-22 07:24 gaea_operator/dataset/imagenet_dataset.py
--rw-r--r--  2.0 unx      584 b- defN 24-Apr-19 06:41 gaea_operator/metric/__init__.py
--rw-r--r--  2.0 unx     5740 b- defN 24-Apr-19 06:41 gaea_operator/metric/metric.py
--rw-r--r--  2.0 unx      433 b- defN 24-Apr-19 06:41 gaea_operator/metric/analysis/__init__.py
--rw-r--r--  2.0 unx    19213 b- defN 24-Apr-23 12:54 gaea_operator/metric/analysis/eval_metric_analysis.py
--rw-r--r--  2.0 unx     7907 b- defN 24-Apr-26 07:59 gaea_operator/metric/analysis/inference_metric_analysis.py
--rw-r--r--  2.0 unx    11706 b- defN 24-Apr-19 06:41 gaea_operator/metric/analysis/label_statistics_metric_analysis.py
--rw-r--r--  2.0 unx      792 b- defN 24-Apr-19 06:41 gaea_operator/metric/operator/__init__.py
--rw-r--r--  2.0 unx     3195 b- defN 24-Apr-19 06:41 gaea_operator/metric/operator/check.py
--rw-r--r--  2.0 unx     1923 b- defN 24-Apr-19 06:41 gaea_operator/metric/operator/metric.py
--rw-r--r--  2.0 unx      779 b- defN 24-Apr-19 06:41 gaea_operator/metric/operator/image/__init__.py
--rw-r--r--  2.0 unx     6960 b- defN 24-Apr-19 06:41 gaea_operator/metric/operator/image/accuracy.py
--rw-r--r--  2.0 unx     2571 b- defN 24-Apr-19 06:41 gaea_operator/metric/operator/image/average_precision.py
--rw-r--r--  2.0 unx     5264 b- defN 24-Apr-19 06:41 gaea_operator/metric/operator/image/bbox_confusion_matrix.py
--rw-r--r--  2.0 unx     3939 b- defN 24-Apr-19 06:41 gaea_operator/metric/operator/image/confusion_matrix.py
--rw-r--r--  2.0 unx    20678 b- defN 24-Apr-19 06:41 gaea_operator/metric/operator/image/mean_ap.py
--rw-r--r--  2.0 unx     6128 b- defN 24-Apr-19 06:41 gaea_operator/metric/operator/image/mean_iou.py
--rw-r--r--  2.0 unx    19509 b- defN 24-Apr-19 06:41 gaea_operator/metric/operator/image/precision_recall_curve.py
--rw-r--r--  2.0 unx    11970 b- defN 24-Apr-19 06:41 gaea_operator/metric/operator/image/precision_recall_f1score.py
--rw-r--r--  2.0 unx      289 b- defN 24-Apr-19 06:41 gaea_operator/metric/operator/tabular/__init__.py
--rw-r--r--  2.0 unx     1207 b- defN 24-Apr-19 06:41 gaea_operator/metric/operator/tabular/count_statistic.py
--rw-r--r--  2.0 unx     2241 b- defN 24-Apr-19 06:41 gaea_operator/metric/operator/tabular/histogram_statistic.py
--rw-r--r--  2.0 unx     4864 b- defN 24-Apr-19 06:41 gaea_operator/metric/schema/object_detection.yaml
--rw-r--r--  2.0 unx      131 b- defN 24-Apr-19 06:41 gaea_operator/metric/types/__init__.py
--rw-r--r--  2.0 unx     1173 b- defN 24-Apr-19 06:41 gaea_operator/metric/types/image_classification_metric.py
--rw-r--r--  2.0 unx     4874 b- defN 24-Apr-19 06:41 gaea_operator/metric/types/metric.py
--rw-r--r--  2.0 unx     2362 b- defN 24-Apr-19 06:41 gaea_operator/metric/types/object_detection_metric.py
--rw-r--r--  2.0 unx     1244 b- defN 24-Apr-19 06:41 gaea_operator/metric/types/semantic_segmentation_metric.py
--rw-r--r--  2.0 unx      214 b- defN 24-Apr-19 06:41 gaea_operator/model/__init__.py
--rw-r--r--  2.0 unx     1436 b- defN 24-Apr-19 06:41 gaea_operator/model/model.py
--rw-r--r--  2.0 unx      687 b- defN 24-Apr-26 07:59 gaea_operator/pipelines/__init__.py
--rw-r--r--  2.0 unx     2173 b- defN 24-Apr-26 07:59 gaea_operator/pipelines/create_ppl.py
--rw-r--r--  2.0 unx     1254 b- defN 24-Apr-26 07:59 gaea_operator/pipelines/change_ppyoloe_plus_pipeline/train_parameter.yaml
--rw-r--r--  2.0 unx     1744 b- defN 24-Apr-26 07:59 gaea_operator/pipelines/change_ppyoloe_plus_pipeline/transform_parameter.yaml
--rw-r--r--  2.0 unx      130 b- defN 24-Apr-23 02:56 gaea_operator/pipelines/codetr_pipeline/__init__.py
--rw-r--r--  2.0 unx    12171 b- defN 24-Apr-26 09:17 gaea_operator/pipelines/codetr_pipeline/pipeline.py
--rw-r--r--  2.0 unx     1224 b- defN 24-Apr-23 08:16 gaea_operator/pipelines/codetr_pipeline/train_parameter.yaml
--rw-r--r--  2.0 unx     1118 b- defN 24-Apr-23 02:56 gaea_operator/pipelines/codetr_pipeline/transform_parameter.yaml
--rw-r--r--  2.0 unx      131 b- defN 24-Apr-22 07:26 gaea_operator/pipelines/convnext_pipeline/__init__.py
--rw-r--r--  2.0 unx    11865 b- defN 24-Apr-26 09:16 gaea_operator/pipelines/convnext_pipeline/convnext_pipeline.py
--rw-r--r--  2.0 unx     1474 b- defN 24-Apr-26 09:16 gaea_operator/pipelines/convnext_pipeline/train_parameter.yaml
--rw-r--r--  2.0 unx     1229 b- defN 24-Apr-26 09:16 gaea_operator/pipelines/convnext_pipeline/transform_parameter.yaml
--rw-r--r--  2.0 unx      131 b- defN 24-Apr-19 06:41 gaea_operator/pipelines/ocrnet_pipeline/__init__.py
--rw-r--r--  2.0 unx    12008 b- defN 24-Apr-26 07:59 gaea_operator/pipelines/ocrnet_pipeline/ocrnet_pipeline.py
+Zip file size: 231591 bytes, number of entries: 167
+-rw-r--r--  2.0 unx      131 b- defN 24-Apr-26 11:37 gaea_operator/__init__.py
+-rw-r--r--  2.0 unx      131 b- defN 24-Apr-26 11:37 gaea_operator/components/__init__.py
+-rw-r--r--  2.0 unx      131 b- defN 24-Apr-26 11:37 gaea_operator/components/eval/__init__.py
+-rw-r--r--  2.0 unx     4731 b- defN 24-Apr-26 11:37 gaea_operator/components/eval/codetr.py
+-rw-r--r--  2.0 unx     4600 b- defN 24-May-09 03:12 gaea_operator/components/eval/convnext.py
+-rw-r--r--  2.0 unx     4169 b- defN 24-Apr-26 11:37 gaea_operator/components/eval/ocrnet.py
+-rw-r--r--  2.0 unx     4334 b- defN 24-May-09 03:12 gaea_operator/components/eval/ppyoloe_plus.py
+-rw-r--r--  2.0 unx     4592 b- defN 24-May-09 03:12 gaea_operator/components/eval/repvit.py
+-rw-r--r--  2.0 unx     4153 b- defN 24-Apr-26 11:37 gaea_operator/components/eval/resnet.py
+-rw-r--r--  2.0 unx      206 b- defN 24-May-09 03:12 gaea_operator/components/icafe/__init__.py
+-rw-r--r--  2.0 unx     3738 b- defN 24-May-09 03:12 gaea_operator/components/icafe/icafe.py
+-rw-r--r--  2.0 unx     3102 b- defN 24-Apr-26 11:37 gaea_operator/components/inference/__init__.py
+-rw-r--r--  2.0 unx     4357 b- defN 24-Apr-26 11:37 gaea_operator/components/inference/inference.py
+-rw-r--r--  2.0 unx     3550 b- defN 24-Apr-26 11:37 gaea_operator/components/package/__init__.py
+-rw-r--r--  2.0 unx     8716 b- defN 24-May-09 06:54 gaea_operator/components/package/package.py
+-rw-r--r--  2.0 unx      131 b- defN 24-Apr-26 11:37 gaea_operator/components/train/__init__.py
+-rw-r--r--  2.0 unx     9635 b- defN 24-May-09 08:43 gaea_operator/components/train/change_ppyoloe_plus.py
+-rw-r--r--  2.0 unx     8678 b- defN 24-May-09 03:12 gaea_operator/components/train/codetr.py
+-rw-r--r--  2.0 unx     8334 b- defN 24-May-09 03:12 gaea_operator/components/train/convnext.py
+-rw-r--r--  2.0 unx     8919 b- defN 24-May-09 03:12 gaea_operator/components/train/ocrnet.py
+-rw-r--r--  2.0 unx     9437 b- defN 24-May-09 03:12 gaea_operator/components/train/ppyoloe_plus.py
+-rw-r--r--  2.0 unx     8324 b- defN 24-May-09 03:12 gaea_operator/components/train/repvit.py
+-rw-r--r--  2.0 unx     8629 b- defN 24-May-09 03:12 gaea_operator/components/train/resnet.py
+-rw-r--r--  2.0 unx      131 b- defN 24-Apr-26 11:37 gaea_operator/components/transform/__init__.py
+-rw-r--r--  2.0 unx     6499 b- defN 24-May-09 03:12 gaea_operator/components/transform/change_ocrnet.py
+-rw-r--r--  2.0 unx     6394 b- defN 24-May-09 03:12 gaea_operator/components/transform/change_ppyoloe_plus.py
+-rw-r--r--  2.0 unx     6209 b- defN 24-May-09 03:12 gaea_operator/components/transform/codetr.py
+-rw-r--r--  2.0 unx     6150 b- defN 24-May-09 03:12 gaea_operator/components/transform/convnext.py
+-rw-r--r--  2.0 unx     6462 b- defN 24-May-09 03:12 gaea_operator/components/transform/ocrnet.py
+-rw-r--r--  2.0 unx     6357 b- defN 24-May-09 03:12 gaea_operator/components/transform/ppyoloe_plus.py
+-rw-r--r--  2.0 unx     6141 b- defN 24-May-09 03:12 gaea_operator/components/transform/repvit.py
+-rw-r--r--  2.0 unx     6493 b- defN 24-May-09 03:12 gaea_operator/components/transform/resnet.py
+-rw-r--r--  2.0 unx     3557 b- defN 24-Apr-26 11:37 gaea_operator/components/transform_eval/__init__.py
+-rw-r--r--  2.0 unx     8763 b- defN 24-May-09 05:28 gaea_operator/components/transform_eval/transform_eval.py
+-rw-r--r--  2.0 unx      774 b- defN 24-May-09 03:12 gaea_operator/config/__init__.py
+-rw-r--r--  2.0 unx     5057 b- defN 24-May-09 03:58 gaea_operator/config/config.py
+-rw-r--r--  2.0 unx    16189 b- defN 24-May-09 03:12 gaea_operator/config/generate_transform_config.py
+-rw-r--r--  2.0 unx    18345 b- defN 24-May-09 05:38 gaea_operator/config/modify_package_files.py
+-rw-r--r--  2.0 unx     3642 b- defN 24-Apr-26 11:37 gaea_operator/config/update_parse.py
+-rw-r--r--  2.0 unx    16721 b- defN 24-Apr-26 11:37 gaea_operator/config/update_pbtxt.py
+-rw-r--r--  2.0 unx      130 b- defN 24-Apr-26 11:37 gaea_operator/config/codetr/__init__.py
+-rw-r--r--  2.0 unx     5339 b- defN 24-May-09 03:12 gaea_operator/config/codetr/codetr_config.py
+-rw-r--r--  2.0 unx      130 b- defN 24-Apr-26 11:37 gaea_operator/config/codetr/template/__init__.py
+-rw-r--r--  2.0 unx      590 b- defN 24-Apr-26 11:37 gaea_operator/config/codetr/template/deploy_parameter.yaml
+-rw-r--r--  2.0 unx    14221 b- defN 24-May-09 03:12 gaea_operator/config/codetr/template/modify_parameter.py
+-rw-r--r--  2.0 unx    13839 b- defN 24-May-09 03:12 gaea_operator/config/codetr/template/train_parameter.yaml
+-rw-r--r--  2.0 unx      130 b- defN 24-Apr-26 11:37 gaea_operator/config/convnext/__init__.py
+-rw-r--r--  2.0 unx     4001 b- defN 24-May-09 03:12 gaea_operator/config/convnext/convnext_config.py
+-rw-r--r--  2.0 unx      130 b- defN 24-Apr-26 11:37 gaea_operator/config/convnext/template/__init__.py
+-rw-r--r--  2.0 unx     4338 b- defN 24-May-09 03:12 gaea_operator/config/convnext/template/modify_train_parameter.py
+-rw-r--r--  2.0 unx     1499 b- defN 24-May-09 03:12 gaea_operator/config/convnext/template/parameter.yaml
+-rw-r--r--  2.0 unx      130 b- defN 24-Apr-26 11:37 gaea_operator/config/ocrnet/__init__.py
+-rw-r--r--  2.0 unx     5588 b- defN 24-May-09 03:12 gaea_operator/config/ocrnet/ocrnet_config.py
+-rw-r--r--  2.0 unx      130 b- defN 24-Apr-26 11:37 gaea_operator/config/ocrnet/template/__init__.py
+-rw-r--r--  2.0 unx     9419 b- defN 24-May-09 03:12 gaea_operator/config/ocrnet/template/modify_train_parameter.py
+-rwxr-xr-x  2.0 unx     1467 b- defN 24-Apr-26 11:37 gaea_operator/config/ocrnet/template/parameter.yaml
+-rw-r--r--  2.0 unx     1656 b- defN 24-May-09 03:12 gaea_operator/config/ocrnet/template/parameter_c.yaml
+-rw-r--r--  2.0 unx      130 b- defN 24-Apr-26 11:37 gaea_operator/config/ppyoloe_plus/__init__.py
+-rw-r--r--  2.0 unx     4058 b- defN 24-Apr-26 11:37 gaea_operator/config/ppyoloe_plus/ppyoloeplus_config.py
+-rw-r--r--  2.0 unx      130 b- defN 24-Apr-26 11:37 gaea_operator/config/ppyoloe_plus/template/__init__.py
+-rw-r--r--  2.0 unx    12621 b- defN 24-Apr-26 11:37 gaea_operator/config/ppyoloe_plus/template/modify_train_parameter.py
+-rw-r--r--  2.0 unx     4583 b- defN 24-May-09 03:12 gaea_operator/config/ppyoloe_plus/template/parameter.yaml
+-rw-r--r--  2.0 unx     4665 b- defN 24-May-09 03:12 gaea_operator/config/ppyoloe_plus/template/parameter_c.yaml
+-rw-r--r--  2.0 unx      130 b- defN 24-May-09 03:12 gaea_operator/config/repvit/__init__.py
+-rw-r--r--  2.0 unx      620 b- defN 24-May-09 03:12 gaea_operator/config/repvit/repvit_config.py
+-rw-r--r--  2.0 unx      130 b- defN 24-Apr-26 11:37 gaea_operator/config/resnet/__init__.py
+-rw-r--r--  2.0 unx     4283 b- defN 24-Apr-26 11:37 gaea_operator/config/resnet/resnet_config.py
+-rw-r--r--  2.0 unx      130 b- defN 24-Apr-26 11:37 gaea_operator/config/resnet/template/__init__.py
+-rw-r--r--  2.0 unx    11498 b- defN 24-Apr-26 11:37 gaea_operator/config/resnet/template/modify_train_parameter.py
+-rw-r--r--  2.0 unx     2315 b- defN 24-Apr-26 11:37 gaea_operator/config/resnet/template/parameter.yaml
+-rw-r--r--  2.0 unx      370 b- defN 24-Apr-26 11:37 gaea_operator/dataset/__init__.py
+-rw-r--r--  2.0 unx     4259 b- defN 24-Apr-26 11:37 gaea_operator/dataset/cityscape_dataset.py
+-rw-r--r--  2.0 unx     6779 b- defN 24-Apr-26 11:37 gaea_operator/dataset/coco_dataset.py
+-rw-r--r--  2.0 unx     7314 b- defN 24-Apr-26 11:37 gaea_operator/dataset/dataset.py
+-rw-r--r--  2.0 unx     4311 b- defN 24-Apr-26 11:37 gaea_operator/dataset/imagenet_dataset.py
+-rw-r--r--  2.0 unx      584 b- defN 24-Apr-26 11:37 gaea_operator/metric/__init__.py
+-rw-r--r--  2.0 unx     5740 b- defN 24-Apr-26 11:37 gaea_operator/metric/metric.py
+-rw-r--r--  2.0 unx      433 b- defN 24-Apr-26 11:37 gaea_operator/metric/analysis/__init__.py
+-rw-r--r--  2.0 unx    19213 b- defN 24-May-09 03:12 gaea_operator/metric/analysis/eval_metric_analysis.py
+-rw-r--r--  2.0 unx     8002 b- defN 24-Apr-28 12:56 gaea_operator/metric/analysis/inference_metric_analysis.py
+-rw-r--r--  2.0 unx    11706 b- defN 24-Apr-26 11:37 gaea_operator/metric/analysis/label_statistics_metric_analysis.py
+-rw-r--r--  2.0 unx      792 b- defN 24-Apr-26 11:37 gaea_operator/metric/operator/__init__.py
+-rw-r--r--  2.0 unx     3195 b- defN 24-Apr-26 11:37 gaea_operator/metric/operator/check.py
+-rw-r--r--  2.0 unx     1923 b- defN 24-Apr-26 11:37 gaea_operator/metric/operator/metric.py
+-rw-r--r--  2.0 unx      779 b- defN 24-Apr-26 11:37 gaea_operator/metric/operator/image/__init__.py
+-rw-r--r--  2.0 unx     6960 b- defN 24-Apr-26 11:37 gaea_operator/metric/operator/image/accuracy.py
+-rw-r--r--  2.0 unx     2571 b- defN 24-Apr-26 11:37 gaea_operator/metric/operator/image/average_precision.py
+-rw-r--r--  2.0 unx     5264 b- defN 24-Apr-26 11:37 gaea_operator/metric/operator/image/bbox_confusion_matrix.py
+-rw-r--r--  2.0 unx     3939 b- defN 24-Apr-26 11:37 gaea_operator/metric/operator/image/confusion_matrix.py
+-rw-r--r--  2.0 unx    20678 b- defN 24-Apr-26 11:37 gaea_operator/metric/operator/image/mean_ap.py
+-rw-r--r--  2.0 unx     6128 b- defN 24-Apr-26 11:37 gaea_operator/metric/operator/image/mean_iou.py
+-rw-r--r--  2.0 unx    19509 b- defN 24-Apr-26 11:37 gaea_operator/metric/operator/image/precision_recall_curve.py
+-rw-r--r--  2.0 unx    11970 b- defN 24-Apr-26 11:37 gaea_operator/metric/operator/image/precision_recall_f1score.py
+-rw-r--r--  2.0 unx      289 b- defN 24-Apr-26 11:37 gaea_operator/metric/operator/tabular/__init__.py
+-rw-r--r--  2.0 unx     1207 b- defN 24-Apr-26 11:37 gaea_operator/metric/operator/tabular/count_statistic.py
+-rw-r--r--  2.0 unx     2241 b- defN 24-Apr-26 11:37 gaea_operator/metric/operator/tabular/histogram_statistic.py
+-rw-r--r--  2.0 unx     4864 b- defN 24-Apr-26 11:37 gaea_operator/metric/schema/object_detection.yaml
+-rw-r--r--  2.0 unx      131 b- defN 24-Apr-26 11:37 gaea_operator/metric/types/__init__.py
+-rw-r--r--  2.0 unx     1173 b- defN 24-Apr-26 11:37 gaea_operator/metric/types/image_classification_metric.py
+-rw-r--r--  2.0 unx     4874 b- defN 24-Apr-26 11:37 gaea_operator/metric/types/metric.py
+-rw-r--r--  2.0 unx     2362 b- defN 24-Apr-26 11:37 gaea_operator/metric/types/object_detection_metric.py
+-rw-r--r--  2.0 unx     1244 b- defN 24-Apr-26 11:37 gaea_operator/metric/types/semantic_segmentation_metric.py
+-rw-r--r--  2.0 unx      214 b- defN 24-Apr-26 11:37 gaea_operator/model/__init__.py
+-rw-r--r--  2.0 unx     1436 b- defN 24-Apr-26 11:37 gaea_operator/model/model.py
+-rw-r--r--  2.0 unx      545 b- defN 24-Apr-28 12:56 gaea_operator/pipelines/__init__.py
+-rw-r--r--  2.0 unx     3132 b- defN 24-Apr-28 12:56 gaea_operator/pipelines/create_ppl.py
+-rw-r--r--  2.0 unx      131 b- defN 24-May-09 03:12 gaea_operator/pipelines/change_ocrnet_pipeline/__init__.py
+-rw-r--r--  2.0 unx    11584 b- defN 24-May-09 03:12 gaea_operator/pipelines/change_ocrnet_pipeline/pipeline.py
+-rw-r--r--  2.0 unx     9743 b- defN 24-May-09 03:12 gaea_operator/pipelines/change_ocrnet_pipeline/pipeline.yaml
+-rw-r--r--  2.0 unx     1051 b- defN 24-May-09 03:12 gaea_operator/pipelines/change_ocrnet_pipeline/train_parameter.yaml
+-rw-r--r--  2.0 unx     1119 b- defN 24-May-09 03:12 gaea_operator/pipelines/change_ocrnet_pipeline/transform_parameter.yaml
+-rw-r--r--  2.0 unx      131 b- defN 24-Apr-28 12:56 gaea_operator/pipelines/change_ppyoloe_plus_pipeline/__init__.py
+-rw-r--r--  2.0 unx    22441 b- defN 24-May-09 08:05 gaea_operator/pipelines/change_ppyoloe_plus_pipeline/pipeline.py
+-rw-r--r--  2.0 unx    11396 b- defN 24-May-07 11:43 gaea_operator/pipelines/change_ppyoloe_plus_pipeline/pipeline.yaml
+-rw-r--r--  2.0 unx     1254 b- defN 24-May-09 08:21 gaea_operator/pipelines/change_ppyoloe_plus_pipeline/train_parameter.yaml
+-rw-r--r--  2.0 unx     1744 b- defN 24-May-09 03:12 gaea_operator/pipelines/change_ppyoloe_plus_pipeline/transform_parameter.yaml
+-rw-r--r--  2.0 unx      130 b- defN 24-Apr-26 11:37 gaea_operator/pipelines/codetr_pipeline/__init__.py
+-rw-r--r--  2.0 unx    12194 b- defN 24-May-09 03:12 gaea_operator/pipelines/codetr_pipeline/pipeline.py
+-rw-r--r--  2.0 unx     1224 b- defN 24-Apr-26 11:37 gaea_operator/pipelines/codetr_pipeline/train_parameter.yaml
+-rw-r--r--  2.0 unx     1118 b- defN 24-Apr-26 11:37 gaea_operator/pipelines/codetr_pipeline/transform_parameter.yaml
+-rw-r--r--  2.0 unx      131 b- defN 24-Apr-26 11:37 gaea_operator/pipelines/convnext_pipeline/__init__.py
+-rw-r--r--  2.0 unx    11865 b- defN 24-May-09 03:12 gaea_operator/pipelines/convnext_pipeline/convnext_pipeline.py
+-rw-r--r--  2.0 unx     1474 b- defN 24-May-09 03:12 gaea_operator/pipelines/convnext_pipeline/train_parameter.yaml
+-rw-r--r--  2.0 unx     1229 b- defN 24-May-09 03:12 gaea_operator/pipelines/convnext_pipeline/transform_parameter.yaml
+-rw-r--r--  2.0 unx      131 b- defN 24-Apr-26 11:37 gaea_operator/pipelines/ocrnet_pipeline/__init__.py
+-rw-r--r--  2.0 unx    11570 b- defN 24-May-09 03:12 gaea_operator/pipelines/ocrnet_pipeline/pipeline.py
 -rw-r--r--  2.0 unx     9743 b- defN 24-Apr-26 07:33 gaea_operator/pipelines/ocrnet_pipeline/pipeline.yaml
--rw-r--r--  2.0 unx     1051 b- defN 24-Apr-19 06:41 gaea_operator/pipelines/ocrnet_pipeline/train_parameter.yaml
--rw-r--r--  2.0 unx     1119 b- defN 24-Apr-19 06:41 gaea_operator/pipelines/ocrnet_pipeline/transform_parameter.yaml
--rw-r--r--  2.0 unx     1226 b- defN 24-Apr-26 07:59 gaea_operator/pipelines/ppyoloe_plus_pipeline/train_parameter.yaml
--rw-r--r--  2.0 unx     1716 b- defN 24-Apr-26 07:59 gaea_operator/pipelines/ppyoloe_plus_pipeline/transform_parameter.yaml
--rw-r--r--  2.0 unx     1461 b- defN 24-Apr-26 09:16 gaea_operator/pipelines/repvit_pipeline/train_parameter.yaml
--rw-r--r--  2.0 unx     1212 b- defN 24-Apr-26 09:16 gaea_operator/pipelines/repvit_pipeline/transform_parameter.yaml
--rw-r--r--  2.0 unx      131 b- defN 24-Apr-19 06:41 gaea_operator/pipelines/resnet_pipeline/__init__.py
+-rw-r--r--  2.0 unx     1051 b- defN 24-Apr-26 11:37 gaea_operator/pipelines/ocrnet_pipeline/train_parameter.yaml
+-rw-r--r--  2.0 unx     1119 b- defN 24-Apr-26 11:37 gaea_operator/pipelines/ocrnet_pipeline/transform_parameter.yaml
+-rw-r--r--  2.0 unx      131 b- defN 24-Apr-28 12:56 gaea_operator/pipelines/ppyoloe_plus_pipeline/__init__.py
+-rw-r--r--  2.0 unx    22347 b- defN 24-May-09 08:38 gaea_operator/pipelines/ppyoloe_plus_pipeline/pipeline.py
+-rw-r--r--  2.0 unx    11396 b- defN 24-May-07 11:43 gaea_operator/pipelines/ppyoloe_plus_pipeline/pipeline.yaml
+-rw-r--r--  2.0 unx     1226 b- defN 24-May-09 03:12 gaea_operator/pipelines/ppyoloe_plus_pipeline/train_parameter.yaml
+-rw-r--r--  2.0 unx     1716 b- defN 24-May-09 03:12 gaea_operator/pipelines/ppyoloe_plus_pipeline/transform_parameter.yaml
+-rw-r--r--  2.0 unx     1461 b- defN 24-May-09 03:12 gaea_operator/pipelines/repvit_pipeline/train_parameter.yaml
+-rw-r--r--  2.0 unx     1212 b- defN 24-May-09 03:12 gaea_operator/pipelines/repvit_pipeline/transform_parameter.yaml
+-rw-r--r--  2.0 unx      131 b- defN 24-Apr-26 11:37 gaea_operator/pipelines/resnet_pipeline/__init__.py
+-rw-r--r--  2.0 unx    12172 b- defN 24-May-09 03:12 gaea_operator/pipelines/resnet_pipeline/pipeline.py
 -rw-r--r--  2.0 unx     9833 b- defN 24-Apr-26 07:33 gaea_operator/pipelines/resnet_pipeline/pipeline.yaml
--rw-r--r--  2.0 unx    12187 b- defN 24-Apr-26 07:59 gaea_operator/pipelines/resnet_pipeline/resnet_pipeline.py
--rw-r--r--  2.0 unx     1271 b- defN 24-Apr-19 06:41 gaea_operator/pipelines/resnet_pipeline/train_parameter.yaml
--rw-r--r--  2.0 unx     1121 b- defN 24-Apr-19 06:41 gaea_operator/pipelines/resnet_pipeline/transform_parameter.yaml
--rw-r--r--  2.0 unx      181 b- defN 24-Apr-19 06:41 gaea_operator/trainer/__init__.py
--rw-r--r--  2.0 unx     6818 b- defN 24-Apr-22 07:24 gaea_operator/trainer/trainer.py
--rw-r--r--  2.0 unx      187 b- defN 24-Apr-19 06:41 gaea_operator/transform/__init__.py
--rw-r--r--  2.0 unx     3307 b- defN 24-Apr-19 06:41 gaea_operator/transform/cvt_copy_model.py
--rw-r--r--  2.0 unx      776 b- defN 24-Apr-19 06:41 gaea_operator/transform/transform.py
--rw-r--r--  2.0 unx     2004 b- defN 24-Apr-26 09:16 gaea_operator/utils/__init__.py
--rw-r--r--  2.0 unx     5557 b- defN 24-Apr-26 07:59 gaea_operator/utils/accelerator.py
--rw-r--r--  2.0 unx     2887 b- defN 24-Apr-19 06:41 gaea_operator/utils/compress.py
--rw-r--r--  2.0 unx      532 b- defN 24-Apr-22 07:24 gaea_operator/utils/consts.py
--rw-r--r--  2.0 unx     2114 b- defN 24-Apr-22 07:24 gaea_operator/utils/file.py
--rw-r--r--  2.0 unx     1533 b- defN 24-Apr-19 06:41 gaea_operator/utils/import_module.py
--rw-r--r--  2.0 unx    11768 b- defN 24-Apr-26 09:16 gaea_operator/utils/model_template.py
--rw-r--r--  2.0 unx     1680 b- defN 24-Apr-19 06:41 gaea_operator/utils/registry.py
--rw-r--r--  2.0 unx     1000 b- defN 24-Apr-19 06:41 gaea_operator/utils/tensor.py
--rw-r--r--  2.0 unx      301 b- defN 24-Apr-19 06:41 gaea_operator/utils/time.py
--rw-r--r--  2.0 unx      590 b- defN 24-Apr-22 07:24 gaea_operator-4.1.2.dev1.data/data/yaml/deploy_parameter.yaml
--rw-r--r--  2.0 unx     4864 b- defN 24-Apr-19 06:41 gaea_operator-4.1.2.dev1.data/data/yaml/object_detection.yaml
--rw-r--r--  2.0 unx     1499 b- defN 24-Apr-26 09:16 gaea_operator-4.1.2.dev1.data/data/yaml/parameter.yaml
--rw-r--r--  2.0 unx     1656 b- defN 24-Apr-26 09:16 gaea_operator-4.1.2.dev1.data/data/yaml/parameter_c.yaml
--rw-r--r--  2.0 unx     9833 b- defN 24-Apr-26 07:33 gaea_operator-4.1.2.dev1.data/data/yaml/pipeline.yaml
--rw-r--r--  2.0 unx    13839 b- defN 24-Apr-26 09:16 gaea_operator-4.1.2.dev1.data/data/yaml/train_parameter.yaml
--rw-r--r--  2.0 unx     1212 b- defN 24-Apr-26 09:16 gaea_operator-4.1.2.dev1.data/data/yaml/transform_parameter.yaml
--rw-r--r--  2.0 unx     2244 b- defN 24-Apr-26 09:24 gaea_operator-4.1.2.dev1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-26 09:24 gaea_operator-4.1.2.dev1.dist-info/WHEEL
--rw-r--r--  2.0 unx       14 b- defN 24-Apr-26 09:24 gaea_operator-4.1.2.dev1.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx    15996 b- defN 24-Apr-26 09:24 gaea_operator-4.1.2.dev1.dist-info/RECORD
-154 files, 671495 bytes uncompressed, 182380 bytes compressed:  72.8%
+-rw-r--r--  2.0 unx     1271 b- defN 24-Apr-26 11:37 gaea_operator/pipelines/resnet_pipeline/train_parameter.yaml
+-rw-r--r--  2.0 unx     1121 b- defN 24-Apr-26 11:37 gaea_operator/pipelines/resnet_pipeline/transform_parameter.yaml
+-rw-r--r--  2.0 unx      181 b- defN 24-Apr-26 11:37 gaea_operator/trainer/__init__.py
+-rw-r--r--  2.0 unx     6988 b- defN 24-May-09 08:43 gaea_operator/trainer/trainer.py
+-rw-r--r--  2.0 unx      187 b- defN 24-Apr-26 11:37 gaea_operator/transform/__init__.py
+-rw-r--r--  2.0 unx     3307 b- defN 24-Apr-26 11:37 gaea_operator/transform/cvt_copy_model.py
+-rw-r--r--  2.0 unx      776 b- defN 24-Apr-26 11:37 gaea_operator/transform/transform.py
+-rw-r--r--  2.0 unx     1951 b- defN 24-May-09 03:12 gaea_operator/utils/__init__.py
+-rw-r--r--  2.0 unx     6183 b- defN 24-May-09 03:12 gaea_operator/utils/accelerator.py
+-rw-r--r--  2.0 unx     2887 b- defN 24-Apr-26 11:37 gaea_operator/utils/compress.py
+-rw-r--r--  2.0 unx      532 b- defN 24-Apr-26 11:37 gaea_operator/utils/consts.py
+-rw-r--r--  2.0 unx     2114 b- defN 24-Apr-26 11:37 gaea_operator/utils/file.py
+-rw-r--r--  2.0 unx     1533 b- defN 24-Apr-26 11:37 gaea_operator/utils/import_module.py
+-rw-r--r--  2.0 unx     7440 b- defN 24-May-09 03:12 gaea_operator/utils/model_template.py
+-rw-r--r--  2.0 unx     1680 b- defN 24-Apr-26 11:37 gaea_operator/utils/registry.py
+-rw-r--r--  2.0 unx     1000 b- defN 24-Apr-26 11:37 gaea_operator/utils/tensor.py
+-rw-r--r--  2.0 unx      301 b- defN 24-Apr-26 11:37 gaea_operator/utils/time.py
+-rw-r--r--  2.0 unx      590 b- defN 24-Apr-26 11:37 gaea_operator-4.1.2.dev4.data/data/yaml/deploy_parameter.yaml
+-rw-r--r--  2.0 unx     4864 b- defN 24-Apr-26 11:37 gaea_operator-4.1.2.dev4.data/data/yaml/object_detection.yaml
+-rw-r--r--  2.0 unx     1499 b- defN 24-May-09 03:12 gaea_operator-4.1.2.dev4.data/data/yaml/parameter.yaml
+-rw-r--r--  2.0 unx     4665 b- defN 24-May-09 03:12 gaea_operator-4.1.2.dev4.data/data/yaml/parameter_c.yaml
+-rw-r--r--  2.0 unx     9743 b- defN 24-May-09 03:12 gaea_operator-4.1.2.dev4.data/data/yaml/pipeline.yaml
+-rw-r--r--  2.0 unx     1254 b- defN 24-May-09 08:21 gaea_operator-4.1.2.dev4.data/data/yaml/train_parameter.yaml
+-rw-r--r--  2.0 unx     1212 b- defN 24-May-09 03:12 gaea_operator-4.1.2.dev4.data/data/yaml/transform_parameter.yaml
+-rw-r--r--  2.0 unx     2833 b- defN 24-May-09 08:46 gaea_operator-4.1.2.dev4.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-May-09 08:46 gaea_operator-4.1.2.dev4.dist-info/WHEEL
+-rw-r--r--  2.0 unx       14 b- defN 24-May-09 08:46 gaea_operator-4.1.2.dev4.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx    17508 b- defN 24-May-09 08:46 gaea_operator-4.1.2.dev4.dist-info/RECORD
+167 files, 779697 bytes uncompressed, 202741 bytes compressed:  74.0%
```

## zipnote {}

```diff
@@ -42,14 +42,17 @@
 
 Filename: gaea_operator/components/package/package.py
 Comment: 
 
 Filename: gaea_operator/components/train/__init__.py
 Comment: 
 
+Filename: gaea_operator/components/train/change_ppyoloe_plus.py
+Comment: 
+
 Filename: gaea_operator/components/train/codetr.py
 Comment: 
 
 Filename: gaea_operator/components/train/convnext.py
 Comment: 
 
 Filename: gaea_operator/components/train/ocrnet.py
@@ -63,14 +66,17 @@
 
 Filename: gaea_operator/components/train/resnet.py
 Comment: 
 
 Filename: gaea_operator/components/transform/__init__.py
 Comment: 
 
+Filename: gaea_operator/components/transform/change_ocrnet.py
+Comment: 
+
 Filename: gaea_operator/components/transform/change_ppyoloe_plus.py
 Comment: 
 
 Filename: gaea_operator/components/transform/codetr.py
 Comment: 
 
 Filename: gaea_operator/components/transform/convnext.py
@@ -306,14 +312,38 @@
 
 Filename: gaea_operator/pipelines/__init__.py
 Comment: 
 
 Filename: gaea_operator/pipelines/create_ppl.py
 Comment: 
 
+Filename: gaea_operator/pipelines/change_ocrnet_pipeline/__init__.py
+Comment: 
+
+Filename: gaea_operator/pipelines/change_ocrnet_pipeline/pipeline.py
+Comment: 
+
+Filename: gaea_operator/pipelines/change_ocrnet_pipeline/pipeline.yaml
+Comment: 
+
+Filename: gaea_operator/pipelines/change_ocrnet_pipeline/train_parameter.yaml
+Comment: 
+
+Filename: gaea_operator/pipelines/change_ocrnet_pipeline/transform_parameter.yaml
+Comment: 
+
+Filename: gaea_operator/pipelines/change_ppyoloe_plus_pipeline/__init__.py
+Comment: 
+
+Filename: gaea_operator/pipelines/change_ppyoloe_plus_pipeline/pipeline.py
+Comment: 
+
+Filename: gaea_operator/pipelines/change_ppyoloe_plus_pipeline/pipeline.yaml
+Comment: 
+
 Filename: gaea_operator/pipelines/change_ppyoloe_plus_pipeline/train_parameter.yaml
 Comment: 
 
 Filename: gaea_operator/pipelines/change_ppyoloe_plus_pipeline/transform_parameter.yaml
 Comment: 
 
 Filename: gaea_operator/pipelines/codetr_pipeline/__init__.py
@@ -339,26 +369,35 @@
 
 Filename: gaea_operator/pipelines/convnext_pipeline/transform_parameter.yaml
 Comment: 
 
 Filename: gaea_operator/pipelines/ocrnet_pipeline/__init__.py
 Comment: 
 
-Filename: gaea_operator/pipelines/ocrnet_pipeline/ocrnet_pipeline.py
+Filename: gaea_operator/pipelines/ocrnet_pipeline/pipeline.py
 Comment: 
 
 Filename: gaea_operator/pipelines/ocrnet_pipeline/pipeline.yaml
 Comment: 
 
 Filename: gaea_operator/pipelines/ocrnet_pipeline/train_parameter.yaml
 Comment: 
 
 Filename: gaea_operator/pipelines/ocrnet_pipeline/transform_parameter.yaml
 Comment: 
 
+Filename: gaea_operator/pipelines/ppyoloe_plus_pipeline/__init__.py
+Comment: 
+
+Filename: gaea_operator/pipelines/ppyoloe_plus_pipeline/pipeline.py
+Comment: 
+
+Filename: gaea_operator/pipelines/ppyoloe_plus_pipeline/pipeline.yaml
+Comment: 
+
 Filename: gaea_operator/pipelines/ppyoloe_plus_pipeline/train_parameter.yaml
 Comment: 
 
 Filename: gaea_operator/pipelines/ppyoloe_plus_pipeline/transform_parameter.yaml
 Comment: 
 
 Filename: gaea_operator/pipelines/repvit_pipeline/train_parameter.yaml
@@ -366,18 +405,18 @@
 
 Filename: gaea_operator/pipelines/repvit_pipeline/transform_parameter.yaml
 Comment: 
 
 Filename: gaea_operator/pipelines/resnet_pipeline/__init__.py
 Comment: 
 
-Filename: gaea_operator/pipelines/resnet_pipeline/pipeline.yaml
+Filename: gaea_operator/pipelines/resnet_pipeline/pipeline.py
 Comment: 
 
-Filename: gaea_operator/pipelines/resnet_pipeline/resnet_pipeline.py
+Filename: gaea_operator/pipelines/resnet_pipeline/pipeline.yaml
 Comment: 
 
 Filename: gaea_operator/pipelines/resnet_pipeline/train_parameter.yaml
 Comment: 
 
 Filename: gaea_operator/pipelines/resnet_pipeline/transform_parameter.yaml
 Comment: 
@@ -423,41 +462,41 @@
 
 Filename: gaea_operator/utils/tensor.py
 Comment: 
 
 Filename: gaea_operator/utils/time.py
 Comment: 
 
-Filename: gaea_operator-4.1.2.dev1.data/data/yaml/deploy_parameter.yaml
+Filename: gaea_operator-4.1.2.dev4.data/data/yaml/deploy_parameter.yaml
 Comment: 
 
-Filename: gaea_operator-4.1.2.dev1.data/data/yaml/object_detection.yaml
+Filename: gaea_operator-4.1.2.dev4.data/data/yaml/object_detection.yaml
 Comment: 
 
-Filename: gaea_operator-4.1.2.dev1.data/data/yaml/parameter.yaml
+Filename: gaea_operator-4.1.2.dev4.data/data/yaml/parameter.yaml
 Comment: 
 
-Filename: gaea_operator-4.1.2.dev1.data/data/yaml/parameter_c.yaml
+Filename: gaea_operator-4.1.2.dev4.data/data/yaml/parameter_c.yaml
 Comment: 
 
-Filename: gaea_operator-4.1.2.dev1.data/data/yaml/pipeline.yaml
+Filename: gaea_operator-4.1.2.dev4.data/data/yaml/pipeline.yaml
 Comment: 
 
-Filename: gaea_operator-4.1.2.dev1.data/data/yaml/train_parameter.yaml
+Filename: gaea_operator-4.1.2.dev4.data/data/yaml/train_parameter.yaml
 Comment: 
 
-Filename: gaea_operator-4.1.2.dev1.data/data/yaml/transform_parameter.yaml
+Filename: gaea_operator-4.1.2.dev4.data/data/yaml/transform_parameter.yaml
 Comment: 
 
-Filename: gaea_operator-4.1.2.dev1.dist-info/METADATA
+Filename: gaea_operator-4.1.2.dev4.dist-info/METADATA
 Comment: 
 
-Filename: gaea_operator-4.1.2.dev1.dist-info/WHEEL
+Filename: gaea_operator-4.1.2.dev4.dist-info/WHEEL
 Comment: 
 
-Filename: gaea_operator-4.1.2.dev1.dist-info/top_level.txt
+Filename: gaea_operator-4.1.2.dev4.dist-info/top_level.txt
 Comment: 
 
-Filename: gaea_operator-4.1.2.dev1.dist-info/RECORD
+Filename: gaea_operator-4.1.2.dev4.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## gaea_operator/components/eval/ppyoloe_plus.py

```diff
@@ -1,15 +1,14 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 """
 # @Time    : 2024/2/23
 # @Author  : yanxiaodong
 # @File    : eval_component.py
 """
-import json
 import os
 from argparse import ArgumentParser
 
 from gaea_tracker import ExperimentTracker
 from bcelogger.base_logger import setup_logger
 from windmilltrainingv1.client.training_api_job import parse_job_name
 from windmillclient.client.windmill_client import WindmillClient
@@ -26,14 +25,15 @@
     Parse arguments.
     """
     parser = ArgumentParser()
     parser.add_argument("--windmill-ak", type=str, default=os.environ.get("WINDMILL_AK"))
     parser.add_argument("--windmill-sk", type=str, default=os.environ.get("WINDMILL_SK"))
     parser.add_argument("--windmill-endpoint", type=str, default=os.environ.get("WINDMILL_ENDPOINT"))
     parser.add_argument("--project-name", type=str, default=os.environ.get("PROJECT_NAME"))
+    parser.add_argument("--scene", type=str, default=os.environ.get("SCENE"))
     parser.add_argument("--tracking-uri", type=str, default=os.environ.get("TRACKING_URI"))
     parser.add_argument("--experiment-name", type=str, default=os.environ.get("EXPERIMENT_NAME"))
     parser.add_argument("--experiment-kind", type=str, default=os.environ.get("EXPERIMENT_KIND"))
     parser.add_argument("--dataset-name", type=str, default=os.environ.get("DATASET_NAME"))
     parser.add_argument("--advanced-parameters",
                         type=str,
                         default=os.environ.get("ADVANCED_PARAMETERS", "{}"))
```

## gaea_operator/components/package/package.py

```diff
@@ -18,26 +18,27 @@
 
 from gaea_operator.config import Config
 from gaea_operator.model import format_name
 from gaea_operator.utils import read_file, \
     write_file, \
     find_dir, \
     get_accelerator, \
-    get_model_template
+    ModelTemplate
 
 
 def parse_args():
     """
     Parse arguments.
     """
     parser = ArgumentParser()
     parser.add_argument("--windmill-ak", type=str, default=os.environ.get("WINDMILL_AK"))
     parser.add_argument("--windmill-sk", type=str, default=os.environ.get("WINDMILL_SK"))
     parser.add_argument("--windmill-endpoint", type=str, default=os.environ.get("WINDMILL_ENDPOINT"))
     parser.add_argument("--project-name", type=str, default=os.environ.get("PROJECT_NAME"))
+    parser.add_argument("--scene", type=str, default=os.environ.get("SCENE"))
     parser.add_argument("--public-model-store",
                         type=str,
                         default=os.environ.get("PUBLIC_MODEL_STORE", "workspaces/public/modelstores/public"))
     parser.add_argument("--tracking-uri", type=str, default=os.environ.get("TRACKING_URI"))
     parser.add_argument("--experiment-name", type=str, default=os.environ.get("EXPERIMENT_NAME"))
     parser.add_argument("--experiment-kind", type=str, default=os.environ.get("EXPERIMENT_KIND"))
     parser.add_argument("--ensemble-model-name",
@@ -72,15 +73,19 @@
                                        experiment_kind=args.experiment_kind,
                                        project_name=args.project_name)
     setup_logger(config=dict(file_name=os.path.join(args.output_uri, "worker.log")))
 
     response = read_file(input_dir=args.input_model_uri)
     metadata = response["artifact"]["metadata"]
 
-    model_template = get_model_template(name=args.algorithm, model_store_name=args.public_model_store)
+    model_template = ModelTemplate(windmill_client=windmill_client,
+                                   scene=args.scene,
+                                   accelerator=args.accelerator,
+                                   model_store_name=args.public_model_store,
+                                   algorithm=args.algorithm)
     ppyoloe_plus_model_to_res = {parse_model_name(model_template.suggest_template_model()).local_name: response}
 
     # 1. 下载ensemble template 模型
     ensemble_artifact_name = get_name(object_name=model_template.suggest_template_ensemble(), version="latest")
     bcelogger.info(f"Dumping model {ensemble_artifact_name} to {args.output_model_uri}")
     windmill_client.dump_models(artifact_name=ensemble_artifact_name,
                                 location_style="Triton",
```

## gaea_operator/components/train/codetr.py

```diff
@@ -93,18 +93,19 @@
     # 2. 合并val分片数据集
     coco_dataset.concat_dataset(dataset_name=args.val_dataset_name,
                                 output_dir=dataset_uri,
                                 usage=CocoDataset.usages[1])
 
     train_advanced_parameters = json.loads(args.advanced_parameters)
     # 3. 下载预训练模型
-    pretrain_name = "co_dino_swin_l"
+    pretrain_name = "co_detr_swin_l"
     pretrain_name = ModelName(workspace_id=parse_modelstore_name(args.public_model_store).workspace_id,
                               model_store_name=parse_modelstore_name(args.public_model_store).local_name,
                               local_name=pretrain_name).get_name()
+    bcelogger.info(f"Pretrain model name: {pretrain_name}")
     pretrain_model_uri = "/home/windmill/tmp/pretrain"
     windmill_client.download_artifact(object_name=pretrain_name, version="latest", output_uri=pretrain_model_uri)
 
     # 4. 生成训练配置文件，固定名字 train_config.yaml，保存在 model_uri
     config = CoDETRConfig(windmill_client=windmill_client, tracker_client=tracker_client)
     config.write_train_config(dataset_uri=dataset_uri,
                               model_uri=args.output_model_uri,
```

## gaea_operator/components/train/ocrnet.py

```diff
@@ -33,14 +33,15 @@
     Parse arguments.
     """
     parser = ArgumentParser()
     parser.add_argument("--windmill-ak", type=str, default=os.environ.get("WINDMILL_AK"))
     parser.add_argument("--windmill-sk", type=str, default=os.environ.get("WINDMILL_SK"))
     parser.add_argument("--windmill-endpoint", type=str, default=os.environ.get("WINDMILL_ENDPOINT"))
     parser.add_argument("--project-name", type=str, default=os.environ.get("PROJECT_NAME"))
+    parser.add_argument("--scene", type=str, default=os.environ.get("SCENE"))
     parser.add_argument("--public-model-store",
                         type=str,
                         default=os.environ.get("PUBLIC_MODEL_STORE", "workspaces/public/modelstores/public"))
     parser.add_argument("--tracking-uri", type=str, default=os.environ.get("TRACKING_URI"))
     parser.add_argument("--experiment-name", type=str, default=os.environ.get("EXPERIMENT_NAME"))
     parser.add_argument("--experiment-kind", type=str, default=os.environ.get("EXPERIMENT_KIND"))
     parser.add_argument("--train-dataset-name", type=str, default=os.environ.get("TRAIN_DATASET_NAME"))
@@ -69,28 +70,46 @@
                                        experiment_name=args.experiment_name,
                                        experiment_kind=args.experiment_kind,
                                        project_name=args.project_name)
     setup_logger(config=dict(file_name=os.path.join(args.output_uri, "worker.log")))
 
     dataset_uri = "/home/windmill/tmp/dataset"
     dataset = CityscapesDataset(windmill_client=windmill_client, work_dir=tracker_client.work_dir)
+    if args.scene is not None and len(args.scene) > 0:
+        bcelogger.info(f"Scene: {args.scene}")
+        tags = [{"scene": args.scene}]
+        response = windmill_client.list_model(workspace_id=parse_modelstore_name(args.public_model_store).workspace_id,
+                                              model_store_name=parse_modelstore_name(
+                                                  args.public_model_store).local_name,
+                                              tags=tags)
+        if len(response.results) == 0:
+            bcelogger.warning(f"No model found with tags: {tags}")
+        for model in response.results:
+            model_name = model["name"]
+            bcelogger.info(f"Model: {model_name}")
+            if "baseDatasetName" in model["tags"]:
+                args.base_train_dataset_name = model["tags"]["baseDatasetName"]
+                args.base_val_dataset_name = model["tags"]["baseDatasetName"]
     # 1. 合并train分片数据集
     dataset.concat_dataset(dataset_name=args.train_dataset_name,
+                           base_dataset_name=args.base_train_dataset_name,
                            output_dir=dataset_uri,
                            usage=CityscapesDataset.usages[0])
 
     # 2. 合并val分片数据集
     dataset.concat_dataset(dataset_name=args.val_dataset_name,
+                           base_dataset_name=args.base_val_dataset_name,
                            output_dir=dataset_uri,
                            usage=CityscapesDataset.usages[1])
 
     # 3. 下载预训练模型
     pretrain_name = ModelName(workspace_id=parse_modelstore_name(args.public_model_store).workspace_id,
                               model_store_name=parse_modelstore_name(args.public_model_store).local_name,
                               local_name="ocrnet_hrnet_w18_ssld").get_name()
+    bcelogger.info(f"Pretrain model name: {pretrain_name}")
     pretrain_model_uri = "/home/windmill/tmp/pretrain"
     windmill_client.download_artifact(object_name=pretrain_name, version="latest", output_uri=pretrain_model_uri)
 
     # 4. 生成训练配置文件，固定名字 train_config.yaml，保存在 model_uri
     config = OCRNetConfig(windmill_client=windmill_client, tracker_client=tracker_client)
     config.write_train_config(
         dataset_uri=dataset_uri,
@@ -100,15 +119,18 @@
 
     # 5. 训练
     trainer = Trainer(framework="PaddlePaddle", tracker_client=tracker_client)
     metric_names = [LOSS_METRIC_NAME, MIOU_METRIC_NAME]
     trainer.track_model_score(metric_names=metric_names)
     trainer.launch()
     advanced_parameters = json.loads(args.advanced_parameters)
-    input_shape = [-1, 3, int(advanced_parameters['eval_height']), int(advanced_parameters['eval_width'])]
+    if 'change' in advanced_parameters['model_type']:
+        input_shape = [-1, 6, int(advanced_parameters['eval_height']), int(advanced_parameters['eval_width'])]
+    else:
+        input_shape = [-1, 3, int(advanced_parameters['eval_height']), int(advanced_parameters['eval_width'])]
     trainer.paddleseg_export(model_dir=args.output_model_uri, input_shape=input_shape)
 
     # 6. 创建模型
     metric_name = SEMANTIC_SEGMENTATION_MIOU_METRIC_NAME
     current_score = get_score_from_file(filepath=os.path.join(args.output_model_uri, "metric.json"),
                                         metric_name=metric_name)
     best_score, version = Model(windmill_client=windmill_client).get_best_model_score(
```

## gaea_operator/components/train/ppyoloe_plus.py

```diff
@@ -35,14 +35,15 @@
     Parse arguments.
     """
     parser = ArgumentParser()
     parser.add_argument("--windmill-ak", type=str, default=os.environ.get("WINDMILL_AK"))
     parser.add_argument("--windmill-sk", type=str, default=os.environ.get("WINDMILL_SK"))
     parser.add_argument("--windmill-endpoint", type=str, default=os.environ.get("WINDMILL_ENDPOINT"))
     parser.add_argument("--project-name", type=str, default=os.environ.get("PROJECT_NAME"))
+    parser.add_argument("--scene", type=str, default=os.environ.get("SCENE"))
     parser.add_argument("--public-model-store",
                         type=str,
                         default=os.environ.get("PUBLIC_MODEL_STORE", "workspaces/public/modelstores/public"))
     parser.add_argument("--tracking-uri", type=str, default=os.environ.get("TRACKING_URI"))
     parser.add_argument("--experiment-name", type=str, default=os.environ.get("EXPERIMENT_NAME"))
     parser.add_argument("--experiment-kind", type=str, default=os.environ.get("EXPERIMENT_KIND"))
     parser.add_argument("--train-dataset-name",
@@ -67,28 +68,44 @@
     args, _ = parser.parse_known_args()
 
     return args
 
 
 def ppyoloe_plus_train(args):
     """
-    Train component for ppyoloe_plus_m model.
+    Train component for ppyoloe_plus model.
     """
     windmill_client = WindmillClient(ak=args.windmill_ak,
                                      sk=args.windmill_sk,
                                      endpoint=args.windmill_endpoint)
     tracker_client = ExperimentTracker(windmill_client=windmill_client,
                                        tracking_uri=args.tracking_uri,
                                        experiment_name=args.experiment_name,
                                        experiment_kind=args.experiment_kind,
                                        project_name=args.project_name)
     setup_logger(config=dict(file_name=os.path.join(args.output_uri, "worker.log")))
 
     dataset_uri = "/home/windmill/tmp/dataset"
     coco_dataset = CocoDataset(windmill_client=windmill_client, work_dir=tracker_client.work_dir)
+    if args.scene is not None and len(args.scene) > 0:
+        bcelogger.info(f"Scene: {args.scene}")
+        tags = [{"scene": args.scene}]
+        response = windmill_client.list_model(workspace_id=parse_modelstore_name(args.public_model_store).workspace_id,
+                                              model_store_name=parse_modelstore_name(
+                                                  args.public_model_store).local_name,
+                                              tags=tags)
+        if len(response.results) == 0:
+            bcelogger.warning(f"No model found with tags: {tags}")
+        for model in response.results:
+            model_name = model["name"]
+            bcelogger.info(f"Model: {model_name}")
+            if "baseDatasetName" in model["tags"]:
+                args.base_train_dataset_name = model["tags"]["baseDatasetName"]
+                args.base_val_dataset_name = model["tags"]["baseDatasetName"]
+
     # 1. 合并train分片数据集
     coco_dataset.concat_dataset(dataset_name=args.train_dataset_name,
                                 output_dir=dataset_uri,
                                 usage=CocoDataset.usages[0])
 
     # 2. 合并val分片数据集
     coco_dataset.concat_dataset(dataset_name=args.val_dataset_name,
@@ -101,14 +118,15 @@
                            "ppyoloe_m": "ppyoloe_crn_m_obj365_pretrained",
                            "ppyoloe_l": "ppyoloe_crn_l_obj365_pretrained",
                            "ppyoloe_x": "ppyoloe_crn_x_obj365_pretrained"}
     pretrain_name = model_type_pretrain[train_advanced_parameters["model_type"]]
     pretrain_name = ModelName(workspace_id=parse_modelstore_name(args.public_model_store).workspace_id,
                               model_store_name=parse_modelstore_name(args.public_model_store).local_name,
                               local_name=pretrain_name).get_name()
+    bcelogger.info(f"Pretrain model name: {pretrain_name}")
     pretrain_model_uri = "/home/windmill/tmp/pretrain"
     windmill_client.download_artifact(object_name=pretrain_name, version="latest", output_uri=pretrain_model_uri)
 
     # 4. 生成训练配置文件，固定名字 train_config.yaml，保存在 model_uri
     config = PPYOLOEPLUSMConfig(windmill_client=windmill_client, tracker_client=tracker_client)
     config.write_train_config(dataset_uri=dataset_uri,
                               model_uri=args.output_model_uri,
```

## gaea_operator/components/train/resnet.py

```diff
@@ -33,14 +33,15 @@
     Parse arguments.
     """
     parser = ArgumentParser()
     parser.add_argument("--windmill-ak", type=str, default=os.environ.get("WINDMILL_AK"))
     parser.add_argument("--windmill-sk", type=str, default=os.environ.get("WINDMILL_SK"))
     parser.add_argument("--windmill-endpoint", type=str, default=os.environ.get("WINDMILL_ENDPOINT"))
     parser.add_argument("--project-name", type=str, default=os.environ.get("PROJECT_NAME"))
+    parser.add_argument("--scene", type=str, default=os.environ.get("SCENE"))
     parser.add_argument("--public-model-store",
                         type=str,
                         default=os.environ.get("PUBLIC_MODEL_STORE", "workspaces/public/modelstores/public"))
     parser.add_argument("--tracking-uri", type=str, default=os.environ.get("TRACKING_URI"))
     parser.add_argument("--experiment-name", type=str, default=os.environ.get("EXPERIMENT_NAME"))
     parser.add_argument("--experiment-kind", type=str, default=os.environ.get("EXPERIMENT_KIND"))
     parser.add_argument("--train-dataset-name", type=str, default=os.environ.get("TRAIN_DATASET_NAME"))
@@ -69,28 +70,46 @@
                                        experiment_name=args.experiment_name,
                                        experiment_kind=args.experiment_kind,
                                        project_name=args.project_name)
     setup_logger(config=dict(file_name=os.path.join(args.output_uri, "worker.log")))
 
     dataset_uri = "/home/windmill/tmp/dataset"
     classify_dataset = ImageNetDataset(windmill_client=windmill_client, work_dir=tracker_client.work_dir)
+    if args.scene is not None and len(args.scene) > 0:
+        bcelogger.info(f"Scene: {args.scene}")
+        tags = [{"scene": args.scene}]
+        response = windmill_client.list_model(workspace_id=parse_modelstore_name(args.public_model_store).workspace_id,
+                                              model_store_name=parse_modelstore_name(
+                                                  args.public_model_store).local_name,
+                                              tags=tags)
+        if len(response.results) == 0:
+            bcelogger.warning(f"No model found with tags: {tags}")
+        for model in response.results:
+            model_name = model["name"]
+            bcelogger.info(f"Model: {model_name}")
+            if "baseDatasetName" in model["tags"]:
+                args.base_train_dataset_name = model["tags"]["baseDatasetName"]
+                args.base_val_dataset_name = model["tags"]["baseDatasetName"]
     # 1. 合并train分片数据集
     classify_dataset.concat_dataset(dataset_name=args.train_dataset_name,
+                                    base_dataset_name=args.base_train_dataset_name,
                                     output_dir=dataset_uri,
                                     usage=ImageNetDataset.usages[0])
 
     # 2. 合并val分片数据集
     classify_dataset.concat_dataset(dataset_name=args.val_dataset_name,
+                                    base_dataset_name=args.base_val_dataset_name,
                                     output_dir=dataset_uri,
                                     usage=ImageNetDataset.usages[1])
 
     # 3. 下载预训练模型
     pretrain_name = ModelName(workspace_id=parse_modelstore_name(args.public_model_store).workspace_id,
                               model_store_name=parse_modelstore_name(args.public_model_store).local_name,
                               local_name="ResNet18_pretrained").get_name()
+    bcelogger.info(f"Pretrain model name: {pretrain_name}")
     pretrain_model_uri = "/home/windmill/tmp/pretrain"
     windmill_client.download_artifact(object_name=pretrain_name, version="latest", output_uri=pretrain_model_uri)
 
     # 4. 生成训练配置文件，固定名字 train_config.yaml，保存在 model_uri
     config = ResNetConfig(windmill_client=windmill_client, tracker_client=tracker_client)
     config.write_train_config(
         dataset_uri=dataset_uri,
```

## gaea_operator/components/transform/change_ppyoloe_plus.py

```diff
@@ -13,28 +13,29 @@
 from gaea_tracker import ExperimentTracker
 from bcelogger.base_logger import setup_logger
 from windmillmodelv1.client.model_api_model import parse_model_name
 from windmillclient.client.windmill_client import WindmillClient
 from gaea_operator.transform import Transform
 
 from gaea_operator.config import Config
-from gaea_operator.utils import write_file, read_file, get_model_template, ModelTemplate
+from gaea_operator.utils import write_file, read_file, ModelTemplate
 from gaea_operator.config.generate_transform_config import KEY_ACCELERATOR
 from gaea_operator.config import PPYOLOEPLUSMConfig
 
 
 def parse_args():
     """
     Parse arguments.
     """
     parser = ArgumentParser()
     parser.add_argument("--windmill-ak", type=str, default=os.environ.get("WINDMILL_AK"))
     parser.add_argument("--windmill-sk", type=str, default=os.environ.get("WINDMILL_SK"))
     parser.add_argument("--windmill-endpoint", type=str, default=os.environ.get("WINDMILL_ENDPOINT"))
     parser.add_argument("--project-name", type=str, default=os.environ.get("PROJECT_NAME"))
+    parser.add_argument("--scene", type=str, default=os.environ.get("SCENE"))
     parser.add_argument("--public-model-store",
                         type=str,
                         default=os.environ.get("PUBLIC_MODEL_STORE", "workspaces/public/modelstores/public"))
     parser.add_argument("--tracking-uri", type=str, default=os.environ.get("TRACKING_URI"))
     parser.add_argument("--experiment-name", type=str, default=os.environ.get("EXPERIMENT_NAME"))
     parser.add_argument("--experiment-kind", type=str, default=os.environ.get("EXPERIMENT_KIND"))
     parser.add_argument("--transform-model-name",
@@ -53,15 +54,15 @@
     parser.add_argument("--output-uri", type=str, default=os.environ.get("OUTPUT_URI"))
 
     args, _ = parser.parse_known_args()
 
     return args
 
 
-def ppyoloe_plus_transform(args):
+def change_ppyoloe_plus_transform(args):
     """
     Transform component for model.
     """
     windmill_client = WindmillClient(ak=args.windmill_ak,
                                      sk=args.windmill_sk,
                                      endpoint=args.windmill_endpoint)
     tracker_client = ExperimentTracker(windmill_client=windmill_client,
@@ -78,16 +79,19 @@
     # 1. 生成转换配置文件，固定名称 transform_config.yaml 保存在 output_model_uri
     transform_advanced_parameters = json.loads(args.advanced_parameters)
     transform_advanced_parameters.update({KEY_ACCELERATOR: args.accelerator})
     config = PPYOLOEPLUSMConfig(windmill_client=windmill_client, tracker_client=tracker_client, metadata=metadata)
     config.write_transform_config(model_uri=args.output_model_uri, advanced_parameters=transform_advanced_parameters)
 
     # 2. 下载模板模型
-    model_template = get_model_template(name=ModelTemplate.CHANGE_PPYOLOE_PLUS_NAME,
-                                        model_store_name=args.public_model_store)
+    model_template = ModelTemplate(windmill_client=windmill_client,
+                                   scene=args.scene,
+                                   accelerator=args.accelerator,
+                                   model_store_name=args.public_model_store,
+                                   algorithm=ModelTemplate.CHANGE_PPYOLOE_PLUS_NAME)
     model = model_template.suggest_template_model()
     windmill_client.download_artifact(object_name=model, version="latest", output_uri=args.output_model_uri)
 
     # 3. 生成配置文件
     modify_model_names = {'model': [model]}
     config.write_sub_model_config(transform_model_uri=args.output_model_uri, modify_model_names=modify_model_names)
 
@@ -102,20 +106,20 @@
     model_store_name = model_name_instance.model_store_name
     local_name = model_name_instance.local_name
     response = windmill_client.create_model(artifact_uri=args.output_model_uri,
                                             workspace_id=workspace_id,
                                             model_store_name=model_store_name,
                                             local_name=local_name,
                                             display_name=args.transform_model_display_name,
-                                            category="Image/ObjectDetection",
+                                            category="Image/ChangeDetection/ObjectDetection",
                                             artifact_metadata=config.metadata,
                                             model_formats=[
-                                                Config.device_type2model_format[args.accelerator]])
+                                                Config.accelerator2model_format[args.accelerator]])
     bcelogger.info(f"Model {args.transform_model_name} created response: {response}")
 
     # 4. 输出文件
     write_file(obj=json.loads(response.raw_data), output_dir=args.output_model_uri)
 
 
 if __name__ == "__main__":
     args = parse_args()
-    ppyoloe_plus_transform(args=args)
+    change_ppyoloe_plus_transform(args=args)
```

## gaea_operator/components/transform/codetr.py

```diff
@@ -106,15 +106,15 @@
                                             workspace_id=workspace_id,
                                             model_store_name=model_store_name,
                                             local_name=local_name,
                                             display_name=args.transform_model_display_name,
                                             category="Image/ObjectDetection",
                                             artifact_metadata=config.metadata,
                                             model_formats=[
-                                                Config.device_type2model_format[args.accelerator]])
+                                                Config.accelerator2model_format[args.accelerator]])
     bcelogger.info(f"Model {args.transform_model_name} created response: {response}")
 
     # 6. 输出文件
     write_file(obj=json.loads(response.raw_data), output_dir=args.output_model_uri)
 
 
 if __name__ == "__main__":
```

## gaea_operator/components/transform/convnext.py

```diff
@@ -105,15 +105,15 @@
                                             workspace_id=workspace_id,
                                             model_store_name=model_store_name,
                                             local_name=local_name,
                                             display_name=args.transform_model_display_name,
                                             category="Image/ImageClassification/MultiClass",
                                             artifact_metadata=config.metadata,
                                             model_formats=[
-                                                Config.device_type2model_format[args.accelerator]])
+                                                Config.accelerator2model_format[args.accelerator]])
     bcelogger.info(f"Model {args.transform_model_name} created response: {response}")
 
     # 6. 输出文件
     write_file(obj=json.loads(response.raw_data), output_dir=args.output_model_uri)
 
 
 if __name__ == "__main__":
```

## gaea_operator/components/transform/ocrnet.py

```diff
@@ -13,28 +13,29 @@
 from gaea_tracker import ExperimentTracker
 from bcelogger.base_logger import setup_logger
 from windmillmodelv1.client.model_api_model import parse_model_name
 from windmillclient.client.windmill_client import WindmillClient
 from gaea_operator.transform import Transform
 
 from gaea_operator.config import Config
-from gaea_operator.utils import write_file, read_file, get_model_template, ModelTemplate
+from gaea_operator.utils import write_file, read_file, ModelTemplate
 from gaea_operator.config.generate_transform_config import KEY_ACCELERATOR, MODEL_NAME_DICT
 from gaea_operator.config import OCRNetConfig
 
 
 def parse_args():
     """
     Parse arguments.
     """
     parser = ArgumentParser()
     parser.add_argument("--windmill-ak", type=str, default=os.environ.get("WINDMILL_AK"))
     parser.add_argument("--windmill-sk", type=str, default=os.environ.get("WINDMILL_SK"))
     parser.add_argument("--windmill-endpoint", type=str, default=os.environ.get("WINDMILL_ENDPOINT"))
     parser.add_argument("--project-name", type=str, default=os.environ.get("PROJECT_NAME"))
+    parser.add_argument("--scene", type=str, default=os.environ.get("SCENE"))
     parser.add_argument("--public-model-store",
                         type=str,
                         default=os.environ.get("PUBLIC_MODEL_STORE", "workspaces/public/modelstores/public"))
     parser.add_argument("--tracking-uri", type=str, default=os.environ.get("TRACKING_URI"))
     parser.add_argument("--experiment-name", type=str, default=os.environ.get("EXPERIMENT_NAME"))
     parser.add_argument("--experiment-kind", type=str, default=os.environ.get("EXPERIMENT_KIND"))
     parser.add_argument("--transform-model-name",
@@ -75,21 +76,24 @@
     response = windmill_client.get_artifact(object_name=input_model_response['artifact']["objectName"],
                                             version=str(input_model_response['artifact']["version"]))
     metadata = response.metadata
 
     # 1. 生成转换配置文件，固定名称 transform_config.yaml 保存在 output_model_uri
     transform_advanced_parameters = json.loads(args.advanced_parameters)
     transform_advanced_parameters.update({KEY_ACCELERATOR: args.accelerator})
-    transform_advanced_parameters['max_box_num'] = 1
     config = OCRNetConfig(windmill_client=windmill_client, tracker_client=tracker_client, metadata=metadata)
 
     config.write_transform_config(model_uri=args.output_model_uri, advanced_parameters=transform_advanced_parameters)
 
     # 2. 下载模板模型
-    model_template = get_model_template(name=ModelTemplate.OCRNET_NAME, model_store_name=args.public_model_store)
+    model_template = ModelTemplate(windmill_client=windmill_client,
+                                   scene=args.scene,
+                                   accelerator=args.accelerator,
+                                   model_store_name=args.public_model_store,
+                                   algorithm=ModelTemplate.OCRNET_NAME)
     model = model_template.suggest_template_model()
     windmill_client.download_artifact(object_name=model, version="latest", output_uri=args.output_model_uri)
 
     # 3. 生成配置文件
     modify_model_names = {'model': [model]}
     config.write_sub_model_config(transform_model_uri=args.output_model_uri,
                                   modify_model_names=modify_model_names)
@@ -108,15 +112,15 @@
                                             workspace_id=workspace_id,
                                             model_store_name=model_store_name,
                                             local_name=local_name,
                                             display_name=args.transform_model_display_name,
                                             category="Image/SemanticSegmentation",
                                             artifact_metadata=config.metadata,
                                             model_formats=[
-                                                Config.device_type2model_format[args.accelerator]])
+                                                Config.accelerator2model_format[args.accelerator]])
     bcelogger.info(f"Model {args.transform_model_name} created response: {response}")
 
     # 6. 输出文件
     write_file(obj=json.loads(response.raw_data), output_dir=args.output_model_uri)
 
 
 if __name__ == "__main__":
```

## gaea_operator/components/transform/ppyoloe_plus.py

```diff
@@ -13,28 +13,29 @@
 from gaea_tracker import ExperimentTracker
 from bcelogger.base_logger import setup_logger
 from windmillmodelv1.client.model_api_model import parse_model_name
 from windmillclient.client.windmill_client import WindmillClient
 from gaea_operator.transform import Transform
 
 from gaea_operator.config import Config
-from gaea_operator.utils import write_file, read_file, get_model_template, ModelTemplate
+from gaea_operator.utils import write_file, read_file, ModelTemplate
 from gaea_operator.config.generate_transform_config import KEY_ACCELERATOR
 from gaea_operator.config import PPYOLOEPLUSMConfig
 
 
 def parse_args():
     """
     Parse arguments.
     """
     parser = ArgumentParser()
     parser.add_argument("--windmill-ak", type=str, default=os.environ.get("WINDMILL_AK"))
     parser.add_argument("--windmill-sk", type=str, default=os.environ.get("WINDMILL_SK"))
     parser.add_argument("--windmill-endpoint", type=str, default=os.environ.get("WINDMILL_ENDPOINT"))
     parser.add_argument("--project-name", type=str, default=os.environ.get("PROJECT_NAME"))
+    parser.add_argument("--scene", type=str, default=os.environ.get("SCENE"))
     parser.add_argument("--public-model-store",
                         type=str,
                         default=os.environ.get("PUBLIC_MODEL_STORE", "workspaces/public/modelstores/public"))
     parser.add_argument("--tracking-uri", type=str, default=os.environ.get("TRACKING_URI"))
     parser.add_argument("--experiment-name", type=str, default=os.environ.get("EXPERIMENT_NAME"))
     parser.add_argument("--experiment-kind", type=str, default=os.environ.get("EXPERIMENT_KIND"))
     parser.add_argument("--transform-model-name",
@@ -78,15 +79,19 @@
     # 1. 生成转换配置文件，固定名称 transform_config.yaml 保存在 output_model_uri
     transform_advanced_parameters = json.loads(args.advanced_parameters)
     transform_advanced_parameters.update({KEY_ACCELERATOR: args.accelerator})
     config = PPYOLOEPLUSMConfig(windmill_client=windmill_client, tracker_client=tracker_client, metadata=metadata)
     config.write_transform_config(model_uri=args.output_model_uri, advanced_parameters=transform_advanced_parameters)
 
     # 2. 下载模板模型
-    model_template = get_model_template(name=ModelTemplate.PPYOLOE_PLUS_NAME, model_store_name=args.public_model_store)
+    model_template = ModelTemplate(windmill_client=windmill_client,
+                                   scene=args.scene,
+                                   accelerator=args.accelerator,
+                                   model_store_name=args.public_model_store,
+                                   algorithm=ModelTemplate.PPYOLOE_PLUS_NAME)
     model = model_template.suggest_template_model()
     windmill_client.download_artifact(object_name=model, version="latest", output_uri=args.output_model_uri)
 
     # 3. 生成配置文件
     modify_model_names = {'model': [model]}
     config.write_sub_model_config(transform_model_uri=args.output_model_uri, modify_model_names=modify_model_names)
 
@@ -104,15 +109,15 @@
                                             workspace_id=workspace_id,
                                             model_store_name=model_store_name,
                                             local_name=local_name,
                                             display_name=args.transform_model_display_name,
                                             category="Image/ObjectDetection",
                                             artifact_metadata=config.metadata,
                                             model_formats=[
-                                                Config.device_type2model_format[args.accelerator]])
+                                                Config.accelerator2model_format[args.accelerator]])
     bcelogger.info(f"Model {args.transform_model_name} created response: {response}")
 
     # 4. 输出文件
     write_file(obj=json.loads(response.raw_data), output_dir=args.output_model_uri)
 
 
 if __name__ == "__main__":
```

## gaea_operator/components/transform/repvit.py

```diff
@@ -105,15 +105,15 @@
                                             workspace_id=workspace_id,
                                             model_store_name=model_store_name,
                                             local_name=local_name,
                                             display_name=args.transform_model_display_name,
                                             category="Image/ImageClassification/MultiClass",
                                             artifact_metadata=config.metadata,
                                             model_formats=[
-                                                Config.device_type2model_format[args.accelerator]])
+                                                Config.accelerator2model_format[args.accelerator]])
     bcelogger.info(f"Model {args.transform_model_name} created response: {response}")
 
     # 6. 输出文件
     write_file(obj=json.loads(response.raw_data), output_dir=args.output_model_uri)
 
 
 if __name__ == "__main__":
```

## gaea_operator/components/transform/resnet.py

```diff
@@ -13,28 +13,29 @@
 from gaea_tracker import ExperimentTracker
 from bcelogger.base_logger import setup_logger
 from windmillmodelv1.client.model_api_model import parse_model_name
 from windmillclient.client.windmill_client import WindmillClient
 from gaea_operator.transform import Transform
 
 from gaea_operator.config import Config
-from gaea_operator.utils import write_file, read_file, get_model_template, ModelTemplate
+from gaea_operator.utils import write_file, read_file, ModelTemplate
 from gaea_operator.config.generate_transform_config import KEY_ACCELERATOR
 from gaea_operator.config import ResNetConfig
 
 
 def parse_args():
     """
     Parse arguments.
     """
     parser = ArgumentParser()
     parser.add_argument("--windmill-ak", type=str, default=os.environ.get("WINDMILL_AK"))
     parser.add_argument("--windmill-sk", type=str, default=os.environ.get("WINDMILL_SK"))
     parser.add_argument("--windmill-endpoint", type=str, default=os.environ.get("WINDMILL_ENDPOINT"))
     parser.add_argument("--project-name", type=str, default=os.environ.get("PROJECT_NAME"))
+    parser.add_argument("--scene", type=str, default=os.environ.get("SCENE"))
     parser.add_argument("--public-model-store",
                         type=str,
                         default=os.environ.get("PUBLIC_MODEL_STORE", "workspaces/public/modelstores/public"))
     parser.add_argument("--tracking-uri", type=str, default=os.environ.get("TRACKING_URI"))
     parser.add_argument("--experiment-name", type=str, default=os.environ.get("EXPERIMENT_NAME"))
     parser.add_argument("--experiment-kind", type=str, default=os.environ.get("EXPERIMENT_KIND"))
     parser.add_argument("--transform-model-name",
@@ -80,15 +81,19 @@
     transform_advanced_parameters = json.loads(args.advanced_parameters)
     transform_advanced_parameters.update({KEY_ACCELERATOR: args.accelerator})
     transform_advanced_parameters['max_box_num'] = 1  # dummy for debug
     config = ResNetConfig(windmill_client=windmill_client, tracker_client=tracker_client, metadata=metadata)
     config.write_transform_config(model_uri=args.output_model_uri, advanced_parameters=transform_advanced_parameters)
 
     # 2. 下载模板模型
-    model_template = get_model_template(name=ModelTemplate.RESNET_NAME, model_store_name=args.public_model_store)
+    model_template = ModelTemplate(windmill_client=windmill_client,
+                                   scene=args.scene,
+                                   accelerator=args.accelerator,
+                                   model_store_name=args.public_model_store,
+                                   algorithm=ModelTemplate.RESNET_NAME)
     model = model_template.suggest_template_model()
     windmill_client.download_artifact(object_name=model, version="latest", output_uri=args.output_model_uri)
 
     # 3. 生成配置文件
     modify_model_names = {'model': [model]}
     config.write_sub_model_config(transform_model_uri=args.output_model_uri, modify_model_names=modify_model_names)
 
@@ -106,15 +111,15 @@
                                             workspace_id=workspace_id,
                                             model_store_name=model_store_name,
                                             local_name=local_name,
                                             display_name=args.transform_model_display_name,
                                             category="Image/ImageClassification/MultiClass",
                                             artifact_metadata=config.metadata,
                                             model_formats=[
-                                                Config.device_type2model_format[args.accelerator]])
+                                                Config.accelerator2model_format[args.accelerator]])
     bcelogger.info(f"Model {args.transform_model_name} created response: {response}")
 
     # 6. 输出文件
     write_file(obj=json.loads(response.raw_data), output_dir=args.output_model_uri)
 
 
 if __name__ == "__main__":
```

## gaea_operator/components/transform_eval/transform_eval.py

```diff
@@ -20,29 +20,29 @@
 from windmillclient.client.windmill_client import WindmillClient
 from tritonv2.evaluator import evaluate
 
 from gaea_operator.config import Config
 from gaea_operator.metric import EvalMetricAnalysis, Metric
 from gaea_operator.utils import find_dir, \
     read_file, \
-    get_model_template, \
     get_accelerator, \
     ModelTemplate, \
     DEFAULT_TRITON_CONFIG_FILE_NAME
 
 
 def parse_args():
     """
     Parse arguments.
     """
     parser = ArgumentParser()
     parser.add_argument("--windmill-ak", type=str, default=os.environ.get("WINDMILL_AK"))
     parser.add_argument("--windmill-sk", type=str, default=os.environ.get("WINDMILL_SK"))
     parser.add_argument("--windmill-endpoint", type=str, default=os.environ.get("WINDMILL_ENDPOINT"))
     parser.add_argument("--project-name", type=str, default=os.environ.get("PROJECT_NAME"))
+    parser.add_argument("--scene", type=str, default=os.environ.get("SCENE"))
     parser.add_argument("--public-model-store",
                         type=str,
                         default=os.environ.get("PUBLIC_MODEL_STORE", "workspaces/public/modelstores/public"))
     parser.add_argument("--tracking-uri", type=str, default=os.environ.get("TRACKING_URI"))
     parser.add_argument("--experiment-name", type=str, default=os.environ.get("EXPERIMENT_NAME"))
     parser.add_argument("--experiment-kind", type=str, default=os.environ.get("EXPERIMENT_KIND"))
     parser.add_argument("--accelerator", type=str, default=os.environ.get("ACCELERATOR", "t4"))
@@ -61,33 +61,38 @@
 
 
 def package_model_by_template(windmill_client: WindmillClient,
                               tracker_client: ExperimentTracker,
                               metadata: Dict,
                               input_model_uri: str,
                               output_model_uri: str,
-                              model_template: ModelTemplate):
+                              ensemble_name: str,
+                              pre_name: str,
+                              post_name: str,
+                              model_name: str,
+                              accelerator: str):
     """
     Package model by template.
     """
-    pre = parse_model_name(model_template.suggest_template_preprocess()).local_name
-    post = parse_model_name(model_template.suggest_template_postprocess()).local_name
-    model = parse_model_name(model_template.suggest_template_model()).local_name
-    ensemble = parse_model_name(model_template.suggest_template_ensemble()).local_name
+    pre = pre_name
+    post = post_name
+    model = model_name
+    ensemble = parse_model_name(ensemble_name).local_name
     modify_model_names = {
         'preprocess': [pre],
         'postprocess': [post],
         'ensemble': [ensemble]
     }
 
     config = Config(windmill_client=windmill_client, tracker_client=tracker_client, metadata=metadata)
     config.write_triton_package_config(transform_model_uri=input_model_uri,
                                        ensemble_model_uri=output_model_uri,
                                        modify_model_names=modify_model_names,
-                                       ensemble_local_name=ensemble)
+                                       ensemble_local_name=ensemble,
+                                       accelerator=accelerator)
 
     pre_uri = os.path.join(output_model_uri, pre)
     shutil.copyfile(src=os.path.join(find_dir(pre_uri), DEFAULT_TRITON_CONFIG_FILE_NAME),
                     dst=os.path.join(pre_uri, DEFAULT_TRITON_CONFIG_FILE_NAME))
 
     post_uri = os.path.join(output_model_uri, post)
     shutil.copyfile(src=os.path.join(find_dir(post_uri), DEFAULT_TRITON_CONFIG_FILE_NAME),
@@ -116,29 +121,41 @@
                                        project_name=args.project_name)
     setup_logger(config=dict(file_name=os.path.join(args.output_uri, "worker.log")))
     response = read_file(input_dir=args.input_model_uri)
     metadata = response["artifact"]["metadata"]
 
     output_model_uri = "/home/windmill/tmp/model"
     # 1. 下载ensemble template 模型
-    model_template = get_model_template(name=args.algorithm, model_store_name=args.public_model_store)
-    ensemble_artifact_name = get_name(object_name=model_template.suggest_template_ensemble(), version="latest")
+    model_template = ModelTemplate(windmill_client=windmill_client,
+                                   scene=args.scene,
+                                   accelerator=args.accelerator,
+                                   model_store_name=args.public_model_store,
+                                   algorithm=args.algorithm)
+    ensemble = model_template.suggest_template_ensemble()
+    ensemble_artifact_name = get_name(object_name=ensemble, version="latest")
     bcelogger.info(f"Dumping model {ensemble_artifact_name} to {output_model_uri}")
     windmill_client.dump_models(artifact_name=ensemble_artifact_name,
                                 location_style="Triton",
                                 rename="ensemble",
                                 output_uri=output_model_uri)
 
     # 2. 基于模板文件组装转换后模型包
+    pre = parse_model_name(model_template.suggest_template_preprocess()).local_name
+    post = parse_model_name(model_template.suggest_template_postprocess()).local_name
+    model = parse_model_name(model_template.suggest_template_model()).local_name
     package_model_by_template(windmill_client=windmill_client,
                               tracker_client=tracker_client,
                               metadata=metadata,
                               input_model_uri=args.input_model_uri,
                               output_model_uri=output_model_uri,
-                              model_template=model_template)
+                              ensemble_name=ensemble,
+                              pre_name=pre,
+                              post_name=post,
+                              model_name=model,
+                              accelerator=args.accelerator,)
 
     # 3.评估数据集
     response = read_file(input_dir=args.input_dataset_uri)
     triton_server_extra_args = get_accelerator(name=args.accelerator).suggest_args()
     dataset_instance = parse_dataset_name(name=response["objectName"])
     response = windmill_client.get_dataset(workspace_id=dataset_instance.workspace_id,
                                            project_name=dataset_instance.project_name,
```

## gaea_operator/config/config.py

```diff
@@ -24,15 +24,15 @@
     KEY_MAX_BOX_NUM
 
 
 class Config(metaclass=ABCMeta):
     """
     Config write for train, transform and package.
     """
-    device_type2model_format = {Accelerator.T4: "TensorRT",
+    accelerator2model_format = {Accelerator.T4: "TensorRT",
                                 Accelerator.A100: "TensorRT",
                                 Accelerator.V100: "TensorRT",
                                 Accelerator.R200: "PaddleLite"}
 
     def __init__(self, windmill_client: WindmillClient, tracker_client: ExperimentTracker, metadata: Dict = {}):
         self.windmill_client = windmill_client
         self.tracker_client = tracker_client
@@ -51,15 +51,15 @@
                            advanced_parameters: dict,
                            pretrain_model_uri: str):
         """
         Config write for train.
         """
         pass
 
-    def write_eval_config(self, dataset_uri: str, model_uri: str,):
+    def write_eval_config(self, dataset_uri: str, model_uri: str, ):
         """
         Config write for eval.
         """
         pass
 
     def write_transform_config(self, model_uri: str, advanced_parameters: dict):
         """
@@ -76,22 +76,24 @@
         """
         pass
 
     def write_triton_package_config(self,
                                     transform_model_uri: str,
                                     ensemble_model_uri: str,
                                     modify_model_names: dict,
-                                    ensemble_local_name: str):
+                                    ensemble_local_name: str,
+                                    accelerator: str):
         """
         Config write for package.
         """
         cfg = ModifyPackageFiles(ensemble_model_uri=ensemble_model_uri,
                                  metadata=self.metadata,
                                  modify_model_names=modify_model_names,
-                                 ensemble_local_name=ensemble_local_name)
+                                 ensemble_local_name=ensemble_local_name,
+                                 accelerator=accelerator)
         cfg.modify_ppyoloe()
 
     def write_ensemble_config(self, ensemble_model_uri: str, model_config: Dict):
         """
         Config write for ensemble.
         """
         cfg = ModifyEnsembleFile(ensemble_model_uri=ensemble_model_uri,
@@ -111,15 +113,15 @@
 
         input_size = InputSize(width=int(advanced_parameters[KEY_EVAL_WIDTH]),
                                height=int(advanced_parameters[KEY_EVAL_HEIGHT]))
 
         meta_data = ModelMetadata(**self._metadata)
         meta_data.inputSize = input_size
         maxBoxNum = int(advanced_parameters[KEY_MAX_BOX_NUM]) \
-                                if KEY_MAX_BOX_NUM in advanced_parameters else 1
+            if KEY_MAX_BOX_NUM in advanced_parameters else 1
         meta_data.maxBoxNum = maxBoxNum
         advanced_parameters = {
             'inferenceMaxBatchSize': int(advanced_parameters[KEY_MAX_BATCH_SIZE]),
             'maxBoxNum': maxBoxNum,
             'evalWidth': int(advanced_parameters[KEY_EVAL_WIDTH]),
             'evalHeight': int(advanced_parameters[KEY_EVAL_HEIGHT])}
```

## gaea_operator/config/generate_transform_config.py

```diff
@@ -19,17 +19,17 @@
 MODEL_NAME_DICT = {"ppyoloe": ["image", "scale_factor"],
                    "change-ppyoloe": ["image", "tmp_image", "scale_factor"],
                    "vit-base": ["x"],
                    "resnet": ["x"],
                    "ocrnet": ["x"],
                    "maskformer": ["x"],
                    "change-ocrnet": ["x", "tmp_image"],
-                   "convnext": ["input"],
+                   "convnext": ["raw"],
                    "codetr": ["input"],
-                   "repvit": ["input"]
+                   "repvit": ["raw"]
                    }
 
 KEY_SOURCE_FRAMEWORK = 'source_framework'
 KEY_ACCELERATOR = 'accelerator'
 KEY_MODEL_TYPE = 'model_type'
 KEY_EVAL_WIDTH = 'eval_width'
 KEY_EVAL_HEIGHT = 'eval_height'
@@ -100,15 +100,15 @@
             "ocrnet" in model_name:
         bcelogger.warning("maskformer and ocrnet not support batchsize > 1")
         batch = 1
         input_shape['x'] = [batch, 3, height, width]
         if "change" in model_name:
             input_shape['x'] = [batch, 6, height, width]
     elif "convnext" in model_name or "repvit" in model_name:
-        input_shape['input'] = [batch, 3, height, width]
+        input_shape['raw'] = [batch, 3, height, width]
     elif "codetr" in model_name:
         input_shape['input'] = [1, 3, height, width]
         bcelogger.warning("codetr not support batchsize > 1")
     else:
         raise ValueError("model name not in model list")
     return input_shape
 
@@ -153,15 +153,15 @@
     conf_thres = float(advanced_parameters[KEY_CONF_THRESHOLD]) if KEY_CONF_THRESHOLD in advanced_parameters else None
     iou_thres = float(advanced_parameters[KEY_IOU_THRESHOLD]) if KEY_IOU_THRESHOLD in advanced_parameters else None
     drop_nms = False
 
     pipeline_cfg = []
 
     source_framework = advanced_parameters[KEY_SOURCE_FRAMEWORK].lower()
-    accelerator = advanced_parameters[KEY_ACCELERATOR].lower()
+    accelerator = advanced_parameters[KEY_ACCELERATOR].split("/")[-1].lower()
 
     nms_params = None
     onnx_op_flag = False
 
     if max_boxes is not None and conf_thres is not None and iou_thres is not None:
         nms_params = {"max_boxes": max_boxes,
                       "conf_thres": conf_thres,
@@ -193,50 +193,67 @@
 
     # check args
     if source_framework not in FRAMEWORK_LIST:
         raise ValueError("{} is not supported".format(source_framework))
     if accelerator not in ACCELERATOR_LIST:
         raise ValueError("{} is not supported".format(accelerator))
 
-    # convert_op_list = []
+    model_name = advanced_parameters[KEY_MODEL_TYPE].lower()
     # kunlun 
     if accelerator == "r200":
+        OnnxToOnnxParam = {}  # R200 不做预处理内置
         OnnxToKunlunParam = {}
         if source_framework == "paddle":
-            if onnx_op_flag and len(OnnxToOnnxParam) != 0 and nms_params is not None:
-                # raise ValueError("nms_params is not supported for paddle to kunlun")
-                bcelogger.warning("ingore nms_params:[max_boxes, conf_thres ,iou_thres, drop_nms] for paddle to kunlun")
-                OnnxToOnnxParam["nms_params"] = None
-
-            if onnx_op_flag and len(OnnxToOnnxParam) != 0:
+            if 'ppyoloe' not in model_name: # 除ppyoloe之外的模型
                 PaddleToOnnxParam = {}
                 PaddleToOnnxParam["type"] = "PaddleToOnnx"
                 PaddleToOnnxParam["input_shape"] = input_shape
                 pipeline_cfg.append(PaddleToOnnxParam)
 
-                pipeline_cfg.append(OnnxToOnnxParam)
-
                 OnnxToKunlunParam['type'] = 'OnnxToKunlun'
                 OnnxToKunlunParam['device_type'] = accelerator
-                if len(OnnxToOnnxParam) > 0 and 'transpose' in OnnxToOnnxParam and OnnxToOnnxParam['transpose']:
-                    OnnxToKunlunParam["input_shape"] = _trans_shape(input_shape)
-                else:
-                    OnnxToKunlunParam["input_shape"] = input_shape
+                OnnxToKunlunParam["input_shape"] = input_shape
+                if KEY_PRECISION in advanced_parameters and advanced_parameters[KEY_PRECISION] == 'fp16':
+                    OnnxToKunlunParam['dtype'] = 'fp16'
+                    if 'ocrnet' in model_name:
+                        OnnxToKunlunParam['convert_params'] = {
+                            "op_precision":
+                                {"nn.softmax": "fp32",
+                                "nn.general_batch_matmul": "fp32"}}
+                    if 'codetr' in model_name:
+                        OnnxToKunlunParam['convert_params'] = {
+                            "fusion_pattern": ["fuse_add_maskformer", 
+                                                "fuse_attention_maskformer", 
+                                                "fuse_ms_deform_attn", 
+                                                "remove_where"],
+                            "op_precision": {"clip": "fp32",
+                                            "divide": "fp32",
+                                            "log": "fp32",
+                                            "sigmoid": "fp32",
+                                            "subtract": "fp32"}}
+                    if 'maskformer' in model_name:
+                        OnnxToKunlunParam['convert_params'] = {
+                            "fusion_pattern": ["fuse_add_maskformer", 
+                                                "fuse_attention_maskformer"]}
                 pipeline_cfg.append(OnnxToKunlunParam)
             else:
                 PaddleToKunlunParam = {}
                 PaddleToKunlunParam["type"] = "PaddleToKunlun"
                 PaddleToKunlunParam['device_type'] = accelerator
                 PaddleToKunlunParam["input_shape"] = input_shape
+                PaddleToKunlunParam['dtype'] = advanced_parameters[KEY_PRECISION] \
+                    if KEY_PRECISION in advanced_parameters else 'fp32'
                 # convert_op_list.append(PaddleToKunlunParam)
                 pipeline_cfg.append(PaddleToKunlunParam)
 
         elif source_framework == "onnx":
             OnnxToKunlunParam['type'] = 'OnnxToKunlun'
             OnnxToKunlunParam["input_shape"] = input_shape
+            OnnxToKunlunParam['dtype'] = advanced_parameters[KEY_PRECISION] \
+                if KEY_PRECISION in advanced_parameters else 'fp32'
             pipeline_cfg.append(OnnxToKunlunParam)
 
             if onnx_op_flag and len(OnnxToOnnxParam) != 0:
                 pipeline_cfg.insert(0, OnnxToOnnxParam)
         else:
             raise NotImplementedError("{} is not supported".format(source_framework))
     elif accelerator in ACCELERATOR_LIST:
@@ -286,16 +303,16 @@
             cmd += f" --workspace=12288"
         if KEY_PRECISION not in advanced_parameters or \
             advanced_parameters[KEY_PRECISION].lower() in ["fp32", "float32"]:
             pass
         else:
             if KEY_PRECISION in advanced_parameters:
                 cmd += f" --{advanced_parameters[KEY_PRECISION]}"
-        model_type = advanced_parameters[KEY_MODEL_TYPE].lower()
-        if model_type in ['codetr']:
+
+        if model_name in ['codetr']:
             cmd += f" --staticPlugins=/usr/src/tensorrt/plugins/libmmdeploy_tensorrt_ops.so"
         bcelogger.info(f"OnnxToTensorrt cmd = {cmd}")
 
         OnnxToTensorrtParam["cmd"] = cmd
 
         pipeline_cfg.append(OnnxToTensorrtParam)
     # bitmain
@@ -327,18 +344,19 @@
     """
     get mean/std from meta.yaml
     """
     yaml_data = metadata
     model_input_name = ['x']
     if 'ppyoloe' in model_name:
         model_input_name = ['image']
-    if 'change' in model_name:
-        model_input_name.append('tmp_image')
-    if 'convnext' in model_name or 'codetr' in model_name \
-        or 'repvit' in model_name:
+        if 'change' in model_name:
+            model_input_name.append('tmp_image')
+    if 'convnext' in model_name or 'repvit' in model_name:
+        model_input_name = ['raw']
+    if 'codetr' in model_name:
         model_input_name = ['input']
 
     if 'artifact' in yaml_data and 'metadata' in yaml_data['artifact'] \
             and 'algorithmParameters' in yaml_data['artifact']['metadata']:
         alg_param = yaml_data['artifact']['metadata']['algorithmParameters']
     elif 'algorithmParameters' in yaml_data:
         alg_param = yaml_data['algorithmParameters']
@@ -377,18 +395,18 @@
                          transpose=transpose,
                          cfg_path=config_name)
 
 
 if __name__ == "__main__":
     param = {
         KEY_SOURCE_FRAMEWORK: "paddle",
-        KEY_ACCELERATOR: 't4',
-        KEY_MODEL_TYPE: 'ppyoloe_m',
-        KEY_EVAL_WIDTH: '640',
-        KEY_EVAL_HEIGHT: '640',
+        KEY_ACCELERATOR: 'r200',
+        KEY_MODEL_TYPE: 'change-ocrnet',
+        KEY_EVAL_WIDTH: '600',
+        KEY_EVAL_HEIGHT: '600',
         KEY_IOU_THRESHOLD: '0.56',
         KEY_CONF_THRESHOLD: '0.12',
         KEY_MAX_BOX_NUM: '24',
         KEY_MAX_BATCH_SIZE: '123',
         KEY_PRECISION: 'fp16'
     }
-    generate_transform_config(param, './tran.yaml')
+    generate_transform_config(param, './tran.yaml', {})
```

## gaea_operator/config/modify_package_files.py

```diff
@@ -96,15 +96,16 @@
     解析修改模型包 parse.yaml
     """
 
     def __init__(self,
                  modify_model_names: dict,
                  metadata: dict = {},
                  ensemble_model_uri: str = None,
-                 ensemble_local_name: str = None
+                 ensemble_local_name: str = None,
+                 accelerator: str = "T4"
                  ):
         """
             初始化YAML数据类
         """
         # 1. read parameter of modify
         algo_param_dict = self.get_algorithm_parameters(metadata)
         self.eval_width = int(algo_param_dict['evalWidth']) if 'evalWidth' in algo_param_dict else 0
@@ -113,14 +114,15 @@
             if 'inferenceMaxBatchSize' in algo_param_dict else 0
         self.max_box_count = int(algo_param_dict['maxBoxNum']) if 'maxBoxNum' in algo_param_dict else 0
         self.categories = self.get_yaml_categories(metadata)
 
         self.ensemble_model_uri = ensemble_model_uri
         self.modify_model_names = modify_model_names
         self.ensemble_local_name = ensemble_local_name
+        self.accelerator = accelerator.split("/", maxsplit=1)[-1].lower()
 
     def get_algorithm_parameters(self, metadata: dict):
         """
         get algorithm parameter dict from meta.yaml
         """
         yaml_data = metadata
 
@@ -189,16 +191,21 @@
                 # 1. preproc node modify width
                 for m in models:
                     aim_files = self.retrive_path(find_dir(
                         os.path.join(self.ensemble_model_uri, m)), [KEY_PBTXT_NAME])
                     if len(aim_files) > 0:
                         preproc_pbtxt_name = aim_files[0]
                         preproc_config = ModelConfig._create_from_file(preproc_pbtxt_name)
-                        preproc_config.set_preproc_width_height(idx=0, width=self.eval_width, \
-                                                                height=self.eval_height, is_nhwc=True)
+                        if self.accelerator == "r200":
+                            bcelogger.info("modify preproc_config for r200")
+                            preproc_config.set_preproc_width_height(idx=1, width=self.eval_width,
+                                                                    height=self.eval_height, is_nhwc=False)
+                        else:
+                            preproc_config.set_preproc_width_height(idx=0, width=self.eval_width,
+                                                                    height=self.eval_height, is_nhwc=True)
                         preproc_config.write_config_to_file(preproc_pbtxt_name)
                     else:
                         bcelogger.error('do NOT find {} in {}'.format(KEY_PBTXT_NAME, m))
             elif model_type == KEY_MODEL:
                 # 2. model node modify max_batch_size/max_box_count
                 for m in models:
                     if output_uri is not None:
@@ -316,18 +323,75 @@
                 for m in models:
                     if output_uri is not None:
                         aim_files = [os.path.join(output_uri, KEY_PBTXT_NAME)]
                     else:
                         aim_files = self.retrive_path(find_dir(
                                         os.path.join(self.ensemble_model_uri, m)), [KEY_PBTXT_NAME])
                     if len(aim_files) > 0:
-                        ppyoloe_pbtxt_name = aim_files[0]
-                        ppyoloe_config = ModelConfig._create_from_file(ppyoloe_pbtxt_name)
-                        ppyoloe_config.set_field(KEY_MAX_BATCH_SIZE, self.max_batch_size)
-                        ppyoloe_config.write_config_to_file(ppyoloe_pbtxt_name)
+                        model_pbtxt_name = aim_files[0]
+                        model_config = ModelConfig._create_from_file(model_pbtxt_name)
+                        model_config.set_field(KEY_MAX_BATCH_SIZE, self.max_batch_size)
+                        model_config.write_config_to_file(model_pbtxt_name)
+                    else:
+                        bcelogger.error('do NOT find {} in {}'.format(KEY_PBTXT_NAME, m))
+            
+            elif model_type == KEY_POSTPROCESS:
+                for m in models:
+                    # 4. modify parse.yaml
+                    aim_files = self.retrive_path(find_dir(
+                        os.path.join(self.ensemble_model_uri, m)), [KEY_PARSE_NAME])
+                    if len(aim_files) > 0:
+                        parse_name = aim_files[0]
+                        cfg = ParseYamlConfig(parse_name)
+                        # 1. set ensemble name
+                        cfg.modify_ensemble_name(self.ensemble_local_name)
+
+                        # 2. set categories
+                        cfg.modify_categories(self.categories)
+
+                        # 3. save
+                        cfg.save_yaml(parse_name)
+                    else:
+                        bcelogger.error('do NOT find {} in {}'.format(KEY_PARSE_NAME, m))
+            else:
+                bcelogger.error('do NOT support model_type: {}'.format(model_type))
+
+    def modify_ocrnet(self, output_uri: str = None):
+        """
+        for classify/ocrnet
+        """
+        # 1. modify pbtxt
+        for model_type, models in self.modify_model_names.items():
+            if model_type == KEY_PREPROCESS:
+                # 1. preproc node modify width
+                for m in models:
+                    aim_files = self.retrive_path(find_dir(
+                        os.path.join(self.ensemble_model_uri, m)), [KEY_PBTXT_NAME])
+                    if len(aim_files) > 0:
+                        preproc_pbtxt_name = aim_files[0]
+                        preproc_config = ModelConfig._create_from_file(preproc_pbtxt_name)
+                        preproc_config.set_preproc_width_height(idx=0, width=self.eval_width, \
+                                                                height=self.eval_height, is_nhwc=True)
+                        preproc_config.write_config_to_file(preproc_pbtxt_name)
+                    else:
+                        bcelogger.error('do NOT find {} in {}'.format(KEY_PBTXT_NAME, m))
+            elif model_type == KEY_MODEL:
+                # 2. model node modify max_batch_size
+                for m in models:
+                    if output_uri is not None:
+                        aim_files = [os.path.join(output_uri, KEY_PBTXT_NAME)]
+                    else:
+                        aim_files = self.retrive_path(find_dir(
+                                        os.path.join(self.ensemble_model_uri, m)), [KEY_PBTXT_NAME])
+                    if len(aim_files) > 0:
+                        model_pbtxt_name = aim_files[0]
+                        model_config = ModelConfig._create_from_file(model_pbtxt_name)
+                        model_config.set_field(KEY_MAX_BATCH_SIZE, self.max_batch_size)
+                        model_config.set_output_dims(0, dims=[self.eval_width, self.eval_height])
+                        model_config.write_config_to_file(model_pbtxt_name)
                     else:
                         bcelogger.error('do NOT find {} in {}'.format(KEY_PBTXT_NAME, m))
             
             elif model_type == KEY_POSTPROCESS:
                 for m in models:
                     # 4. modify parse.yaml
                     aim_files = self.retrive_path(find_dir(
```

## gaea_operator/config/codetr/codetr_config.py

```diff
@@ -60,23 +60,21 @@
             os.makedirs(model_uri, exist_ok=True)
         self._update_train_metadata(advanced_parameters=new_advanced_parameters)
 
         generate_train_config(new_advanced_parameters,
                               pretrain_model_uri,
                               os.path.join(model_uri, DEFAULT_TRAIN_CONFIG_FILE_NAME))
 
-
     def write_deploy_config(self, advanced_parameters: dict, model_uri: str):
         """
         Config write for export of ppyoloe_plus_m model.
         """
         generate_deploy_config(advanced_parameters, os.path.join(model_uri, DEFAULT_DEPLOY_CONFIG_FILE_NAME))
 
-
-    def write_eval_config(self, dataset_uri: str, model_uri: str, ):
+    def write_eval_config(self, dataset_uri: str, model_uri: str):
         """
         Config write for eval of ppyoloe_plus_m model.
         """
         var_name_vals = [[VAR_KEY_DATA_ROOT, dataset_uri], 
                         [VAR_KEY_VAL_ANNO, os.path.join(dataset_uri, 'val.json')]]
         input_yaml_name = os.path.join(model_uri, DEFAULT_TRAIN_CONFIG_FILE_NAME)
         config_data = modify_var_value(input_yaml_name, var_name_vals)
```

## gaea_operator/config/codetr/template/modify_parameter.py

```diff
@@ -26,30 +26,32 @@
 KEY_CLASS_NAMES = "class_names"
 VAR_KEY_MEAN = "mean"
 VAR_KEY_STD = "std"
 
 KEY_LOAD_FROM = 'load_from'
 KEY_PARAM_SCHEDULER = 'param_scheduler'
 KEY_TYPE = 'type'
-KEY_MILESTONES = 'milestones'    
+KEY_MILESTONES = 'milestones'
 KEY_MULTISTEPLR = "MultiStepLR"
 KEY_TRAIN_DATALOADER = 'train_dataloader'
 KEY_DATASET = 'dataset'
 KEY_PIPELINE = 'pipeline'
 KEY_TRANSFROMS = 'transforms'
 KEY_SCALES = 'scales'
 KEY_CODETR = 'codetr'
 PRETRAINED_MODEL_NAME_CODETR = 'co_dino_swin_l.pth'
 KEY_MODEL_TYPE = 'model_type'
-KEY_CLASS_NAMES_META = ['metainfo.classes', 'test_dataloader.dataset.metainfo.classes', 
-                    'train_dataloader.dataset.metainfo.classes', 
-                    'val_dataloader.dataset.metainfo.classes']
-#eval
+KEY_CLASS_NAMES_META = ['metainfo.classes', 'test_dataloader.dataset.metainfo.classes',
+                        'train_dataloader.dataset.metainfo.classes',
+                        'val_dataloader.dataset.metainfo.classes']
+# eval
 KEY_TEST_DATA_ROOT = ['data_root', 'test_dataloader.dataset.data_root', 'train_dataloader.dataset.data_root']
-KEY_TEST_ANNO_FILES = ['test_dataloader.dataset.ann_file', 'test_evaluator.ann_file']
+KEY_TEST_ANNO_FILES = ['train_dataloader.dataset.ann_file',
+                       'test_dataloader.dataset.ann_file',
+                       'test_evaluator.ann_file']
 # deploy
 KEY_SCORE_THRESH = 'score_thresh'
 KEY_IOU_THRESH = 'iou_thresh'
 DEPLOY_KEY_SCORE_THRESHOLD = 'codebase_config.post_processing.score_threshold'
 DEPLOY_KEY_IOU_THRESHOLD = 'codebase_config.post_processing.iou_threshold'
 DEPLOY_KEY_DEPLOY_INPUT_SHAPE = 'onnx_config.input_shape'
 
@@ -217,31 +219,31 @@
     scales = []
     # step必须为32整数倍
     for width in range(min_width, max_width + 1, 32):
         for height in range(min_height, max_height + 1, 32):
             scales.append((width, height))
 
     if KEY_TRAIN_DATALOADER in yaml_data and KEY_DATASET in yaml_data[KEY_TRAIN_DATALOADER] \
-        and KEY_PIPELINE in yaml_data[KEY_TRAIN_DATALOADER][KEY_DATASET]:
-            for ppl in yaml_data[KEY_TRAIN_DATALOADER][KEY_DATASET][KEY_PIPELINE]:
-                if ppl["type"] == "RandomChoice" and 'transforms' in ppl:
-                    for choices in ppl['transforms']:
-                        for choice in choices:
-                            if choice['type'] == "RandomChoiceResize":
-                                choice['scales'] = scales
+            and KEY_PIPELINE in yaml_data[KEY_TRAIN_DATALOADER][KEY_DATASET]:
+        for ppl in yaml_data[KEY_TRAIN_DATALOADER][KEY_DATASET][KEY_PIPELINE]:
+            if ppl["type"] == "RandomChoice" and 'transforms' in ppl:
+                for choices in ppl['transforms']:
+                    for choice in choices:
+                        if choice['type'] == "RandomChoiceResize":
+                            choice['scales'] = scales
 
 
 def set_schedule_step(yaml_data, max_epochs: int):
     """
         set scheduler step
     """
-    half_epochs =  max(1, max_epochs // 2)
+    half_epochs = max(1, max_epochs // 2)
     if KEY_PARAM_SCHEDULER in yaml_data:
         for scheduler in yaml_data[KEY_PARAM_SCHEDULER]:
-            if KEY_MULTISTEPLR  == scheduler[KEY_TYPE]:
+            if KEY_MULTISTEPLR == scheduler[KEY_TYPE]:
                 scheduler[KEY_MILESTONES] = [half_epochs]
                 bcelogger.info('set scheduler milestones to: {}'.format(scheduler[KEY_MILESTONES]))
 
 
 def set_class_names(yaml_data, class_names: list):
     """
     设置yaml数据中的类别名称。
@@ -258,43 +260,41 @@
         set_multi_key_value(yaml_data, multi_key, class_names)
 
 
 def get_pretrained_model_name(model_type, pretrained_model_path):
     """
         get pretrained model absolute path
     """
-    if model_type == KEY_CODETR:
-        return os.path.join(pretrained_model_path, PRETRAINED_MODEL_NAME_CODETR)
-    else:
-        bcelogger.error('do NOT support model type. {} use default pretrained model. {}'.format(
-            model_type, PRETRAINED_MODEL_NAME_CODETR))
-        return os.path.join(pretrained_model_path, PRETRAINED_MODEL_NAME_CODETR)
+    for filepath in os.listdir(pretrained_model_path):
+        if filepath.endswith('.pth'):
+            return os.path.join(pretrained_model_path, filepath)
+
 
 def generate_train_config(
         advanced_parameters: dict,
         pretrain_model_uri: str,
         train_config_name: str
-    ):
+):
     """
         modify parameter by template config
     """
     # 0. list var parameters
     width = advanced_parameters[VAR_KEY_EVAL_WIDTH]
     height = advanced_parameters[VAR_KEY_EVAL_HEIGHT]
     max_epochs = advanced_parameters[VAR_KEY_MAX_EPOCHS]
     batch_size = advanced_parameters[VAR_KEY_BATCH_SIZE]
     data_root = advanced_parameters[VAR_KEY_DATA_ROOT]
     num_lcasses = advanced_parameters[VAR_KEY_NUM_CLASSES]
 
     var_name_vals = [[VAR_KEY_EVAL_WIDTH, width], [VAR_KEY_EVAL_HEIGHT, height],
-                    [VAR_KEY_MAX_EPOCHS, max_epochs], [VAR_KEY_BATCH_SIZE, batch_size],
-                    [VAR_KEY_DATA_ROOT, data_root], [VAR_KEY_NUM_CLASSES, num_lcasses],
-                    [VAR_KEY_TRAIN_ANNO, os.path.join(data_root, 'train.json')],
-                    [VAR_KEY_VAL_ANNO, os.path.join(data_root, 'val.json')],
-                    ]
+                     [VAR_KEY_MAX_EPOCHS, max_epochs], [VAR_KEY_BATCH_SIZE, batch_size],
+                     [VAR_KEY_DATA_ROOT, data_root], [VAR_KEY_NUM_CLASSES, num_lcasses],
+                     [VAR_KEY_TRAIN_ANNO, os.path.join(data_root, 'train.json')],
+                     [VAR_KEY_VAL_ANNO, os.path.join(data_root, 'val.json')],
+                     ]
 
     input_yaml_name = 'train_parameter.yaml'
     bcelogger.info('train parameter name: {}'.format(input_yaml_name))
 
     input_yaml_name = os.path.join(os.path.dirname(os.path.abspath(__file__)), input_yaml_name)
     yaml_data = modify_var_value(input_yaml_name, var_name_vals)
 
@@ -329,21 +329,22 @@
         modify parameter by template config
     """
     input_yaml_name = 'deploy_parameter.yaml'
     input_yaml_name = os.path.join(os.path.dirname(os.path.abspath(__file__)), input_yaml_name)
     bcelogger.info('deploy parameter name: {}'.format(input_yaml_name))
     with open(input_yaml_name) as f:
         yaml_data = yaml.load(f, Loader=yaml.Loader)
-        set_multi_key_value(yaml_data, DEPLOY_KEY_SCORE_THRESHOLD, 
-            advanced_parameters[KEY_SCORE_THRESH] if KEY_SCORE_THRESH in advanced_parameters else 0.001)
-        set_multi_key_value(yaml_data, DEPLOY_KEY_IOU_THRESHOLD, 
-            advanced_parameters[KEY_IOU_THRESH] if KEY_IOU_THRESH in advanced_parameters else 0.5)
-        set_multi_key_value(yaml_data, DEPLOY_KEY_DEPLOY_INPUT_SHAPE, 
-            [int(advanced_parameters[VAR_KEY_EVAL_WIDTH]), int(advanced_parameters[VAR_KEY_EVAL_HEIGHT])])
-        
+        set_multi_key_value(yaml_data, DEPLOY_KEY_SCORE_THRESHOLD,
+                            advanced_parameters[KEY_SCORE_THRESH] if KEY_SCORE_THRESH in advanced_parameters else 0.001)
+        set_multi_key_value(yaml_data, DEPLOY_KEY_IOU_THRESHOLD,
+                            advanced_parameters[KEY_IOU_THRESH] if KEY_IOU_THRESH in advanced_parameters else 0.5)
+        set_multi_key_value(yaml_data, DEPLOY_KEY_DEPLOY_INPUT_SHAPE,
+                            [int(advanced_parameters[VAR_KEY_EVAL_WIDTH]),
+                             int(advanced_parameters[VAR_KEY_EVAL_HEIGHT])])
+
     bcelogger.info('begin to save yaml. {}'.format(deploy_config_name))
     save_yaml(yaml_data, deploy_config_name)
     bcelogger.info('write deploy config finish.')
 
 
 def modify_eval_config(config_data: dict, params: list):
     """
```

## gaea_operator/config/ocrnet/ocrnet_config.py

```diff
@@ -87,15 +87,15 @@
                                modify_model_names: dict,
                                ensemble_model_uri: str = None,
                                ensemble_local_name: str = None):
         """
         Config write for package.
         """
         cfg = ModifyPackageFiles(modify_model_names=modify_model_names, metadata=self.metadata)
-        cfg.modify_common_pkg_config(output_uri=transform_model_uri)
+        cfg.modify_ocrnet(output_uri=transform_model_uri)
 
     def _update_train_metadata(self, advanced_parameters: Dict):
         super()._update_train_metadata(advanced_parameters=advanced_parameters)
 
         input_size = InputSize(width=int(advanced_parameters[KEY_EVAL_WIDTH]),
                                height=int(advanced_parameters[KEY_EVAL_HEIGHT]))
         model_meta_data = ModelMetadata(labels=self.labels,
```

## gaea_operator/config/ocrnet/template/modify_train_parameter.py

```diff
@@ -28,15 +28,16 @@
 KEY_CROP_SIZE = 'crop_size'
 KEY_MODEL_TYPE = 'model_type'
 KEY_PRETRAINED = 'model.backbone.pretrained'
 KEY_PRETRAINED_TYPE = 'model.backbone.type'
 
 # model_type -> [type, name]
 MODEL_TYPE_NAME_DICT = {
-    'ocrnet': ['HRNet_W18', 'ocrnet_hrnet_w18_ssld.pdparams']
+    'ocrnet': ['HRNet_W18', 'ocrnet_hrnet_w18_ssld.pdparams'],
+    'change-ocrnet': ['HRNet_W18', 'ocrnet_hrnet_w18_ssld.pdparams'],
 }
 
 
 def get_yaml(yaml_name):
     """
     读取指定YAML文件，并返回解析后的数据。如果读取失败，则返回None。
     
@@ -180,25 +181,43 @@
         model_type_name = MODEL_TYPE_NAME_DICT[model_type]
         set_multi_key_value(yaml_data, KEY_PRETRAINED_TYPE, model_type_name[0])
         set_multi_key_value(yaml_data, KEY_PRETRAINED, os.path.join(pretrained_model_path, model_type_name[1]))
     else:
         bcelogger.error('do NOT support model type. {}'.format(model_type))
 
 
+def get_mean_std(yaml_data):
+    """
+        get train mean/std
+    """
+    transform_ops = yaml_data[KEY_VAL_DATASET][KEY_TRANSFORMS]
+    for _, v in enumerate(transform_ops):
+        if 'mean' in v and 'std' in v:
+            return v['mean'], v['std']
+    return [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]
+
+
 def generate_train_config(
         advanced_parameters: dict,
         metadata: dict,
         train_config_name: str
 ):
     """
         modify parameter by template config
     """
-    input_yaml_name = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'parameter.yaml')
+    if advanced_parameters[KEY_MODEL_TYPE].startswith('change-'):
+        input_yaml_name = 'parameter_c.yaml'
+    else:
+        input_yaml_name = 'parameter.yaml'
+    
+    input_yaml_name = os.path.join(os.path.dirname(os.path.abspath(__file__)), input_yaml_name)
+    bcelogger.info('train parameter name: {}'.format(input_yaml_name))
+
     yaml_data = get_yaml(input_yaml_name)
-    mean, std = [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]
+    mean, std = get_mean_std(yaml_data)
     # 更新metadata
     metadata["algorithmParameters"].update({'mean': mean, 'std': std})
 
     # 1. set correlative parameters
     correlative_parameter_keys = [KEY_EVAL_WIDTH, KEY_EVAL_HEIGHT, KEY_MODEL_TYPE, KEY_PRETRAINED]
     # 1.1 target size
     set_target_size(yaml_data, advanced_parameters[KEY_EVAL_WIDTH], advanced_parameters[KEY_EVAL_HEIGHT])
@@ -248,12 +267,12 @@
 
     setup_logger(config=dict(file_name=os.path.join("/ssd2/lyg/GAEA-PIPE/ocrnet", "worker.log")))
     meta = {'algorithmParameters': {'evalHeight': 512, 'evalWidth': 512},
             'experimentName': None, 'experimentRunID': None, 'extraLoadModel': None,
             'inputSize': {'height': 512, 'width': 512},
             'jobName': None, 'labels': [], 'maxBoxNum': None}
     advanced_parameters = {"iters": "100", "lr_scheduler.learning_rate": "0.001",
-                           "eval_height": "512", "eval_width": "512", "batch_size": "6", "model_type": "ocrnet",
+                           "eval_height": "512", "eval_width": "512", "batch_size": "6", "model_type": "change-ocrnet",
                            "model.backbone.pretrained": "/ssd2/lyg/GAEA-PIPE/ocrnet/pretrained_model"}
     opt.train_config_name = '/ssd2/lyg/GAEA-PIPE/ocrnet/train_config.yaml'
     generate_train_config(advanced_parameters=advanced_parameters,
                           metadata=meta, train_config_name=opt.train_config_name)
```

## gaea_operator/config/ppyoloe_plus/template/parameter.yaml

```diff
@@ -22,15 +22,15 @@
     dataset_dir: dataset # if set, anno_path will be 'dataset_dir/anno_path'
 
 use_gpu: true
 use_xpu: false
 log_iter: 100
 save_dir: output
 # make sure snap_epoch <= epoch
-snapshot_epoch: 5
+snapshot_epoch: 1
 print_flops: false
 
 # Exporting the model
 export:
   post_process: True  # Whether post-processing is included in the network when export model.
   nms: True           # Whether NMS is included in the network when export model.
   benchmark: False    # It is used to testing model performance, if set `True`, post-process and NMS will not be exported.
```

## gaea_operator/config/ppyoloe_plus/template/parameter_c.yaml

```diff
@@ -22,15 +22,15 @@
     dataset_dir: dataset # if set, anno_path will be 'dataset_dir/anno_path'
 
 use_gpu: true
 use_xpu: false
 log_iter: 100
 save_dir: output
 # make sure snap_epoch <= epoch
-snapshot_epoch: 20
+snapshot_epoch: 1
 print_flops: false
 
 # Exporting the model
 export:
   post_process: True  # Whether post-processing is included in the network when export model.
   nms: True           # Whether NMS is included in the network when export model.
   benchmark: False    # It is used to testing model performance, if set `True`, post-process and NMS will not be exported.
```

## gaea_operator/metric/analysis/inference_metric_analysis.py

```diff
@@ -96,17 +96,19 @@
             im_id = item["image_id"]
             im_id_int = self.img_id_str2int[im_id]
             array_item = np.zeros(len(self.labels), dtype=np.int8)
             if item.get("annotations") is None:
                 reference_dict[im_id_int].append(array_item)
                 continue
             for anno in item["annotations"]:
+                if "bbox" in anno and len(anno["bbox"]) == 0:
+                    continue
                 for idx in range(len(anno["labels"])):
                     if isinstance(anno["labels"][idx]["id"], str):
-                        anno["labels"][idx]["id"] = int(anno["labels"][0]["id"])
+                        anno["labels"][idx]["id"] = int(anno["labels"][idx]["id"])
                     if math.isnan(anno["labels"][idx]["id"]):
                         continue
                     # 如果标注标签id不在label,则跳过（修改了标签但是标注没有同步修改）
                     if anno["labels"][idx]["id"] not in self.label_id2index:
                         continue
                     index = self.label_id2index[anno["labels"][idx]["id"]]
                     array_item[index] = 1
@@ -122,15 +124,15 @@
             # 如果预测结果不在 gt里面，是一张未标注的图片，不参与指标计算
             if item.get("annotations") is None or im_id_int not in reference_dict:
                 prediction_list.append(array_item)
                 continue
             for anno in item["annotations"]:
                 for idx in range(len(anno["labels"])):
                     if isinstance(anno["labels"][idx]["id"], str):
-                        anno["labels"][idx]["id"] = int(anno["labels"][0]["id"])
+                        anno["labels"][idx]["id"] = int(anno["labels"][idx]["id"])
                     if math.isnan(anno["labels"][idx]["id"]):
                         continue
                     # 如果预测结果标签id不在label,则跳过（修改了标签但是预测结果没有同步修改）
                     if anno["labels"][idx]["id"] not in self.label_id2index:
                         continue
                     if anno["labels"][idx]["confidence"] > self.conf_threshold:
                         index = self.label_id2index[anno["labels"][idx]["id"]]
```

## gaea_operator/pipelines/__init__.py

```diff
@@ -1,15 +1,14 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 """
 __init__.py
 """
-from gaea_operator.pipelines.ocrnet_pipeline.ocrnet_pipeline import pipeline as ocrnet_pipeline
-from gaea_operator.pipelines.ppyoloe_plus_pipeline.ppyoloe_plus_pipeline import pipeline as ppyoloe_plus_pipeline
-from gaea_operator.pipelines.resnet_pipeline.resnet_pipeline import pipeline as resnet_pipeline
-from gaea_operator.pipelines.codetr_pipeline.codetr_pipeline import pipeline as codetr_pipeline
+from gaea_operator.pipelines.ocrnet_pipeline.pipeline import pipeline as ocrnet_pipeline
+from gaea_operator.pipelines.ppyoloe_plus_pipeline.pipeline import pipeline as ppyoloe_plus_pipeline
+from gaea_operator.pipelines.resnet_pipeline.pipeline import pipeline as resnet_pipeline
 
 category_to_ppls = {
     "Image/SemanticSegmentation": [ocrnet_pipeline()],
-    "Image/ObjectDetection": [ppyoloe_plus_pipeline(), codetr_pipeline()],
+    "Image/ObjectDetection": [ppyoloe_plus_pipeline()],
     "Image/ImageClassification/MultiClass": [resnet_pipeline()]
 }
```

## gaea_operator/pipelines/create_ppl.py

```diff
@@ -6,47 +6,64 @@
 
 import os
 from argparse import ArgumentParser
 from gaea_operator.pipelines import category_to_ppls
 from windmillclient.client.windmill_client import WindmillClient
 from windmillartifactv1.client.artifact_api_artifact import ArtifactContent
 from windmilltrainingv1.client.training_api_pipeline import PipelineName
+from bceinternalsdk.client.paging import PagingRequest
 
 
 # python create_ppl.py --windmill-endpoint http://windmill.baidu-int.com:8340 --windmill-ak e0415220bbc94902b89fa3ceba3d4ca7 --windmill-sk 25f9ad7065b041598ce7711a2e591a2f
 
 if __name__ == "__main__":
     parser = ArgumentParser()
     parser.add_argument("--windmill-endpoint", type=str, default=os.environ.get("WINDMILL_ENDPOINT"))
     parser.add_argument("--windmill-ak", type=str, default=os.environ.get("WINDMILL_AK"))
     parser.add_argument("--windmill-sk", type=str, default=os.environ.get("WINDMILL_SK")) 
 
-    parser.add_argument("--workspace-id", type=str, default="public")
-    parser.add_argument("--project-name", type=str, default="default")
+    parser.add_argument("--workspace-id", type=str, default="")
+    parser.add_argument("--project-name", type=str, default="spiproject")
     args, _ = parser.parse_known_args()
 
     client = WindmillClient(endpoint=args.windmill_endpoint, ak=args.windmill_ak, sk=args.windmill_sk)
     workspace_id = args.workspace_id
+    if workspace_id == "":
+        resp = client.list_workspace(page_request=PagingRequest(order="asc", orderby="created_at"))
+        print("workspace list response {}".format(resp))
+        assert len(resp.results) > 0, "must have greater than one workspace id"
+        workspace_id = resp.results[0]["id"]
+    print("workspace id {}".format(workspace_id))
+
     project_name = args.project_name
+    try:
+        resp = client.get_project(workspace_id=workspace_id, project_name=project_name)
+    except Exception as e:
+        print("get project {} failed, error: {}".format(project_name, e))
+        print("start create project {}".format(project_name))
+        client.create_project(workspace_id=workspace_id, local_name=project_name, display_name=project_name)
 
+    filedir = os.path.dirname(__file__)
     for cat, ppls in category_to_ppls.items():
         for p in ppls:
             print("pipeline name: {}".format(p.name))
-            filepath = "./pipelines/{}_pipeline.yaml".format(p.name)
+            sub_filedir = os.path.join(filedir, "{}_pipeline".format(p.name))
+            filepath = os.path.join(sub_filedir, "pipeline.yaml")
+            print("pipeline compile output file: {}".format(filepath))
             p.compile(save_path=filepath)
 
             ppl_name = PipelineName(workspace_id=workspace_id, project_name=project_name, local_name=p.name)
-            location = client.create_location_with_uri(uri=filepath, object_name=ppl_name.get_name())
+            location = client.create_location_with_uri(uri=sub_filedir, object_name=ppl_name.get_name())
 
             artifact = ArtifactContent(uri=location)
+            print("pipeline artifact uri {}".format(location))
+
+            resp = client.create_pipeline(
+                workspace_id=workspace_id,
+                project_name=project_name,
+                local_name=p.name,
+                display_name=p.name,
+                category=cat,
+                artifact=artifact)
+            print("pipeline: {} created.".format(resp.name))
 
-            try:
-                resp = client.create_pipeline(
-                    workspace_id=workspace_id,
-                    project_name=project_name,
-                    local_name=p.name,
-                    category=cat,
-                    artifact=artifact)
-                print("pipeline: {} created.".format(resp.get("name")))
-            except Exception as e:
-                print(e)
```

## gaea_operator/pipelines/change_ppyoloe_plus_pipeline/train_parameter.yaml

```diff
@@ -29,18 +29,18 @@
   defaultValue: 8
   step: 1
   name: "TrainReader.batch_size"
   help: "是指一次训练(Iteration)所包含的样本数。 Batchsize越大，显存占用越大"
   type: "inputNumber"
 - label: "模型类型"
   options:
-    - "change_ppyoloe_s"
-    - "change_ppyoloe_m"
-    - "change_ppyoloe_l"
-    - "change_ppyoloe_x"
+    - "change-ppyoloe_m"
+    - "change-ppyoloe_s"
+    - "change-ppyoloe_l"
+    - "change-ppyoloe_x"
   name: "model_type"
   defaultIndex: 0
   help: "模型类型越大训练资源越多，训练越慢，精度越高"
   type: "Select"
 - label: "模型训练图像宽度*高度"
   options:
     - "320*320"
```

## gaea_operator/pipelines/change_ppyoloe_plus_pipeline/transform_parameter.yaml

```diff
@@ -45,18 +45,18 @@
     - "fp16"
     - "fp32"
   name: "precision"
   defaultIndex: 0
   type: "Select"
 - label: "模型类型"
   options:
-    - "change_ppyoloe_s"
-    - "change_ppyoloe_m"
-    - "change_ppyoloe_l"
-    - "change_ppyoloe_x"
+    - "change-ppyoloe_s"
+    - "change-ppyoloe_m"
+    - "change-ppyoloe_l"
+    - "change-ppyoloe_x"
   name: "model_type"
   defaultIndex: 0
   help: "模型类型越大训练资源越多，训练越慢，精度越高"
   type: "Select"
 - label: "模型训练图像宽度*高度"
   options:
     - "320*320"
```

## gaea_operator/pipelines/codetr_pipeline/pipeline.py

```diff
@@ -63,15 +63,15 @@
                 "WINDMILL_AK": "{{windmill_ak}}",
                 "WINDMILL_SK": "{{windmill_sk}}",
                 "WINDMILL_ENDPOINT": "{{windmill_endpoint}}",
                 "EXPERIMENT_KIND": "{{experiment_kind}}",
                 "EXPERIMENT_NAME": "{{experiment_name}}",
                 "TRACKING_URI": "{{tracking_uri}}",
                 "PROJECT_NAME": "{{project_name}}",
-                "PUBLIC_MODEL_STORE": "workspaces/internal/modelstores/lyg-exp"}
+                "PUBLIC_MODEL_STORE": "workspaces/public/modelstores/public"}
 
     train_params = {"train_dataset_name": train_dataset_name,
                     "val_dataset_name": val_dataset_name,
                     "base_train_dataset_name": base_train_dataset_name,
                     "base_val_dataset_name": base_val_dataset_name,
                     "model_name": train_model_name,
                     "model_display_name": train_model_display_name,
@@ -95,46 +95,46 @@
     train = ContainerStep(name="train",
                           docker_env="iregistry.baidu-int.com/windmill-public/pytorch/pytorch:v4.1.2-dev1",
                           parameters=train_params,
                           env=train_env,
                           extra_fs=[ExtraFS(name=extra_fs_name, mount_path=extra_fs_mount_path)],
                           outputs={"output_model_uri": Artifact(), "output_uri": Artifact()},
                           command=f'cd /root && '
-                                f'package_path=$(python3 -c "import site; print(site.getsitepackages()[0])") && '
-                                f'python3 -m gaea_operator.components.train.codetr '
-                                f'--output-model-uri={{{{output_model_uri}}}} '
-                                f'--output-uri={{{{output_uri}}}} '
-                                f'--log_dir={{{{output_uri}}}} '
-                                f'$package_path/mmdet/tools/train.py '
-                                f'{{{{output_model_uri}}}}/{DEFAULT_TRAIN_CONFIG_FILE_NAME} '
-                                f'--work-dir={{{{output_model_uri}}}} ')
+                                  f'package_path=$(python3 -c "import site; print(site.getsitepackages()[0])") && '
+                                  f'python3 -m gaea_operator.components.train.codetr '
+                                  f'--output-model-uri={{{{output_model_uri}}}} '
+                                  f'--output-uri={{{{output_uri}}}} '
+                                  f'--log_dir={{{{output_uri}}}} '
+                                  f'$package_path/mmdet/tools/train.py '
+                                  f'{{{{output_model_uri}}}}/{DEFAULT_TRAIN_CONFIG_FILE_NAME} '
+                                  f'--work-dir={{{{output_model_uri}}}} ')
 
     eval_params = {"dataset_name": eval_dataset_name,
                    "advanced_parameters": '{}'}
     eval_env = {"DATASET_NAME": "{{dataset_name}}",
                 "ADVANCED_PARAMETERS": "{{advanced_parameters}}"}
     eval_env.update(base_env)
     eval_params.update(base_params)
     eval = ContainerStep(name="eval",
-                         docker_env="iregistry.baidu-int.com/windmill-public/pytorch/pytorch:v1.2.0-dev1",
+                         docker_env="iregistry.baidu-int.com/windmill-public/pytorch/pytorch:v4.1.2-dev1",
                          parameters=eval_params,
                          env=eval_env,
                          inputs={"input_model_uri": train.outputs["output_model_uri"]},
                          outputs={"output_uri": Artifact(), "output_dataset_uri": Artifact()},
                          command=f'cd /root && '
-                                f'package_path=$(python3 -c "import site; print(site.getsitepackages()[0])") && '
-                                f'python3 -m gaea_operator.components.eval.codetr '
-                                f'--input-model-uri={{{{input_model_uri}}}} '
-                                f'--output-uri={{{{output_uri}}}} '
-                                f'--output-dataset-uri={{{{output_dataset_uri}}}} '
-                                f'--log_dir={{{{output_uri}}}} '
-                                f'$package_path/mmdet/tools/test.py '
-                                f'{{{{input_model_uri}}}}/{DEFAULT_TRAIN_CONFIG_FILE_NAME} '
-                                f'{{{{input_model_uri}}}}/{DEFAULT_PYTORCH_MODEL_FILE_NAME} '
-                                f'--work-dir={{{{input_model_uri}}}} ')
+                                 f'package_path=$(python3 -c "import site; print(site.getsitepackages()[0])") && '
+                                 f'python3 -m gaea_operator.components.eval.codetr '
+                                 f'--input-model-uri={{{{input_model_uri}}}} '
+                                 f'--output-uri={{{{output_uri}}}} '
+                                 f'--output-dataset-uri={{{{output_dataset_uri}}}} '
+                                 f'--log_dir={{{{output_uri}}}} '
+                                 f'$package_path/mmdet/tools/test.py '
+                                 f'{{{{input_model_uri}}}}/{DEFAULT_TRAIN_CONFIG_FILE_NAME} '
+                                 f'{{{{input_model_uri}}}}/{DEFAULT_PYTORCH_MODEL_FILE_NAME} '
+                                 f'--work-dir={{{{input_model_uri}}}} ')
 
     transform_params = {"transform_model_name": transform_model_name,
                         "transform_model_display_name": transform_model_display_name,
                         "accelerator": "T4",
                         "advanced_parameters": '{"max_batch_size":"1",'
                                                '"source_framework":"onnx",'
                                                '"eval_height":"224",'
@@ -143,15 +143,15 @@
     transform_env = {"TRANSFORM_MODEL_NAME": "{{transform_model_name}}",
                      "TRANSFORM_MODEL_DISPLAY_NAME": "{{transform_model_display_name}}",
                      "ACCELERATOR": "{{accelerator}}",
                      "ADVANCED_PARAMETERS": "{{advanced_parameters}}"}
     transform_env.update(base_env)
     transform_params.update(base_params)
     transform = ContainerStep(name="transform",
-                              docker_env="iregistry.baidu-int.com/windmill-public/transform:v1.2.0-dev1",
+                              docker_env="iregistry.baidu-int.com/windmill-public/transform:v4.1.2-dev1",
                               env=transform_env,
                               parameters=transform_params,
                               inputs={"input_model_uri": train.outputs["output_model_uri"]},
                               outputs={"output_model_uri": Artifact(), "output_uri": Artifact()},
                               command=f'python3 -m gaea_operator.components.transform.codetr '
                                       f'--input-model-uri={{{{input_model_uri}}}} '
                                       f'--output-uri={{{{output_uri}}}} '
```

## gaea_operator/trainer/trainer.py

```diff
@@ -67,21 +67,24 @@
             bcelogger.error(f"Pytorch launch training failed: {e}")
             raise e
         finally:
             self.training_exit_flag = True
             if self.thread is not None:
                 self.thread.join()
 
-    def paddledet_export(self, model_dir: str):
+    def paddledet_export(self, model_dir: str, is_change_model: bool = False):
         """
         Export the model to static.
         """
-        from paddledet.tools import export_model
+        from paddledet.tools import export_model, export_model_pair
         weights = os.path.join(model_dir, DEFAULT_PADDLEPADDLE_MODEL_FILE_NAME)
-        export_model.main(weights=weights, output_dir=model_dir)
+        if is_change_model:
+            export_model_pair.main(weights=weights, output_dir=model_dir)
+        else:
+            export_model.main(weights=weights, output_dir=model_dir)
 
     def paddleclas_export(self, model_dir: str):
         """
         Export the model to static.
         """
         from paddleclas.tools import export_model
         train_config = os.path.join(model_dir, DEFAULT_TRAIN_CONFIG_FILE_NAME)
```

## gaea_operator/utils/__init__.py

```diff
@@ -18,15 +18,15 @@
     read_file, \
     read_yaml_file, \
     write_yaml_file, \
     find_dir
 from .compress import get_filepaths_in_archive
 from .time import format_time
 from .accelerator import get_accelerator, Accelerator
-from .model_template import get_model_template, ModelTemplate
+from .model_template import ModelTemplate
 from .registry import METRIC
 from .import_module import paddle, torch, Tensor, PTensor, TTensor
 from .tensor import list2ndarray, numpy_round2list, paddle_round2list, torch_round2list, list_round
 
 __all__ = ["find_upper_level_folder",
            "get_filepaths_in_archive",
            "write_file",
@@ -42,15 +42,14 @@
            "DEFAULT_META_FILE_NAME",
            "DEFAULT_METRIC_FILE_NAME",
            "DEFAULT_TRITON_CONFIG_FILE_NAME",
            "DEFAULT_PYTORCH_MODEL_FILE_NAME",
            "DEFAULT_DEPLOY_CONFIG_FILE_NAME",
            "get_accelerator",
            "Accelerator",
-           "get_model_template",
            "ModelTemplate",
            "METRIC",
            "paddle",
            "torch",
            "Tensor",
            "PTensor",
            "TTensor",
```

## gaea_operator/utils/accelerator.py

```diff
@@ -11,25 +11,46 @@
 class Accelerator(metaclass=ABCMeta):
     """
     Accelerator
     """
     T4 = "T4"
     V100 = "V100"
     A100 = "A100"
+    A10 = "A10"
     R200 = "R200"
 
     NVIDIA = "Nvidia"
     KUNLUN = "Kunlun"
 
-    def __init__(self, name: str = "T4"):
+    def __init__(self, kind: str = None, name: str = "T4"):
         self.name = name
         self.image = ""
         self.args = None
         self.env = None
 
+        self._kind = kind
+
+    @property
+    def get_kind(self):
+        """
+        Kind
+        """
+        if self._kind is None:
+            name_list = self.name.split("/", maxsplit=1)
+            if len(name_list) > 1:
+                self._kind = name_list[0]
+            elif len(name_list) == 1:
+                if self.name in [self.T4, self.V100, self.A100, self.A10]:
+                    self._kind = self.NVIDIA
+                else:
+                    self._kind = self.KUNLUN
+            else:
+                self._kind = self.KUNLUN
+        return self._kind
+
     def suggest_image(self):
         """
         Suggest image
         """
         return self.image
 
     def suggest_env(self):
@@ -67,17 +88,17 @@
 
 
 class NvidiaAccelerator(Accelerator):
     """
     Nvidia Accelerator
     """
 
-    def __init__(self, name: str = "T4"):
-        super().__init__(name=name)
-        self.image = "iregistry.baidu-int.com/windmill-public/inference/nvidia:v1.2.0-dev1"
+    def __init__(self, kind: str = None, name: str = "T4"):
+        super().__init__(kind=kind, name=name)
+        self.image = "iregistry.baidu-int.com/windmill-public/inference/nvidia:v4.1.2-dev1"
         self.args = {"backend-config": "tensorrt,plugins=/opt/tritonserver/lib/libmmdeploy_tensorrt_ops.so"}
         self.env = \
             {
                 "LD_LIBRARY_PATH":
                     "/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/tritonserver/lib",
                 "PATH": "/opt/tritonserver/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:"
                         "/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin"
@@ -121,22 +142,21 @@
 
 
 class KunlunAccelerator(Accelerator):
     """
     Kunlun Accelerator
     """
 
-    def __init__(self, name: str = "R200"):
-        super().__init__(name=name)
-        self.image = "iregistry.baidu-int.com/windmill-public/inference/kunlun:v1.2.0"
+    def __init__(self, kind: str = None, name: str = "R200"):
+        super().__init__(kind=kind, name=name)
+        self.image = "iregistry.baidu-int.com/windmill-public/inference/kunlun:v4.1.2-dev1"
         self.args = {"backend-config": "tensorrt,plugins=/opt/tritonserver/lib/libmmdeploy_tensorrt_ops.so"}
         self.env = \
             {
-                "LD_LIBRARY_PATH":
-                    "/opt/tritonserver/backends/paddlelite:/opt/tritonserver/backends/Kunlun:$LD_LIBRARY_PATH",
+                "LD_LIBRARY_PATH": "/opt/tritonserver/lib",
                 "XTCL_L3_SIZE": "16776192"
             }
 
     def suggest_flavours(self):
         """
         Suggest flavours
         """
@@ -168,17 +188,17 @@
 
 
 def get_accelerator(name: str = None, kind: str = None) -> Accelerator:
     """
     Get accelerator.
     """
     if kind == Accelerator.NVIDIA:
-        return NvidiaAccelerator(name=name)
+        return NvidiaAccelerator(kind=kind, name=name)
     if kind == Accelerator.KUNLUN:
-        return KunlunAccelerator(name=name)
+        return KunlunAccelerator(kind=kind, name=name)
 
-    if name in (Accelerator.T4, Accelerator.V100, Accelerator.A100):
+    if name in (Accelerator.T4, Accelerator.V100, Accelerator.A100, Accelerator.A10):
         return NvidiaAccelerator(name=name)
-    elif name in (Accelerator.R200, ):
+    elif name in (Accelerator.R200,):
         return KunlunAccelerator(name=name)
     else:
         raise Exception("Unsupported accelerator: {}".format(name))
```

## gaea_operator/utils/model_template.py

```diff
@@ -1,340 +1,156 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 """
 # @Time    : 2024/3/27
 # @Author  : yanxiaodong
 # @File    : algorithm.py
 """
-from abc import ABCMeta, abstractmethod
+import bcelogger
 from windmillmodelv1.client.model_api_modelstore import parse_modelstore_name
-from windmillmodelv1.client.model_api_model import ModelName
+from windmillclient.client.windmill_client import WindmillClient
 
+from .accelerator import get_accelerator
 
-class ModelTemplate(metaclass=ABCMeta):
+
+class ModelTemplate(object):
     """
     Algorithm class
     """
-    PPYOLOE_PLUS_NAME = 'ppyoloe_plus'
-    CHANGE_PPYOLOE_PLUS_NAME = 'change_ppyoloe_plus'
-    RESNET_NAME = 'resnet'
-    OCRNET_NAME = 'ocrnet'
-    CONVNEXT_NAME = 'convnext'
-    CODETR_NAME = 'codetr'
-    REPVIT_NAME = 'repvit'
+    PPYOLOE_PLUS_NAME = "PPYOLOEPLUS/Model"
+    CHANGE_PPYOLOE_PLUS_NAME = "ChangePPYOLOEPLUS/Model"
+    RESNET_NAME = "ResNet/Model"
+    OCRNET_NAME = "OCRNet/Model"
+    CHANGE_OCRNET_NAME = "ChangeOCRNet/Model"
+
+    DEFAULT_SCENE = ""
+
+    def __init__(self, windmill_client: WindmillClient,
+                 model_store_name: str,
+                 scene: str = None,
+                 accelerator: str = "T4",
+                 algorithm: str = "PPYOLOEPLUS/Model"):
+        self.windmill_client = windmill_client
+        self.scene = scene
+        self.accelerator = get_accelerator(name=accelerator)
+        self.algorithm = algorithm
 
-    def __init__(self, model_store_name: str):
         model_store = parse_modelstore_name(model_store_name)
         self.workspace_id = model_store.workspace_id
         self.model_store_name = model_store.local_name
 
-    @abstractmethod
-    def suggest_template_preprocess(self):
-        """
-        Get template name for preprocess
-        """
-        raise NotImplementedError()
-
-    @abstractmethod
-    def suggest_template_postprocess(self):
-        """
-        Get template name for postprocess
-        """
-        raise NotImplementedError()
-
-    @abstractmethod
-    def suggest_template_model(self):
-        """
-        Get template name for model
-        """
-        raise NotImplementedError()
-
-    @abstractmethod
-    def suggest_template_ensemble(self):
-        """
-        Get template name for ensemble
-        """
-        raise NotImplementedError()
-
-
-class PPYOLOEPLUSTemplate(ModelTemplate):
-    """
-    PPYOLOE_PLUS Algorithm class
-    """
-    def __init__(self, model_store_name):
-        super(PPYOLOEPLUSTemplate, self).__init__(model_store_name=model_store_name)
-
-    def suggest_template_preprocess(self):
-        """
-        Get template name for preprocess
-        """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="ppyoloeplus-preprocess")
-        return model_name.get_name()
-
-    def suggest_template_postprocess(self):
-        """
-        Get template name for postprocess
-        """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="ppyoloeplus-postprocess")
-        return model_name.get_name()
-
-    def suggest_template_model(self):
-        """
-        Get template name for model
-        """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="ppyoloeplus-model")
-        return model_name.get_name()
-
-    def suggest_template_ensemble(self):
-        """
-        Get template name for ensemble
-        """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="ppyoloeplus-ensemble")
-        return model_name.get_name()
-
-
-class ResNetTemplate(ModelTemplate):
-    """
-    ResNet Algorithm class
-    """
-    def __init__(self, model_store_name):
-        super(ResNetTemplate, self).__init__(model_store_name=model_store_name)
-
-    def suggest_template_preprocess(self):
-        """
-        Get template name for preprocess
-        """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="single-attr-cls-preprocess")
-        return model_name.get_name()
-
-    def suggest_template_postprocess(self):
-        """
-        Get template name for postprocess
-        """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="single-attr-cls-postprocess")
-        return model_name.get_name()
+        bcelogger.info(f"Model scene is {self.scene}")
 
     def suggest_template_model(self):
         """
         Get template name for model
         """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="single-attr-cls-model")
-        return model_name.get_name()
+        tags = [{"algorithm": self.algorithm}]
+        if self.scene is not None and len(self.scene) > 0:
+            tags.append({"scene": self.scene})
+        else:
+            tags.append({"scene": self.DEFAULT_SCENE})
+
+        bcelogger.info(f"List model for workspace_id {self.workspace_id} "
+                       f"model_store_name {self.model_store_name} "
+                       f"and tags {tags}")
+        response = self.windmill_client.list_model(workspace_id=self.workspace_id,
+                                                   model_store_name=self.model_store_name,
+                                                   tags=tags)
+        assert len(response.result) > 0, f"No model found for tags {tags}"
+        for model in response.result:
+            model_accelerator = model["preferModelServerParameters"]["resource"]["accelerator"]
+            if get_accelerator(name=model_accelerator).get_kind == self.accelerator.get_kind:
+                bcelogger.info(f"Model {model['name']} found")
+                return model["name"]
+        raise ValueError(f"The model {response.result} not found for kind {self.accelerator.get_kind}")
 
     def suggest_template_ensemble(self):
         """
         Get template name for ensemble
         """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="single-attr-cls-ensemble")
-        return model_name.get_name()
-
-
-class OCRNetTemplate(ModelTemplate):
-    """
-    ResNet Algorithm class
-    """
-    def __init__(self, model_store_name):
-        super(OCRNetTemplate, self).__init__(model_store_name=model_store_name)
+        if self.scene is not None and len(self.scene) > 0:
+            scene_list = self.scene.split("/", maxsplit=1)
+            assert len(scene_list) >= 1, f"Scene {self.scene} is not valid."
+
+            ensemble_scene = scene_list[0] + "/" + "Ensemble"
+            tags = [{"scene": ensemble_scene}]
+        else:
+            algorithm_list = self.algorithm.split("/", maxsplit=1)
+            assert len(algorithm_list) >= 1, f"Algorithm {self.algorithm} is not valid."
+            ensemble_algorithm = algorithm_list[0] + "/" + "Ensemble"
+            tags = [{"algorithm": ensemble_algorithm}]
+
+        bcelogger.info(f"List model for workspace_id {self.workspace_id} "
+                       f"model_store_name {self.model_store_name} "
+                       f"and tags {tags}")
+        response = self.windmill_client.list_model(workspace_id=self.workspace_id,
+                                                   model_store_name=self.model_store_name,
+                                                   tags=tags)
+        assert len(response.result) > 0, f"No model found for tags {tags}"
+        for model in response.result:
+            model_accelerator = model["preferModelServerParameters"]["resource"]["accelerator"]
+            if get_accelerator(name=model_accelerator).get_kind == self.accelerator.get_kind:
+                bcelogger.info(f"Model {model['name']} found")
+                return model["name"]
+        raise ValueError(f"The model {response.result} not found for kind {self.accelerator.get_kind}")
 
     def suggest_template_preprocess(self):
         """
         Get template name for preprocess
         """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="ocrnet-preprocess")
-        return model_name.get_name()
+        if self.scene is not None and len(self.scene) > 0:
+            scene_list = self.scene.split("/", maxsplit=1)
+            assert len(scene_list) >= 1, f"Scene {self.scene} is not valid."
+
+            ensemble_scene = scene_list[0] + "/" + "Preprocess"
+            tags = [{"scene": ensemble_scene}]
+        else:
+            algorithm_list = self.algorithm.split("/", maxsplit=1)
+            assert len(algorithm_list) >= 1, f"Algorithm {self.algorithm} is not valid."
+            ensemble_algorithm = algorithm_list[0] + "/" + "Preprocess"
+            tags = [{"algorithm": ensemble_algorithm}]
+
+        bcelogger.info(f"List model for workspace_id {self.workspace_id} "
+                       f"model_store_name {self.model_store_name} "
+                       f"and tags {tags}")
+        response = self.windmill_client.list_model(workspace_id=self.workspace_id,
+                                                   model_store_name=self.model_store_name,
+                                                   tags=tags)
+        assert len(response.result) > 0, f"No model found for tags {tags}"
+        for model in response.result:
+            model_accelerator = model["preferModelServerParameters"]["resource"]["accelerator"]
+            if get_accelerator(name=model_accelerator).get_kind == self.accelerator.get_kind:
+                bcelogger.info(f"Model {model['name']} found")
+                return model["name"]
+        raise ValueError(f"The model {response.result} not found for kind {self.accelerator.get_kind}")
 
     def suggest_template_postprocess(self):
         """
         Get template name for postprocess
         """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="ocrnet-postprocess")
-        return model_name.get_name()
-
-    def suggest_template_model(self):
-        """
-        Get template name for model
-        """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="ocrnet-model")
-        return model_name.get_name()
+        if self.scene is not None and len(self.scene) > 0:
+            scene_list = self.scene.split("/", maxsplit=1)
+            assert len(scene_list) >= 1, f"Scene {self.scene} is not valid."
+
+            ensemble_scene = scene_list[0] + "/" + "Postprocess"
+            tags = [{"scene": ensemble_scene}]
+        else:
+            algorithm_list = self.algorithm.split("/", maxsplit=1)
+            assert len(algorithm_list) >= 1, f"Algorithm {self.algorithm} is not valid."
+            ensemble_algorithm = algorithm_list[0] + "/" + "Postprocess"
+            tags = [{"algorithm": ensemble_algorithm}]
+
+        bcelogger.info(f"List model for workspace_id {self.workspace_id} "
+                       f"model_store_name {self.model_store_name} "
+                       f"and tags {tags}")
+        response = self.windmill_client.list_model(workspace_id=self.workspace_id,
+                                                   model_store_name=self.model_store_name,
+                                                   tags=tags)
+        assert len(response.result) > 0, f"No model found for tags {tags}"
+        for model in response.result:
+            model_accelerator = model["preferModelServerParameters"]["resource"]["accelerator"]
+            if get_accelerator(name=model_accelerator).get_kind == self.accelerator.get_kind:
+                bcelogger.info(f"Model {model['name']} found")
+                return model["name"]
+        raise ValueError(f"The model {response.result} not found for kind {self.accelerator.get_kind}")
 
-    def suggest_template_ensemble(self):
-        """
-        Get template name for ensemble
-        """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="ocrnet-ensemble")
-        return model_name.get_name()
-
-
-class ConvNextTemplate(ModelTemplate):
-    """
-    ResNet Algorithm class
-    """
-    def __init__(self, model_store_name):
-        super(ConvNextTemplate, self).__init__(model_store_name=model_store_name)
-
-    def suggest_template_preprocess(self):
-        """
-        Get template name for preprocess
-        """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="convnext-preprocess")
-        return model_name.get_name()
-
-    def suggest_template_postprocess(self):
-        """
-        Get template name for postprocess
-        """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="convnext-postprocess")
-        return model_name.get_name()
-
-    def suggest_template_model(self):
-        """
-        Get template name for model
-        """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="convnext-model")
-        return model_name.get_name()
-
-    def suggest_template_ensemble(self):
-        """
-        Get template name for ensemble
-        """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="convnext-ensemble")
-        return model_name.get_name()
-
-
-class CoDETRTemplate(ModelTemplate):
-    """
-    ResNet Algorithm class
-    """
-    def __init__(self, model_store_name):
-        super(CoDETRTemplate, self).__init__(model_store_name=model_store_name)
-
-    def suggest_template_preprocess(self):
-        """
-        Get template name for preprocess
-        """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="codetr-preprocess")
-        return model_name.get_name()
-
-    def suggest_template_postprocess(self):
-        """
-        Get template name for postprocess
-        """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="codetr-postprocess")
-        return model_name.get_name()
-
-    def suggest_template_model(self):
-        """
-        Get template name for model
-        """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="codetr-model")
-        return model_name.get_name()
-
-    def suggest_template_ensemble(self):
-        """
-        Get template name for ensemble
-        """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="codetr-ensemble")
-        return model_name.get_name()
-
-
-class RepViTTemplate(ModelTemplate):
-    """
-    ResNet Algorithm class
-    """
-    def __init__(self, model_store_name):
-        super(RepViTTemplate, self).__init__(model_store_name=model_store_name)
-
-    def suggest_template_preprocess(self):
-        """
-        Get template name for preprocess
-        """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="repvit-preprocess")
-        return model_name.get_name()
-
-    def suggest_template_postprocess(self):
-        """
-        Get template name for postprocess
-        """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="repvit-postprocess")
-        return model_name.get_name()
-
-    def suggest_template_model(self):
-        """
-        Get template name for model
-        """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="repvit-model")
-        return model_name.get_name()
-
-    def suggest_template_ensemble(self):
-        """
-        Get template name for ensemble
-        """
-        model_name = ModelName(workspace_id=self.workspace_id,
-                               model_store_name=self.model_store_name,
-                               local_name="repvit-ensemble")
-        return model_name.get_name()
-
-
-def get_model_template(name: str, model_store_name: str):
-    """
-    Get algorithm class by name
-    """
-    if name == ModelTemplate.PPYOLOE_PLUS_NAME:
-        return PPYOLOEPLUSTemplate(model_store_name=model_store_name)
-    elif name == ModelTemplate.RESNET_NAME:
-        return ResNetTemplate(model_store_name=model_store_name)
-    elif name == ModelTemplate.OCRNET_NAME:
-        return OCRNetTemplate(model_store_name=model_store_name)
-    elif name == ModelTemplate.CONVNEXT_NAME:
-        return ConvNextTemplate(model_store_name=model_store_name)
-    elif name == ModelTemplate.CODETR_NAME:
-        return CoDETRTemplate(model_store_name=model_store_name)
-    elif name == ModelTemplate.REPVIT_NAME:
-        return RepViTTemplate(model_store_name=model_store_name)
-    else:
-        raise NotImplementedError(f'Algorithm {name} not supported')
```

## Comparing `gaea_operator/pipelines/ocrnet_pipeline/ocrnet_pipeline.py` & `gaea_operator/pipelines/resnet_pipeline/pipeline.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,27 +1,31 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 """
-# @File    : ocrnet_pipeline.py
+# @Time    : 2024/3/26
+# @Author  : liyinggang
+# @File    : resnet_pipeline.py
 """
+import os
 from paddleflow.pipeline import Pipeline
 from paddleflow.pipeline import CacheOptions
 from paddleflow.pipeline import ContainerStep
 from paddleflow.pipeline import Artifact
 from paddleflow.pipeline import ExtraFS
 
 from gaea_operator.utils import DEFAULT_TRAIN_CONFIG_FILE_NAME, \
     DEFAULT_PADDLEPADDLE_MODEL_FILE_NAME, \
     ModelTemplate
 from gaea_operator.components.transform_eval import transform_eval_step
 from gaea_operator.components.package import package_step
 from gaea_operator.components.inference import inference_step
 
+
 @Pipeline(
-    name="ocrnet",
+    name="resnet",
     cache_options=CacheOptions(enable=False),
 )
 def pipeline(accelerator: str = "T4",
              extra_fs_name: str = "vistudio",
              extra_fs_mount_path: str = "/home/paddleflow/storage/mnt/fs-root-vistudio",
              windmill_ak: str = "",
              windmill_sk: str = "",
@@ -29,25 +33,27 @@
              experiment_kind: str = "",
              experiment_name: str = "",
              modelstore_name: str = "",
              tracking_uri: str = "",
              project_name: str = "",
              train_dataset_name: str = "",
              val_dataset_name: str = "",
+             base_train_dataset_name: str = "",
+             base_val_dataset_name: str = "",
              train_model_name: str = "",
              train_model_display_name: str = "",
              eval_dataset_name: str = "",
              transform_model_name: str = "",
              transform_model_display_name: str = "",
              ensemble_model_name: str = "",
              ensemble_model_display_name: str = ""):
     """
-    Pipeline for ocrnet training eval transform transform-eval package inference.
+    Pipeline for resnet training eval transform transform-eval package inference.
     """
-    base_params = {"flavour": "c8m32gpu1",
+    base_params = {"flavour": "c4m16gpu1",
                    "queue": "qtrain",
                    "windmill_ak": windmill_ak,
                    "windmill_sk": windmill_sk,
                    "windmill_endpoint": windmill_endpoint,
                    "experiment_name": experiment_name,
                    "experiment_kind": experiment_kind,
                    "tracking_uri": tracking_uri,
@@ -61,111 +67,110 @@
                 "EXPERIMENT_KIND": "{{experiment_kind}}",
                 "EXPERIMENT_NAME": "{{experiment_name}}",
                 "TRACKING_URI": "{{tracking_uri}}",
                 "PROJECT_NAME": "{{project_name}}"}
 
     train_params = {"train_dataset_name": train_dataset_name,
                     "val_dataset_name": val_dataset_name,
+                    "base_train_dataset_name": base_train_dataset_name,
+                    "base_val_dataset_name": base_val_dataset_name,
                     "model_name": train_model_name,
                     "model_display_name": train_model_display_name,
-                    "advanced_parameters": '{"iters":"100",'
-                                           '"lr_scheduler.learning_rate":"0.001",'
-                                           '"eval_height":"512",'
-                                           '"eval_width":"512",'
-                                           '"batch_size":"6",'
-                                           '"model_type":"ocrnet"}'}
+                    "advanced_parameters": '{"Global.epochs":"1",'
+                                           '"Optimizer.lr.learning_rate":"0.001",'
+                                           '"DataLoader.Train.loader.num_workers":"2",'
+                                           '"eval_height":"224",'
+                                           '"eval_width":"224",'
+                                           '"DataLoader.Train.sampler.batch_size":"8",'
+                                           '"model_type":"resnet"}'}
     train_env = {"TRAIN_DATASET_NAME": "{{train_dataset_name}}",
                  "VAL_DATASET_NAME": "{{val_dataset_name}}",
+                 "BASE_TRAIN_DATASET_NAME": "{{base_train_dataset_name}}",
+                 "BASE_VAL_DATASET_NAME": "{{base_val_dataset_name}}",
                  "MODEL_NAME": "{{model_name}}",
                  "MODEL_DISPLAY_NAME": "{{model_display_name}}",
                  "ADVANCED_PARAMETERS": "{{advanced_parameters}}",
                  "PF_EXTRA_WORK_DIR": extra_fs_mount_path}
     train_env.update(base_env)
     train_params.update(base_params)
     train = ContainerStep(name="train",
-                          docker_env="iregistry.baidu-int.com/windmill-public/train/paddlepaddle:v1.2.0-dev1",
+                          docker_env="iregistry.baidu-int.com/windmill-public/train/paddlepaddle:v1.2.0",
                           parameters=train_params,
                           env=train_env,
                           extra_fs=[ExtraFS(name=extra_fs_name, mount_path=extra_fs_mount_path)],
                           outputs={"output_model_uri": Artifact(), "output_uri": Artifact()},
                           command=f'package_path=$(python3 -c "import site; print(site.getsitepackages()[0])") && '
-                                  f'python3 -m gaea_operator.components.train.ocrnet '
+                                  f'python3 -m gaea_operator.components.train.resnet '
                                   f'--output-model-uri={{{{output_model_uri}}}} '
                                   f'--output-uri={{{{output_uri}}}} '
                                   f'--log_dir={{{{output_uri}}}} '
-                                  f'$package_path/paddleseg/tools/train.py '
-                                  f'--config {{{{output_model_uri}}}}/{DEFAULT_TRAIN_CONFIG_FILE_NAME} '
-                                  f'--do_eval '
-                                  f'--save_dir={{{{output_model_uri}}}}')
+                                  f'$package_path/paddleclas/tools/train.py '
+                                  f'-c {{{{output_model_uri}}}}/{DEFAULT_TRAIN_CONFIG_FILE_NAME} '
+                                  f'-o Global.output_dir={{{{output_model_uri}}}}')
 
     eval_params = {"dataset_name": eval_dataset_name}
     eval_env = {"DATASET_NAME": "{{dataset_name}}"}
     eval_env.update(base_env)
     eval_params.update(base_params)
     eval = ContainerStep(name="eval",
-                         docker_env="iregistry.baidu-int.com/windmill-public/train/paddlepaddle:v1.2.0-dev1",
+                         docker_env="iregistry.baidu-int.com/windmill-public/train/paddlepaddle:v1.2.0",
                          parameters=eval_params,
                          env=eval_env,
                          inputs={"input_model_uri": train.outputs["output_model_uri"]},
                          outputs={"output_uri": Artifact(), "output_dataset_uri": Artifact()},
                          command=f'package_path=$(python3 -c "import site; print(site.getsitepackages()[0])") && '
-                                 f'python3 -m gaea_operator.components.eval.ocrnet '
+                                 f'python3 -m gaea_operator.components.eval.resnet '
                                  f'--input-model-uri={{{{input_model_uri}}}} '
                                  f'--output-uri={{{{output_uri}}}} '
                                  f'--output-dataset-uri={{{{output_dataset_uri}}}} '
-                                 f'$package_path/paddleseg/tools/val.py '
-                                 f'--config {{{{input_model_uri}}}}/{DEFAULT_TRAIN_CONFIG_FILE_NAME} '
-                                 f'--model_path={{{{input_model_uri}}}}/{DEFAULT_PADDLEPADDLE_MODEL_FILE_NAME} '
-                                 f'--save_dir={{{{output_uri}}}}')
+                                 f'--log_dir={{{{output_uri}}}} '
+                                 f'$package_path/paddleclas/tools/eval.py '
+                                 f'-c {{{{input_model_uri}}}}/{DEFAULT_TRAIN_CONFIG_FILE_NAME} '
+                                 f'-o Global.pretrained_model='
+                                 f'{{{{input_model_uri}}}}/{os.path.splitext(DEFAULT_PADDLEPADDLE_MODEL_FILE_NAME)[0]}')
 
     transform_params = {"transform_model_name": transform_model_name,
                         "transform_model_display_name": transform_model_display_name,
                         "accelerator": "T4",
-                        "advanced_parameters": '{"max_batch_size":"1",'
+                        "advanced_parameters": '{"max_batch_size":"4",'
                                                '"precision":"fp16",'
                                                '"eval_height":"512",'
                                                '"eval_width":"512",'
                                                '"source_framework":"paddle",'
-                                               '"model_type":"ocrnet"}',
-                        "advanced_parameters1": '{"max_batch_size":"1",'
-                                                '"precision":"fp16",'
-                                                '"eval_height":"512",'
-                                                '"eval_width":"512",'
-                                                '"source_framework":"paddle",'
-                                                '"model_type":"ocrnet"}'}
+                                               '"model_type":"resnet"}'}
     transform_env = {"TRANSFORM_MODEL_NAME": "{{transform_model_name}}",
                      "TRANSFORM_MODEL_DISPLAY_NAME": "{{transform_model_display_name}}",
                      "ACCELERATOR": "{{accelerator}}",
-                     "ADVANCED_PARAMETERS": "{{advanced_parameters1}}"}
+                     "ADVANCED_PARAMETERS": "{{advanced_parameters}}"}
     transform_env.update(base_env)
     transform_params.update(base_params)
     transform = ContainerStep(name="transform",
-                              docker_env="iregistry.baidu-int.com/windmill-public/transform:v1.2.0-dev1",
+                              docker_env="iregistry.baidu-int.com/windmill-public/transform:v1.2.0",
                               env=transform_env,
                               parameters=transform_params,
                               inputs={"input_model_uri": train.outputs["output_model_uri"]},
                               outputs={"output_model_uri": Artifact(), "output_uri": Artifact()},
-                              command=f'python3 -m gaea_operator.components.transform.ocrnet '
+                              command=f'python3 -m gaea_operator.components.transform.resnet '
                                       f'--input-model-uri={{{{input_model_uri}}}} '
                                       f'--output-uri={{{{output_uri}}}} '
                                       f'--output-model-uri={{{{output_model_uri}}}}').after(eval)
 
-    transform_eval = transform_eval_step(algorithm=ModelTemplate.OCRNET_NAME,
+    transform_eval = transform_eval_step(algorithm=ModelTemplate.RESNET_NAME,
                                          windmill_ak=windmill_ak,
                                          windmill_sk=windmill_sk,
                                          windmill_endpoint=windmill_endpoint,
                                          experiment_kind=experiment_kind,
                                          experiment_name=experiment_name,
                                          tracking_uri=tracking_uri,
                                          project_name=project_name,
                                          accelerator=accelerator,
                                          eval_step=eval,
                                          transform_step=transform)
 
-    package = package_step(algorithm=ModelTemplate.OCRNET_NAME,
+    package = package_step(algorithm=ModelTemplate.RESNET_NAME,
                            windmill_ak=windmill_ak,
                            windmill_sk=windmill_sk,
                            windmill_endpoint=windmill_endpoint,
                            experiment_kind=experiment_kind,
                            experiment_name=experiment_name,
                            tracking_uri=tracking_uri,
                            project_name=project_name,
@@ -192,22 +197,21 @@
 if __name__ == "__main__":
     pipeline_client = pipeline(
         accelerator="T4",
         windmill_ak="a1a9069e2b154b2aa1a83ed12316d163",
         windmill_sk="eefac23d2660404e93855197ce60efb3",
         windmill_endpoint="http://10.27.240.5:8340",
         experiment_kind="Aim",
-        experiment_name="ocrnet",
+        experiment_name="resnet",
         tracking_uri="aim://10.27.240.5:8329",
         project_name="workspaces/internal/projects/proj-o97H2oAE",
-        train_dataset_name="workspaces/internal/projects/proj-o97H2oAE/datasets/ds-tQLjA9NM/versions/1",
-        val_dataset_name="workspaces/internal/projects/proj-o97H2oAE/datasets/ds-tQLjA9NM/versions/1",
-        eval_dataset_name="workspaces/internal/projects/proj-o97H2oAE/datasets/ds-tQLjA9NM/versions/1",
-        train_model_name="workspaces/internal/modelstores/ms-6TDGY7Hv/models/ocrnet-model",
-        train_model_display_name="ocrnet",
-        transform_model_name="workspaces/internal/modelstores/ms-6TDGY7Hv/models/ocrnet-t4",
-        transform_model_display_name="ocrnet-t4",
-        ensemble_model_name="workspaces/internal/modelstores/ms-6TDGY7Hv/models/ocrnet-ensemble",
-        ensemble_model_display_name="ocrnet-ensemble"
-    )
-    pipeline_client.compile(save_path="../../../ocrnet_pipeline.yaml")
+        train_dataset_name="workspaces/internal/projects/proj-o97H2oAE/datasets/ds-D7looaa4/versions/1",
+        val_dataset_name="workspaces/internal/projects/proj-o97H2oAE/datasets/ds-D7looaa4/versions/1",
+        eval_dataset_name="workspaces/internal/projects/proj-o97H2oAE/datasets/ds-D7looaa4/versions/1",
+        train_model_name="workspaces/internal/modelstores/ms-6TDGY7Hv/models/single-attr-cls",
+        train_model_display_name="resnet18",
+        transform_model_name="workspaces/internal/modelstores/ms-6TDGY7Hv/models/single-attr-cls-t4",
+        transform_model_display_name="single-attr-cls-t4",
+        ensemble_model_name="workspaces/internal/modelstores/ms-6TDGY7Hv/models/single-attr-cls-ensemble",
+        ensemble_model_display_name="single-attr-cls-ensemble")
+    pipeline_client.compile(save_path="../../../resnet_pipeline.yaml")
     _, run_id = pipeline_client.run(fs_name="vistudio")
```

## Comparing `gaea_operator/pipelines/resnet_pipeline/resnet_pipeline.py` & `gaea_operator/pipelines/ocrnet_pipeline/pipeline.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,31 +1,27 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 """
-# @Time    : 2024/3/26
-# @Author  : liyinggang
-# @File    : resnet_pipeline.py
+# @File    : ocrnet_pipeline.py
 """
-import os
 from paddleflow.pipeline import Pipeline
 from paddleflow.pipeline import CacheOptions
 from paddleflow.pipeline import ContainerStep
 from paddleflow.pipeline import Artifact
 from paddleflow.pipeline import ExtraFS
 
 from gaea_operator.utils import DEFAULT_TRAIN_CONFIG_FILE_NAME, \
     DEFAULT_PADDLEPADDLE_MODEL_FILE_NAME, \
     ModelTemplate
 from gaea_operator.components.transform_eval import transform_eval_step
 from gaea_operator.components.package import package_step
 from gaea_operator.components.inference import inference_step
 
-
 @Pipeline(
-    name="resnet",
+    name="ocrnet",
     cache_options=CacheOptions(enable=False),
 )
 def pipeline(accelerator: str = "T4",
              extra_fs_name: str = "vistudio",
              extra_fs_mount_path: str = "/home/paddleflow/storage/mnt/fs-root-vistudio",
              windmill_ak: str = "",
              windmill_sk: str = "",
@@ -33,27 +29,25 @@
              experiment_kind: str = "",
              experiment_name: str = "",
              modelstore_name: str = "",
              tracking_uri: str = "",
              project_name: str = "",
              train_dataset_name: str = "",
              val_dataset_name: str = "",
-             base_train_dataset_name: str = "",
-             base_val_dataset_name: str = "",
              train_model_name: str = "",
              train_model_display_name: str = "",
              eval_dataset_name: str = "",
              transform_model_name: str = "",
              transform_model_display_name: str = "",
              ensemble_model_name: str = "",
              ensemble_model_display_name: str = ""):
     """
-    Pipeline for resnet training eval transform transform-eval package inference.
+    Pipeline for ocrnet training eval transform transform-eval package inference.
     """
-    base_params = {"flavour": "c4m16gpu1",
+    base_params = {"flavour": "c8m32gpu1",
                    "queue": "qtrain",
                    "windmill_ak": windmill_ak,
                    "windmill_sk": windmill_sk,
                    "windmill_endpoint": windmill_endpoint,
                    "experiment_name": experiment_name,
                    "experiment_kind": experiment_kind,
                    "tracking_uri": tracking_uri,
@@ -67,110 +61,105 @@
                 "EXPERIMENT_KIND": "{{experiment_kind}}",
                 "EXPERIMENT_NAME": "{{experiment_name}}",
                 "TRACKING_URI": "{{tracking_uri}}",
                 "PROJECT_NAME": "{{project_name}}"}
 
     train_params = {"train_dataset_name": train_dataset_name,
                     "val_dataset_name": val_dataset_name,
-                    "base_train_dataset_name": base_train_dataset_name,
-                    "base_val_dataset_name": base_val_dataset_name,
                     "model_name": train_model_name,
                     "model_display_name": train_model_display_name,
-                    "advanced_parameters": '{"Global.epochs":"1",'
-                                           '"Optimizer.lr.learning_rate":"0.001",'
-                                           '"DataLoader.Train.loader.num_workers":"2",'
-                                           '"eval_height":"224",'
-                                           '"eval_width":"224",'
-                                           '"DataLoader.Train.sampler.batch_size":"8",'
-                                           '"model_type":"resnet"}'}
+                    "advanced_parameters": '{"iters":"100",'
+                                           '"lr_scheduler.learning_rate":"0.001",'
+                                           '"eval_height":"512",'
+                                           '"eval_width":"512",'
+                                           '"batch_size":"6",'
+                                           '"model_type":"ocrnet"}'}
     train_env = {"TRAIN_DATASET_NAME": "{{train_dataset_name}}",
                  "VAL_DATASET_NAME": "{{val_dataset_name}}",
-                 "BASE_TRAIN_DATASET_NAME": "{{base_train_dataset_name}}",
-                 "BASE_VAL_DATASET_NAME": "{{base_val_dataset_name}}",
                  "MODEL_NAME": "{{model_name}}",
                  "MODEL_DISPLAY_NAME": "{{model_display_name}}",
                  "ADVANCED_PARAMETERS": "{{advanced_parameters}}",
                  "PF_EXTRA_WORK_DIR": extra_fs_mount_path}
     train_env.update(base_env)
     train_params.update(base_params)
     train = ContainerStep(name="train",
-                          docker_env="iregistry.baidu-int.com/windmill-public/train/paddlepaddle:v1.2.0-dev1",
+                          docker_env="iregistry.baidu-int.com/windmill-public/train/paddlepaddle:v4.1.2-dev1",
                           parameters=train_params,
                           env=train_env,
                           extra_fs=[ExtraFS(name=extra_fs_name, mount_path=extra_fs_mount_path)],
                           outputs={"output_model_uri": Artifact(), "output_uri": Artifact()},
                           command=f'package_path=$(python3 -c "import site; print(site.getsitepackages()[0])") && '
-                                  f'python3 -m gaea_operator.components.train.resnet '
+                                  f'python3 -m gaea_operator.components.train.ocrnet '
                                   f'--output-model-uri={{{{output_model_uri}}}} '
                                   f'--output-uri={{{{output_uri}}}} '
                                   f'--log_dir={{{{output_uri}}}} '
-                                  f'$package_path/paddleclas/tools/train.py '
-                                  f'-c {{{{output_model_uri}}}}/{DEFAULT_TRAIN_CONFIG_FILE_NAME} '
-                                  f'-o Global.output_dir={{{{output_model_uri}}}}')
+                                  f'$package_path/paddleseg/tools/train.py '
+                                  f'--config {{{{output_model_uri}}}}/{DEFAULT_TRAIN_CONFIG_FILE_NAME} '
+                                  f'--do_eval '
+                                  f'--save_dir={{{{output_model_uri}}}}')
 
     eval_params = {"dataset_name": eval_dataset_name}
     eval_env = {"DATASET_NAME": "{{dataset_name}}"}
     eval_env.update(base_env)
     eval_params.update(base_params)
     eval = ContainerStep(name="eval",
-                         docker_env="iregistry.baidu-int.com/windmill-public/train/paddlepaddle:v1.2.0-dev1",
+                         docker_env="iregistry.baidu-int.com/windmill-public/train/paddlepaddle:v4.1.2-dev1",
                          parameters=eval_params,
                          env=eval_env,
                          inputs={"input_model_uri": train.outputs["output_model_uri"]},
                          outputs={"output_uri": Artifact(), "output_dataset_uri": Artifact()},
                          command=f'package_path=$(python3 -c "import site; print(site.getsitepackages()[0])") && '
-                                 f'python3 -m gaea_operator.components.eval.resnet '
+                                 f'python3 -m gaea_operator.components.eval.ocrnet '
                                  f'--input-model-uri={{{{input_model_uri}}}} '
                                  f'--output-uri={{{{output_uri}}}} '
                                  f'--output-dataset-uri={{{{output_dataset_uri}}}} '
-                                 f'--log_dir={{{{output_uri}}}} '
-                                 f'$package_path/paddleclas/tools/eval.py '
-                                 f'-c {{{{input_model_uri}}}}/{DEFAULT_TRAIN_CONFIG_FILE_NAME} '
-                                 f'-o Global.pretrained_model='
-                                 f'{{{{input_model_uri}}}}/{os.path.splitext(DEFAULT_PADDLEPADDLE_MODEL_FILE_NAME)[0]}')
+                                 f'$package_path/paddleseg/tools/val.py '
+                                 f'--config {{{{input_model_uri}}}}/{DEFAULT_TRAIN_CONFIG_FILE_NAME} '
+                                 f'--model_path={{{{input_model_uri}}}}/{DEFAULT_PADDLEPADDLE_MODEL_FILE_NAME} '
+                                 f'--save_dir={{{{output_uri}}}}')
 
     transform_params = {"transform_model_name": transform_model_name,
                         "transform_model_display_name": transform_model_display_name,
                         "accelerator": "T4",
-                        "advanced_parameters": '{"max_batch_size":"4",'
+                        "advanced_parameters": '{"max_batch_size":"1",'
                                                '"precision":"fp16",'
                                                '"eval_height":"512",'
                                                '"eval_width":"512",'
                                                '"source_framework":"paddle",'
-                                               '"model_type":"resnet"}'}
+                                               '"model_type":"ocrnet"}'}
     transform_env = {"TRANSFORM_MODEL_NAME": "{{transform_model_name}}",
                      "TRANSFORM_MODEL_DISPLAY_NAME": "{{transform_model_display_name}}",
                      "ACCELERATOR": "{{accelerator}}",
                      "ADVANCED_PARAMETERS": "{{advanced_parameters}}"}
     transform_env.update(base_env)
     transform_params.update(base_params)
     transform = ContainerStep(name="transform",
-                              docker_env="iregistry.baidu-int.com/windmill-public/transform:v1.2.0-dev1",
+                              docker_env="iregistry.baidu-int.com/windmill-public/transform:v4.1.2-dev2",
                               env=transform_env,
                               parameters=transform_params,
                               inputs={"input_model_uri": train.outputs["output_model_uri"]},
                               outputs={"output_model_uri": Artifact(), "output_uri": Artifact()},
-                              command=f'python3 -m gaea_operator.components.transform.resnet '
+                              command=f'python3 -m gaea_operator.components.transform.ocrnet '
                                       f'--input-model-uri={{{{input_model_uri}}}} '
                                       f'--output-uri={{{{output_uri}}}} '
                                       f'--output-model-uri={{{{output_model_uri}}}}').after(eval)
 
-    transform_eval = transform_eval_step(algorithm=ModelTemplate.RESNET_NAME,
+    transform_eval = transform_eval_step(algorithm=ModelTemplate.OCRNET_NAME,
                                          windmill_ak=windmill_ak,
                                          windmill_sk=windmill_sk,
                                          windmill_endpoint=windmill_endpoint,
                                          experiment_kind=experiment_kind,
                                          experiment_name=experiment_name,
                                          tracking_uri=tracking_uri,
                                          project_name=project_name,
                                          accelerator=accelerator,
                                          eval_step=eval,
                                          transform_step=transform)
 
-    package = package_step(algorithm=ModelTemplate.RESNET_NAME,
+    package = package_step(algorithm=ModelTemplate.OCRNET_NAME,
                            windmill_ak=windmill_ak,
                            windmill_sk=windmill_sk,
                            windmill_endpoint=windmill_endpoint,
                            experiment_kind=experiment_kind,
                            experiment_name=experiment_name,
                            tracking_uri=tracking_uri,
                            project_name=project_name,
@@ -197,21 +186,22 @@
 if __name__ == "__main__":
     pipeline_client = pipeline(
         accelerator="T4",
         windmill_ak="a1a9069e2b154b2aa1a83ed12316d163",
         windmill_sk="eefac23d2660404e93855197ce60efb3",
         windmill_endpoint="http://10.27.240.5:8340",
         experiment_kind="Aim",
-        experiment_name="resnet",
+        experiment_name="ocrnet",
         tracking_uri="aim://10.27.240.5:8329",
         project_name="workspaces/internal/projects/proj-o97H2oAE",
-        train_dataset_name="workspaces/internal/projects/proj-o97H2oAE/datasets/ds-D7looaa4/versions/1",
-        val_dataset_name="workspaces/internal/projects/proj-o97H2oAE/datasets/ds-D7looaa4/versions/1",
-        eval_dataset_name="workspaces/internal/projects/proj-o97H2oAE/datasets/ds-D7looaa4/versions/1",
-        train_model_name="workspaces/internal/modelstores/ms-6TDGY7Hv/models/single-attr-cls",
-        train_model_display_name="resnet18",
-        transform_model_name="workspaces/internal/modelstores/ms-6TDGY7Hv/models/single-attr-cls-t4",
-        transform_model_display_name="single-attr-cls-t4",
-        ensemble_model_name="workspaces/internal/modelstores/ms-6TDGY7Hv/models/single-attr-cls-ensemble",
-        ensemble_model_display_name="single-attr-cls-ensemble")
-    pipeline_client.compile(save_path="../../../resnet_pipeline.yaml")
+        train_dataset_name="workspaces/internal/projects/proj-o97H2oAE/datasets/ds-tQLjA9NM/versions/1",
+        val_dataset_name="workspaces/internal/projects/proj-o97H2oAE/datasets/ds-tQLjA9NM/versions/1",
+        eval_dataset_name="workspaces/internal/projects/proj-o97H2oAE/datasets/ds-tQLjA9NM/versions/1",
+        train_model_name="workspaces/internal/modelstores/ms-6TDGY7Hv/models/ocrnet-model",
+        train_model_display_name="ocrnet",
+        transform_model_name="workspaces/internal/modelstores/ms-6TDGY7Hv/models/ocrnet-t4",
+        transform_model_display_name="ocrnet-t4",
+        ensemble_model_name="workspaces/internal/modelstores/ms-6TDGY7Hv/models/ocrnet-ensemble",
+        ensemble_model_display_name="ocrnet-ensemble"
+    )
+    pipeline_client.compile(save_path="../../../ocrnet_pipeline.yaml")
     _, run_id = pipeline_client.run(fs_name="vistudio")
```

## Comparing `gaea_operator-4.1.2.dev1.data/data/yaml/deploy_parameter.yaml` & `gaea_operator-4.1.2.dev4.data/data/yaml/deploy_parameter.yaml`

 * *Files identical despite different names*

## Comparing `gaea_operator-4.1.2.dev1.data/data/yaml/object_detection.yaml` & `gaea_operator-4.1.2.dev4.data/data/yaml/object_detection.yaml`

 * *Files identical despite different names*

## Comparing `gaea_operator-4.1.2.dev1.data/data/yaml/parameter.yaml` & `gaea_operator-4.1.2.dev4.data/data/yaml/parameter.yaml`

 * *Files identical despite different names*

## Comparing `gaea_operator-4.1.2.dev1.data/data/yaml/pipeline.yaml` & `gaea_operator/pipelines/change_ocrnet_pipeline/pipeline.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -6,18 +6,18 @@
     artifacts:
       input:
         input_model_uri: '{{train.output_model_uri}}'
       output:
       - output_dataset_uri
       - output_uri
     command: package_path=$(python3 -c "import site; print(site.getsitepackages()[0])")
-      && python3 -m gaea_operator.components.eval.resnet --input-model-uri={{input_model_uri}}
-      --output-uri={{output_uri}} --output-dataset-uri={{output_dataset_uri}} --log_dir={{output_uri}}
-      $package_path/paddleclas/tools/eval.py -c {{input_model_uri}}/train_config.yaml
-      -o Global.pretrained_model={{input_model_uri}}/best_model
+      && python3 -m gaea_operator.components.eval.ocrnet --input-model-uri={{input_model_uri}}
+      --output-uri={{output_uri}} --output-dataset-uri={{output_dataset_uri}} $package_path/paddleseg/tools/val.py
+      --config {{input_model_uri}}/train_config.yaml --model_path={{input_model_uri}}/best_model.pdparams
+      --save_dir={{output_uri}}
     deps: train
     docker_env: iregistry.baidu-int.com/windmill-public/train/paddlepaddle:v1.2.0
     env:
       DATASET_NAME: '{{dataset_name}}'
       EXPERIMENT_KIND: '{{experiment_kind}}'
       EXPERIMENT_NAME: '{{experiment_name}}'
       PF_JOB_FLAVOUR: '{{flavour}}'
@@ -27,15 +27,15 @@
       WINDMILL_AK: '{{windmill_ak}}'
       WINDMILL_ENDPOINT: '{{windmill_endpoint}}'
       WINDMILL_SK: '{{windmill_sk}}'
     parameters:
       dataset_name: ''
       experiment_kind: ''
       experiment_name: ''
-      flavour: c4m16gpu1
+      flavour: c8m32gpu1
       model_store_name: ''
       project_name: ''
       queue: qtrain
       tracking_uri: ''
       windmill_ak: ''
       windmill_endpoint: ''
       windmill_sk: ''
@@ -82,15 +82,15 @@
   package:
     artifacts:
       input:
         input_model_uri: '{{transform.output_model_uri}}'
       output:
       - output_model_uri
       - output_uri
-    command: python3 -m gaea_operator.components.package.package --algorithm=resnet
+    command: python3 -m gaea_operator.components.package.package --algorithm=ocrnet
       --input-model-uri={{input_model_uri}} --output-uri={{output_uri}} --output-model-uri={{output_model_uri}}
     deps: transform,transform-eval
     docker_env: iregistry.baidu-int.com/windmill-public/inference/nvidia:v1.2.0
     env:
       ACCELERATOR: '{{accelerator}}'
       ENSEMBLE_MODEL_DISPLAY_NAME: '{{ensemble_model_display_name}}'
       ENSEMBLE_MODEL_NAME: '{{ensemble_model_name}}'
@@ -124,22 +124,20 @@
     type: step
   train:
     artifacts:
       output:
       - output_model_uri
       - output_uri
     command: package_path=$(python3 -c "import site; print(site.getsitepackages()[0])")
-      && python3 -m gaea_operator.components.train.resnet --output-model-uri={{output_model_uri}}
-      --output-uri={{output_uri}} --log_dir={{output_uri}} $package_path/paddleclas/tools/train.py
-      -c {{output_model_uri}}/train_config.yaml -o Global.output_dir={{output_model_uri}}
+      && python3 -m gaea_operator.components.train.ocrnet --output-model-uri={{output_model_uri}}
+      --output-uri={{output_uri}} --log_dir={{output_uri}} $package_path/paddleseg/tools/train.py
+      --config {{output_model_uri}}/train_config.yaml --do_eval --save_dir={{output_model_uri}}
     docker_env: iregistry.baidu-int.com/windmill-public/train/paddlepaddle:v1.2.0
     env:
       ADVANCED_PARAMETERS: '{{advanced_parameters}}'
-      BASE_TRAIN_DATASET_NAME: '{{base_train_dataset_name}}'
-      BASE_VAL_DATASET_NAME: '{{base_val_dataset_name}}'
       EXPERIMENT_KIND: '{{experiment_kind}}'
       EXPERIMENT_NAME: '{{experiment_name}}'
       MODEL_DISPLAY_NAME: '{{model_display_name}}'
       MODEL_NAME: '{{model_name}}'
       PF_EXTRA_WORK_DIR: /home/paddleflow/storage/mnt/fs-root-vistudio
       PF_JOB_FLAVOUR: '{{flavour}}'
       PF_JOB_QUEUE_NAME: '{{queue}}'
@@ -151,20 +149,18 @@
       WINDMILL_ENDPOINT: '{{windmill_endpoint}}'
       WINDMILL_SK: '{{windmill_sk}}'
     extra_fs:
     - mount_path: /home/paddleflow/storage/mnt/fs-root-vistudio
       name: vistudio
       read_only: false
     parameters:
-      advanced_parameters: '{"Global.epochs":"1","Optimizer.lr.learning_rate":"0.001","DataLoader.Train.loader.num_workers":"2","eval_height":"224","eval_width":"224","DataLoader.Train.sampler.batch_size":"8","model_type":"resnet"}'
-      base_train_dataset_name: ''
-      base_val_dataset_name: ''
+      advanced_parameters: '{"iters":"100","lr_scheduler.learning_rate":"0.001","eval_height":"512","eval_width":"512","batch_size":"6","model_type":"ocrnet"}'
       experiment_kind: ''
       experiment_name: ''
-      flavour: c4m16gpu1
+      flavour: c8m32gpu1
       model_display_name: ''
       model_name: ''
       model_store_name: ''
       project_name: ''
       queue: qtrain
       tracking_uri: ''
       train_dataset_name: ''
@@ -176,38 +172,39 @@
   transform:
     artifacts:
       input:
         input_model_uri: '{{train.output_model_uri}}'
       output:
       - output_model_uri
       - output_uri
-    command: python3 -m gaea_operator.components.transform.resnet --input-model-uri={{input_model_uri}}
+    command: python3 -m gaea_operator.components.transform.ocrnet --input-model-uri={{input_model_uri}}
       --output-uri={{output_uri}} --output-model-uri={{output_model_uri}}
     deps: eval,train
     docker_env: iregistry.baidu-int.com/windmill-public/transform:v1.2.0
     env:
       ACCELERATOR: '{{accelerator}}'
-      ADVANCED_PARAMETERS: '{{advanced_parameters}}'
+      ADVANCED_PARAMETERS: '{{advanced_parameters1}}'
       EXPERIMENT_KIND: '{{experiment_kind}}'
       EXPERIMENT_NAME: '{{experiment_name}}'
       PF_JOB_FLAVOUR: '{{flavour}}'
       PF_JOB_QUEUE_NAME: '{{queue}}'
       PROJECT_NAME: '{{project_name}}'
       TRACKING_URI: '{{tracking_uri}}'
       TRANSFORM_MODEL_DISPLAY_NAME: '{{transform_model_display_name}}'
       TRANSFORM_MODEL_NAME: '{{transform_model_name}}'
       WINDMILL_AK: '{{windmill_ak}}'
       WINDMILL_ENDPOINT: '{{windmill_endpoint}}'
       WINDMILL_SK: '{{windmill_sk}}'
     parameters:
       accelerator: T4
-      advanced_parameters: '{"max_batch_size":"4","precision":"fp16","eval_height":"512","eval_width":"512","source_framework":"paddle","model_type":"resnet"}'
+      advanced_parameters: '{"max_batch_size":"1","precision":"fp16","eval_height":"512","eval_width":"512","source_framework":"paddle","model_type":"ocrnet"}'
+      advanced_parameters1: '{"max_batch_size":"1","precision":"fp16","eval_height":"512","eval_width":"512","source_framework":"paddle","model_type":"ocrnet"}'
       experiment_kind: ''
       experiment_name: ''
-      flavour: c4m16gpu1
+      flavour: c8m32gpu1
       model_store_name: ''
       project_name: ''
       queue: qtrain
       tracking_uri: ''
       transform_model_display_name: ''
       transform_model_name: ''
       windmill_ak: ''
@@ -217,15 +214,15 @@
   transform-eval:
     artifacts:
       input:
         input_dataset_uri: '{{eval.output_dataset_uri}}'
         input_model_uri: '{{transform.output_model_uri}}'
       output:
       - output_uri
-    command: python3 -m gaea_operator.components.transform_eval.transform_eval --algorithm=resnet
+    command: python3 -m gaea_operator.components.transform_eval.transform_eval --algorithm=ocrnet
       --input-model-uri={{input_model_uri}} --input-dataset-uri={{input_dataset_uri}}
       --output-uri={{output_uri}}
     deps: eval,transform
     docker_env: iregistry.baidu-int.com/windmill-public/inference/nvidia:v1.2.0
     env:
       ACCELERATOR: '{{accelerator}}'
       ADVANCED_PARAMETERS: '{{advanced_parameters}}'
@@ -250,8 +247,8 @@
       project_name: ''
       queue: qtrain
       tracking_uri: ''
       windmill_ak: ''
       windmill_endpoint: ''
       windmill_sk: ''
     type: step
-name: resnet
+name: ocrnet
```

## Comparing `gaea_operator-4.1.2.dev1.data/data/yaml/transform_parameter.yaml` & `gaea_operator-4.1.2.dev4.data/data/yaml/transform_parameter.yaml`

 * *Files identical despite different names*

## Comparing `gaea_operator-4.1.2.dev1.dist-info/METADATA` & `gaea_operator-4.1.2.dev4.dist-info/METADATA`

 * *Files 11% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: gaea-operator
-Version: 4.1.2.dev1
+Version: 4.1.2.dev4
 Summary: A common operator library to help with training neural networks.
 Home-page: https://console.cloud.baidu-int.com/devops/icode/repos/baidu/mlops/gaea-operator/tree/master
 Author: liuyawen03
 Author-email: liuyawen03@baidu.com
 License: MIT
 Classifier: Programming Language :: Python
 Classifier: Programming Language :: Python :: 3
@@ -24,26 +24,37 @@
 Requires-Dist: opt-einsum
 Requires-Dist: protobuf
 Requires-Dist: PyYAML
 Requires-Dist: six
 Requires-Dist: urllib3
 Requires-Dist: pycocotools
 Requires-Dist: jsonargparse
-Requires-Dist: pywindmill
-Requires-Dist: bcelogger
-Requires-Dist: gaea-tracker
+Requires-Dist: pywindmill (==1.0.0.2)
+Requires-Dist: bcelogger (==1.2.0.4)
+Requires-Dist: gaea-tracker (==1.2.0.8)
 
 # 可迭代算法描述
-|        algorithm        |           描述            | 说明             |
-|:-----------------------:|:-----------------------:|----------------|
-|      ppyoloe_plus       |  paddledet-2.5检测模型迭代产线  |                |
-|   change_ppyoloe_plus   | paddledet-2.5变化检测模型迭代产线 |                |
-|         resnet          | paddleclas-2.5分类模型迭代产线  |  |
-|         ocrnet          | paddleseg-2.2语义分割模型迭代产线 |                |
-|         codetr          |    mmdet3.0检测大模型迭代产线    |                |
+|        algorithm        |            描述             | 说明             |
+|:-----------------------:|:-------------------------:|----------------|
+|    PPYOLOEPLUS/Model    |   paddledet-2.5检测模型迭代产线   |                |
+| ChangePPYOLOEPLUS/Model |  paddledet-2.5变化检测模型迭代产线  |                |
+|      ResNet/Model       |  paddleclas-2.5分类模型迭代产线   |  |
+|      OCRNet/Model       |  paddleseg-2.2语义分割模型迭代产线  |                |
+|            ChangeOCRNet/Model             | paddleseg-2.2变化语义分割模型迭代产线 |                |
+
+# 可选择accelerator
+| accelerator |        描述         | 说明             |
+|:-----------:|:-----------------:|----------------|
+|    A100     | 适用于Nvidia A100服务器 |                |
+|    V100     | 适用于Nvidia V100服务器 |                |
+|     T4      |  适用于Nvidia T4服务器  |  |
+|     A10     | 适用于Nvidia A10服务器  |                |
+|    R200     | 适用于Kunlun R200服务器 |                |
+|    K200     | 适用于Kunlun K200服务器 |                |
+
 Changelog
 ===
 以下记录了项目中所有值得关注的变更内容，其格式基于[Keep a Changelog]。
 
 本项目版本遵守[Semantic Versioning]和[PEP-440]。
 
 [Unreleased]
```

## Comparing `gaea_operator-4.1.2.dev1.dist-info/RECORD` & `gaea_operator-4.1.2.dev4.dist-info/RECORD`

 * *Files 9% similar despite different names*

```diff
@@ -1,68 +1,70 @@
 gaea_operator/__init__.py,sha256=ByRuPwRErAhcYsPdR2RnVWtm35lq8yW-pzKVQkMlzIU,131
 gaea_operator/components/__init__.py,sha256=ByRuPwRErAhcYsPdR2RnVWtm35lq8yW-pzKVQkMlzIU,131
 gaea_operator/components/eval/__init__.py,sha256=I_nhvM_IU3swPZsE4m9lKQj50PABhRHZTVkiDjYZK5s,131
 gaea_operator/components/eval/codetr.py,sha256=GjstYt8BVRET_ZOmHoD9fWPYZd4zYDDIt0KVa1bclXc,4731
 gaea_operator/components/eval/convnext.py,sha256=-Zxd6Dj7I9DcluSePNW2k4b3j3NxH8ObiHqFec8q9YM,4600
 gaea_operator/components/eval/ocrnet.py,sha256=MO5F_bFFGFcYrZ2fG0eequzlTJxO_paPJCTh9gvjCpE,4169
-gaea_operator/components/eval/ppyoloe_plus.py,sha256=IXw89UF6Dp4gzAuhL0jHZZmmQGHFDpk_rhIyo7g9ygQ,4268
+gaea_operator/components/eval/ppyoloe_plus.py,sha256=3FaUBAhEvVSgyqjf7T_eX8r8jsoov6oLY9t0On8q49Q,4334
 gaea_operator/components/eval/repvit.py,sha256=FLbvMLJxRx21yu7DWA532viKpl9y-NtQEu24BVfKiqQ,4592
 gaea_operator/components/eval/resnet.py,sha256=ZxVF6RtFbqOEL0sM1sIMFOCbTIRZD3FQm2k43otT2ak,4153
 gaea_operator/components/icafe/__init__.py,sha256=HEYq40c6iefC_2910K0n1Bx39n8BOp5JMN-SjftTaIM,206
 gaea_operator/components/icafe/icafe.py,sha256=B3d4zlS2LE4pjKPBFBnveFsTxzarKsYZYRxlX0ukUNU,3738
 gaea_operator/components/inference/__init__.py,sha256=2aksz2GZp7BM51TKl-8KpAWpZoSSSMzEqOtSls7bd-E,3102
 gaea_operator/components/inference/inference.py,sha256=lwQV4nW-M9AD9quwlrVYoYk7towBR70erxv1xrMIVRE,4357
 gaea_operator/components/package/__init__.py,sha256=KxEJhC3kcIqj6Q7G_BCGCudrVvVkDnrRkkoJCXM6-Q8,3550
-gaea_operator/components/package/package.py,sha256=rnzZbpfzEANTZmetsGP89V70yoO14u26Z3Dr-PqTuEA,8422
+gaea_operator/components/package/package.py,sha256=IYaBP9JRZJY_G0ahTAGBkrs83ZsAaJC020YR91BT1Ts,8716
 gaea_operator/components/train/__init__.py,sha256=I_nhvM_IU3swPZsE4m9lKQj50PABhRHZTVkiDjYZK5s,131
-gaea_operator/components/train/codetr.py,sha256=jARDcx2O5xwRhy5MrTsKnf0Jb4zEu5Vr0xeViQodml4,8618
+gaea_operator/components/train/change_ppyoloe_plus.py,sha256=9a3bdDo-w9zpghf5QmGIzneCNjS80GOzlCqOS92hcSA,9635
+gaea_operator/components/train/codetr.py,sha256=M_8ykpK_TCOsMmY-7UtswDb3327qjczmSWksMYgGBO8,8678
 gaea_operator/components/train/convnext.py,sha256=Qk5WPgxOAk6MJt1o8VTM2coNGtk8fuY1guHp6RUYe6w,8334
-gaea_operator/components/train/ocrnet.py,sha256=N3JcXdhCaWuO1PDCXgA_8dyA04LBeFDrez3Y9spujkM,7519
-gaea_operator/components/train/ppyoloe_plus.py,sha256=pJ7XuhRhpYQnL1IRkwzxrtWYI8-EgS8LnwZY6a9w0XU,8365
+gaea_operator/components/train/ocrnet.py,sha256=dt6h9USRbFAzDrn5w6r_AWasMeCEN33V3qcYlObmLhM,8919
+gaea_operator/components/train/ppyoloe_plus.py,sha256=CvFdQQ3OeK6rqf-5a3T4J1iowdRv_EiljlD9gK9eJ9g,9437
 gaea_operator/components/train/repvit.py,sha256=bESnKn-qJP2QG4ohtmOVPgFihl2eNEwN3lH4HE8DQds,8324
-gaea_operator/components/train/resnet.py,sha256=1AsZtSTZyCA965Dasw9Ti9VHK_55mO1BRSyBE7MAHNc,7390
+gaea_operator/components/train/resnet.py,sha256=8flVOi2b6XhGHEvaqp24_jg58xmNwk7kIeSsbcau-0w,8629
 gaea_operator/components/transform/__init__.py,sha256=I_nhvM_IU3swPZsE4m9lKQj50PABhRHZTVkiDjYZK5s,131
-gaea_operator/components/transform/change_ppyoloe_plus.py,sha256=MdQC7cNNca-cAGdHTewKU9pCodXaEerMflPp4dq4anU,6125
-gaea_operator/components/transform/codetr.py,sha256=SIsNh2TPVSjdppngl8w4rI3AnLbxQQZMWpPGTx3ZBNE,6209
-gaea_operator/components/transform/convnext.py,sha256=mttAxUwoak_NFBaaCjq3d1Sodqk0-fKKVqlAI8sZZzw,6150
-gaea_operator/components/transform/ocrnet.py,sha256=i75STCEued24oL7F0SmEbMBK7ESFry1eRIBMMupsUzc,6236
-gaea_operator/components/transform/ppyoloe_plus.py,sha256=WzwLtmTyvhd6iINlmXoh1zEX20RQahB2v9qZT3PsmU0,6078
-gaea_operator/components/transform/repvit.py,sha256=nwn8eV71_AfY-RnVcQ-XZdy-okkXsz00dxrjDOnnK2c,6141
-gaea_operator/components/transform/resnet.py,sha256=-FHg9_M5Sdt46U6HxfjSqHOUFA8jc6c0O6qgg7fk7aM,6214
+gaea_operator/components/transform/change_ocrnet.py,sha256=wSIiL_DxTab01wdZtYRBPfVfjDIsUjJJ4dg7nku0dck,6499
+gaea_operator/components/transform/change_ppyoloe_plus.py,sha256=XgL8b1TMbWSojumrsAZtXjgBuJWXu-ZDryUYyDZJ5lM,6394
+gaea_operator/components/transform/codetr.py,sha256=3fAnePrX1SSes8MM9ZKIDk72Ri9rEP2owXa2sYMeINU,6209
+gaea_operator/components/transform/convnext.py,sha256=o3VPiibO1rD7hlhJblpEwmjqOXcNDrqyN01V_uB1FmY,6150
+gaea_operator/components/transform/ocrnet.py,sha256=66BoSif5QX0Y6bS-34SiNcRN1HQ6EhEGcPiW6ZOK1bI,6462
+gaea_operator/components/transform/ppyoloe_plus.py,sha256=frVFeC_EW6pfvHhWi6LG12l3dgtTAe9gosFkvTKAOsQ,6357
+gaea_operator/components/transform/repvit.py,sha256=r-8xqsRLqP3LRC37I52ZptRdV2A1rDiIK-DmNL9BgSM,6141
+gaea_operator/components/transform/resnet.py,sha256=gbhFP0_I66DfrBeusFPgazFKpeC0xn8qd59HFerNnJw,6493
 gaea_operator/components/transform_eval/__init__.py,sha256=VV2mbByhDQmiNkRPPQf8EgLqbTSXvwAJUqUylJT01tQ,3557
-gaea_operator/components/transform_eval/transform_eval.py,sha256=aaxyrom38RccFE8B7gNgxEs9E-bBUrFUH6dw2PpOBK4,8001
+gaea_operator/components/transform_eval/transform_eval.py,sha256=FT0khfNfSXiLNx25C8KqXFM6usAKG7IlZBuB8kjX1Zs,8763
 gaea_operator/config/__init__.py,sha256=PLdD6OqfwgP3svbwIFkl4ERWrfMWPAigCXbkfl7RVWM,774
-gaea_operator/config/config.py,sha256=bVLmNPzB-xMJPupe_I97tAhSiL9NPSwj5dKN1pWC99A,4964
-gaea_operator/config/generate_transform_config.py,sha256=V6SuLtSrR28eriHvho3kKWrPJoR_8thm-6Ekp_hHHEg,14999
-gaea_operator/config/modify_package_files.py,sha256=iZAmxnNPdH0cHuEFJUTnzf0rM54rPFfyI7ZDJaUe1zU,14835
+gaea_operator/config/config.py,sha256=d2n78rAUIZtVJkfV8OPadDwnvx0FvCFNHYk9ZiNKFZ4,5057
+gaea_operator/config/generate_transform_config.py,sha256=7TIqSoY_NJToPD5wU4EanPCaFT4FOVYEEtyl52zYn08,16189
+gaea_operator/config/modify_package_files.py,sha256=PzJXYtgywmcUsa2sK1gqDhadciJWzCdnCmKDZkI19Bs,18345
 gaea_operator/config/update_parse.py,sha256=JrqELK2dgIWCrtVz8gI6A6rH_5QbqZOHDNCDujnMqxs,3642
 gaea_operator/config/update_pbtxt.py,sha256=w3A5CRbnK1B4vKyUA8Qk2EDWLAqatM3ZkOw9Jxj1v9Q,16721
 gaea_operator/config/codetr/__init__.py,sha256=qIyiMMEuckOcc1g1DuA94Pa6HIwl9HHRcHbWtVeHPXc,130
-gaea_operator/config/codetr/codetr_config.py,sha256=TOhEquRjxbne_mqIBVJAQxxWeRK80OzHoY6a56qu6CA,5343
+gaea_operator/config/codetr/codetr_config.py,sha256=VEswLZcSYhjy2LE-MNs2pHo-t63uVmhuI5jhWPmHkgM,5339
 gaea_operator/config/codetr/template/__init__.py,sha256=qIyiMMEuckOcc1g1DuA94Pa6HIwl9HHRcHbWtVeHPXc,130
 gaea_operator/config/codetr/template/deploy_parameter.yaml,sha256=9HpozKsKup6_yGb_Snwbq03FB7uIIKi1A6JWd4VZJDg,590
-gaea_operator/config/codetr/template/modify_parameter.py,sha256=C462ayX23C-oe-O6ivJEthGiK5DNsssi1LOC6IRbJt0,14288
+gaea_operator/config/codetr/template/modify_parameter.py,sha256=yjms-rPxlGcb4qAvU4fQSgSZgqDxOu9kOB2G82UpUWU,14221
 gaea_operator/config/codetr/template/train_parameter.yaml,sha256=lrkuDhNQYGv5OvlnRlWRHd2aL8zm9x1fzU6b97-oZzY,13839
 gaea_operator/config/convnext/__init__.py,sha256=qIyiMMEuckOcc1g1DuA94Pa6HIwl9HHRcHbWtVeHPXc,130
 gaea_operator/config/convnext/convnext_config.py,sha256=-PzxxagxelwEK36fXN7CDxzVYS0K-hrnMJDAZdNsknM,4001
 gaea_operator/config/convnext/template/__init__.py,sha256=qIyiMMEuckOcc1g1DuA94Pa6HIwl9HHRcHbWtVeHPXc,130
 gaea_operator/config/convnext/template/modify_train_parameter.py,sha256=adHurePfkbyk8lW9csNWyIhFKu_F4ug4ykQll-XIzPo,4338
 gaea_operator/config/convnext/template/parameter.yaml,sha256=Piznlbuazf9MdH2hcm1kSEyaiPFC-BRu80vYAGzV2N0,1499
 gaea_operator/config/ocrnet/__init__.py,sha256=qIyiMMEuckOcc1g1DuA94Pa6HIwl9HHRcHbWtVeHPXc,130
-gaea_operator/config/ocrnet/ocrnet_config.py,sha256=FbS-W3ljAbE-ZRkBCONC5mSowk87QVOMxN9PUV6AAww,5599
+gaea_operator/config/ocrnet/ocrnet_config.py,sha256=1Sy1QqAGG4TWo-oGK5WKsyA4pk6E9ma8UxceD3PE3g4,5588
 gaea_operator/config/ocrnet/template/__init__.py,sha256=lX4deGvIgAQ1fTcskBUDqRfnOlOabgQjZXGwOJCVCkU,130
-gaea_operator/config/ocrnet/template/modify_train_parameter.py,sha256=p21spoGEwZHPfQL94HFAL5947UXU1OEQHQ2x_Z6J-xI,8809
+gaea_operator/config/ocrnet/template/modify_train_parameter.py,sha256=5o7XqnYCv7C6j4wJAbyzkLiH3J2z-Y_IP1y7OyPsKRU,9419
 gaea_operator/config/ocrnet/template/parameter.yaml,sha256=CbogpeuW_OZJLgF0AbxsFjFJzZ-_RF3s9NCnGojGB9o,1467
 gaea_operator/config/ocrnet/template/parameter_c.yaml,sha256=ixzpW0XOnZKonf3GNdqiIQabci-H0Ww7YF7IW4t973M,1656
 gaea_operator/config/ppyoloe_plus/__init__.py,sha256=qIyiMMEuckOcc1g1DuA94Pa6HIwl9HHRcHbWtVeHPXc,130
 gaea_operator/config/ppyoloe_plus/ppyoloeplus_config.py,sha256=t1jN8ti8hpMM-l1U2Ukl8AS8xZsyKQh2pE5wNE1ew2U,4058
 gaea_operator/config/ppyoloe_plus/template/__init__.py,sha256=lX4deGvIgAQ1fTcskBUDqRfnOlOabgQjZXGwOJCVCkU,130
 gaea_operator/config/ppyoloe_plus/template/modify_train_parameter.py,sha256=BePbG16yrxAJiwctUbc0s1VtKDDThsDtylndcIO8WPk,12621
-gaea_operator/config/ppyoloe_plus/template/parameter.yaml,sha256=cliceLv-V-sYmwEzbXyylbXR4MElQZQ9yrAmg6CIohM,4583
-gaea_operator/config/ppyoloe_plus/template/parameter_c.yaml,sha256=KVxZIotf24fk_SAI1v-CHNMC2ouG_lpMY0l_CtSXoRM,4666
+gaea_operator/config/ppyoloe_plus/template/parameter.yaml,sha256=Nm3cI5voKNPM7VbXrHF8p2c6cKkPiMZk8LzFuOWetwo,4583
+gaea_operator/config/ppyoloe_plus/template/parameter_c.yaml,sha256=ML3RGr_GYBoEWhUT4Jk483Iq5eVRh20Aki-9fS4YWWs,4665
 gaea_operator/config/repvit/__init__.py,sha256=qIyiMMEuckOcc1g1DuA94Pa6HIwl9HHRcHbWtVeHPXc,130
 gaea_operator/config/repvit/repvit_config.py,sha256=o2Tsk9WPvIdRkXHex25ufcdO5GkCyt_swnul38FCb18,620
 gaea_operator/config/resnet/__init__.py,sha256=qIyiMMEuckOcc1g1DuA94Pa6HIwl9HHRcHbWtVeHPXc,130
 gaea_operator/config/resnet/resnet_config.py,sha256=oJcrEEsIOe8waeijGNit9B215bNULXYw_xO9AIn6k9U,4283
 gaea_operator/config/resnet/template/__init__.py,sha256=qIyiMMEuckOcc1g1DuA94Pa6HIwl9HHRcHbWtVeHPXc,130
 gaea_operator/config/resnet/template/modify_train_parameter.py,sha256=TbSV1IvnYIDS2m1uixHbJst4rA4BzzynbprqaLcSrwA,11498
 gaea_operator/config/resnet/template/parameter.yaml,sha256=c1lyNOcU63Ekb1gW86ZiHfwIOnrGJhLqOiyXEsLq9yU,2315
@@ -71,15 +73,15 @@
 gaea_operator/dataset/coco_dataset.py,sha256=VN916DU9gERp8ZDjR7-fLItGVYDxpW38J2N_exOAqJk,6779
 gaea_operator/dataset/dataset.py,sha256=FEnDgbyS3bzx_XxLYnoEb-TXL3QB3NMNfbeByBhUmRA,7314
 gaea_operator/dataset/imagenet_dataset.py,sha256=xL35XeFBvZKrTRjmncUtKLTxFtbtfc5KFuMq4j701bg,4311
 gaea_operator/metric/__init__.py,sha256=fk0G_Cw3od-yzlYq5l48xDslTmqLFddrWoXOi3xqI48,584
 gaea_operator/metric/metric.py,sha256=p6KtrpC0muO0BPAdxePf3-17K5yRI6P5f9YhfncYhIo,5740
 gaea_operator/metric/analysis/__init__.py,sha256=kEv9_MuQOFC83fCprxY19T7omFNXa9dAuxstXlsEsX8,433
 gaea_operator/metric/analysis/eval_metric_analysis.py,sha256=r89em8EuokRW9mWJpRfDCWXrXTkz3jfP9AFlVeE1jFc,19213
-gaea_operator/metric/analysis/inference_metric_analysis.py,sha256=oxXltL3ySZHvT0Ay1LjSo0sgxJb0emjE-gq7ClaJxHI,7907
+gaea_operator/metric/analysis/inference_metric_analysis.py,sha256=WMWS26XBxtBEiGUhC4LVGlK_smKWPMlyOJ35CniuxYA,8002
 gaea_operator/metric/analysis/label_statistics_metric_analysis.py,sha256=93j10RML9xkGAu2fDQokIzl-0DYprLiVtnhdiThYRmQ,11706
 gaea_operator/metric/operator/__init__.py,sha256=Tz9wUArWR7NZvW1X9OwIGn7yTIELiwFFYszRXhQnAyY,792
 gaea_operator/metric/operator/check.py,sha256=CTaAvD4VDpllUp3d7_1HD-HP_b3beuh-HyMwM2V6u4o,3195
 gaea_operator/metric/operator/metric.py,sha256=ia3NY6twXmFgr_ULfaudIcbmIqyJJwC51pakJdpvRhc,1923
 gaea_operator/metric/operator/image/__init__.py,sha256=iw6-w66SbPp5uLPizSWLJU4qumZI3kKGR_GcVrWrHpc,779
 gaea_operator/metric/operator/image/accuracy.py,sha256=O-0m0zkPmlEzp4Hr3fI6oYmFdBvxtZoXP9Wfma4kgD8,6960
 gaea_operator/metric/operator/image/average_precision.py,sha256=WMZZk1de78k23OYZ8kDzV9ndCJwpysh3GNSmK4XZ9lc,2571
@@ -96,59 +98,70 @@
 gaea_operator/metric/types/__init__.py,sha256=x5whaLpvnYR6XL2VB8IbYJ12jtYW7_zUnWks_JZY1A8,131
 gaea_operator/metric/types/image_classification_metric.py,sha256=Q-XVRRogS43yhuN0MHQY6viu-k9_r6ADK_Df2tBjPkU,1173
 gaea_operator/metric/types/metric.py,sha256=H1KHU_Kf3yxXd4pvrxY2d75tBNkQ0vEQ526A6tg3AnI,4874
 gaea_operator/metric/types/object_detection_metric.py,sha256=fS5aJZ8lHxRAcs69bfgVlvRijsbAAjuWSg2ZtuVtKA0,2362
 gaea_operator/metric/types/semantic_segmentation_metric.py,sha256=RVOUp2x8QGKwf3EepvBR-yaLvEj0OF6uM0aC0Ah-ASQ,1244
 gaea_operator/model/__init__.py,sha256=EssP2HXBMWO-4iXPbWjscBrXxSojJBOOHV3p-ioV6tA,214
 gaea_operator/model/model.py,sha256=pNswhABsGB5HHeExA4fOHH4ob2uRPqs97sCzRGPQwIo,1436
-gaea_operator/pipelines/__init__.py,sha256=XUWBO-CQCQXxEjadslKp4U6-IKHvmXaiMTisWNABH2E,687
-gaea_operator/pipelines/create_ppl.py,sha256=E4hLrf0bEGfJB_DhDU9VW9Q2lsvx3y5Xb5smoHQkcnU,2173
-gaea_operator/pipelines/change_ppyoloe_plus_pipeline/train_parameter.yaml,sha256=sGgJrnUUmQjp7MH600lPqaaTZDOlKeiBuvFXX4w8iX4,1254
-gaea_operator/pipelines/change_ppyoloe_plus_pipeline/transform_parameter.yaml,sha256=cnuRAM2PKeDwl7GnNMpWSwmLx1D4Kmp_W3RA1_X7lq4,1744
+gaea_operator/pipelines/__init__.py,sha256=up1Z-Pjo7YNelnTctDU4L1gRohHbzyVM4HYkUCb98Wo,545
+gaea_operator/pipelines/create_ppl.py,sha256=YHPGD8AdWQ7TOCzQaA742xGfcq3-ht9v1DBawjwv68w,3132
+gaea_operator/pipelines/change_ocrnet_pipeline/__init__.py,sha256=L2s64dKZZVsGx5vKew7wn61rdsT_y7GkzPJaxCs1rmw,131
+gaea_operator/pipelines/change_ocrnet_pipeline/pipeline.py,sha256=xDWmzqwGoJ0NncAuO_XzDpgecSACCeyTy901jrFgnv0,11584
+gaea_operator/pipelines/change_ocrnet_pipeline/pipeline.yaml,sha256=d9IPkZVkmy7jcmmMlQEDYLzwsehLoqp4ZOboPcbD_sg,9743
+gaea_operator/pipelines/change_ocrnet_pipeline/train_parameter.yaml,sha256=-9TJKBJuH8fA-Ftb-zarkuixRYCaDRd7pog6SilDrWk,1051
+gaea_operator/pipelines/change_ocrnet_pipeline/transform_parameter.yaml,sha256=TdQFxYG4tE0TnasDO_4nfJji1pCbMxRu9j0WtkOrYp8,1119
+gaea_operator/pipelines/change_ppyoloe_plus_pipeline/__init__.py,sha256=L2s64dKZZVsGx5vKew7wn61rdsT_y7GkzPJaxCs1rmw,131
+gaea_operator/pipelines/change_ppyoloe_plus_pipeline/pipeline.py,sha256=OsX5YkhFLO7wGKBWNLYWbzSchK38fhCRAclEJifVH1k,22441
+gaea_operator/pipelines/change_ppyoloe_plus_pipeline/pipeline.yaml,sha256=_nkTdG45ZMXRWNjj6USVOrKODCSDAgL_mbnGgLWt-q4,11396
+gaea_operator/pipelines/change_ppyoloe_plus_pipeline/train_parameter.yaml,sha256=AnMG-6w1D8vAz9d2RqK7g2qV476xKlDdPfGG32AJMd4,1254
+gaea_operator/pipelines/change_ppyoloe_plus_pipeline/transform_parameter.yaml,sha256=GFxjmbu4fpd6EaiNjV5nROFyYqiipy1IAcwJm7by9VM,1744
 gaea_operator/pipelines/codetr_pipeline/__init__.py,sha256=Q2QSUUml_2Ck7Mz38ixvJxuItQXkzxhIP1ypfIndhuY,130
-gaea_operator/pipelines/codetr_pipeline/pipeline.py,sha256=lYw21XVCNOQsQLDKBo9mRPH7SyuuVPYkW5q5_npuxws,12171
+gaea_operator/pipelines/codetr_pipeline/pipeline.py,sha256=x6FCx_qUBkpB7varmlJyHeCEjKC0TX8cQUYqbsvjuUI,12194
 gaea_operator/pipelines/codetr_pipeline/train_parameter.yaml,sha256=LeD0Te1a0bFFlltQzrRXpt33TS_u4YCEtoChInBEvY0,1224
 gaea_operator/pipelines/codetr_pipeline/transform_parameter.yaml,sha256=fTG192Hi2A55p3CkZmt80ocAopSe1kG9q2CJrB5ftUA,1118
 gaea_operator/pipelines/convnext_pipeline/__init__.py,sha256=1lMjOt9_9c8pQcVCxYDTt5cq9bvl4jS1yrAjTvc5ZVI,131
 gaea_operator/pipelines/convnext_pipeline/convnext_pipeline.py,sha256=vZnS7rfDwd73EGaDx9-QyJNn1OE_bd1HCJs0rRw8jI0,11865
 gaea_operator/pipelines/convnext_pipeline/train_parameter.yaml,sha256=eQ3bLJ-p5frQJJY51IOBSFe-7cnhKJYsWLIwpf_hd2g,1474
 gaea_operator/pipelines/convnext_pipeline/transform_parameter.yaml,sha256=vLZ2kHIeJR7bfa9Qbel1DnNoAEOhSoaR2OMBamv59B4,1229
 gaea_operator/pipelines/ocrnet_pipeline/__init__.py,sha256=L2s64dKZZVsGx5vKew7wn61rdsT_y7GkzPJaxCs1rmw,131
-gaea_operator/pipelines/ocrnet_pipeline/ocrnet_pipeline.py,sha256=cpxfX6VLc3MSnE4gfZmqPJArdnMhakMhhPHujZB6fBo,12008
+gaea_operator/pipelines/ocrnet_pipeline/pipeline.py,sha256=aLnCDsz2kTEuXsQNRENbmW2GmbFndqPrwd9goYUb6dI,11570
 gaea_operator/pipelines/ocrnet_pipeline/pipeline.yaml,sha256=d9IPkZVkmy7jcmmMlQEDYLzwsehLoqp4ZOboPcbD_sg,9743
 gaea_operator/pipelines/ocrnet_pipeline/train_parameter.yaml,sha256=-9TJKBJuH8fA-Ftb-zarkuixRYCaDRd7pog6SilDrWk,1051
 gaea_operator/pipelines/ocrnet_pipeline/transform_parameter.yaml,sha256=TdQFxYG4tE0TnasDO_4nfJji1pCbMxRu9j0WtkOrYp8,1119
+gaea_operator/pipelines/ppyoloe_plus_pipeline/__init__.py,sha256=L2s64dKZZVsGx5vKew7wn61rdsT_y7GkzPJaxCs1rmw,131
+gaea_operator/pipelines/ppyoloe_plus_pipeline/pipeline.py,sha256=vdg2JrlHNEW0LmA8Ud0YF156Ppp6oTcujTcTxPPZlSk,22347
+gaea_operator/pipelines/ppyoloe_plus_pipeline/pipeline.yaml,sha256=_nkTdG45ZMXRWNjj6USVOrKODCSDAgL_mbnGgLWt-q4,11396
 gaea_operator/pipelines/ppyoloe_plus_pipeline/train_parameter.yaml,sha256=ECBrWkFnrwW5yLFNpXR0gE77eKqqW9YmKy7mewspMzA,1226
 gaea_operator/pipelines/ppyoloe_plus_pipeline/transform_parameter.yaml,sha256=iDMweH0uIMvN8IqSJEJfXzbH-Oo98LPA0KRJs-4c_rs,1716
 gaea_operator/pipelines/repvit_pipeline/train_parameter.yaml,sha256=W9GnX5ddbWQktpRDV8TC2SpvFPVyKgT0qh1ikvaxOfQ,1461
 gaea_operator/pipelines/repvit_pipeline/transform_parameter.yaml,sha256=538nOckpOAr5wQ5zJ5IvfeanP6TIpmVvPKw0chlhNGQ,1212
 gaea_operator/pipelines/resnet_pipeline/__init__.py,sha256=L2s64dKZZVsGx5vKew7wn61rdsT_y7GkzPJaxCs1rmw,131
+gaea_operator/pipelines/resnet_pipeline/pipeline.py,sha256=r4eibkHFdXbhHcZIDwooshF73yLk-ZN4LpfNR3MoubA,12172
 gaea_operator/pipelines/resnet_pipeline/pipeline.yaml,sha256=vh8zW9w392AAJ9leeqWhjnTFPn_DXQ8jST9eWCV7lhM,9833
-gaea_operator/pipelines/resnet_pipeline/resnet_pipeline.py,sha256=CFLBY_PY1LKVzWnPwq-Un-L-D1rYwmRGpkkF-nNLurw,12187
 gaea_operator/pipelines/resnet_pipeline/train_parameter.yaml,sha256=kVRkIx_DvDle-02D3YoWpVhJ8rkbXOiuBWSCF-YDCfY,1271
 gaea_operator/pipelines/resnet_pipeline/transform_parameter.yaml,sha256=luJ-ZjerE13jXu4e7igHrrtR8_k8UYSCTxiyQbS7VhE,1121
 gaea_operator/trainer/__init__.py,sha256=Kpisv4LZyJQy6vEce-8g3HS8bo8y6rwk8K3pEaF0na0,181
-gaea_operator/trainer/trainer.py,sha256=MkEwTykpnDCgxUZXez0VhqYMfAgtwoyS1gX_ftKcn1Y,6818
+gaea_operator/trainer/trainer.py,sha256=J4jGoNL9MmUwYUXZomuihdXAaLDxx9vQ30THM9yYhl8,6988
 gaea_operator/transform/__init__.py,sha256=1NtMabt2_F9fVeLuAM7g3i0yIac_4RP0lHMZzdyDDcY,187
 gaea_operator/transform/cvt_copy_model.py,sha256=jSWWgt2RT9ULPLNyOxypmpNuQ1kWH0gw2XNe6OLE7Sw,3307
 gaea_operator/transform/transform.py,sha256=kDZ4m4QUPbuDYSwT6lKFH7T0GEADNL3f6T-L4IUjG0g,776
-gaea_operator/utils/__init__.py,sha256=YFAZ8ewHiTdbgFTPhapJPxvpnHG8JrznTSTSvTKVW8w,2004
-gaea_operator/utils/accelerator.py,sha256=pSxy9v9IS1xWQ_utJWQ4ljX80-rrRxnHoSBFmDZLAuY,5557
+gaea_operator/utils/__init__.py,sha256=fmK0yF7GQ4eiabYwmpDYLlCiap6rNWyxCG33N1JQR4E,1951
+gaea_operator/utils/accelerator.py,sha256=cgmZzuSxLsKlE7225cvmpfQHPO8Fy3VdYi1k2RnUoIg,6183
 gaea_operator/utils/compress.py,sha256=rnM_Wv_UrP9LB30xeu6f5Zch3QFH-pHGcReC8PTYjZk,2887
 gaea_operator/utils/consts.py,sha256=qP2cVRQ9oDS946cpFBx75DXGzRDsoB9ZRHBkn45WIPw,532
 gaea_operator/utils/file.py,sha256=vwWaBAo9FVDbcEQUxiHwIDgvKEg-r5IoQLeSV-hPkY0,2114
 gaea_operator/utils/import_module.py,sha256=W1mKFqBClRsYm9MNqParN-03PUFIwgMJJAgSAvD9m38,1533
-gaea_operator/utils/model_template.py,sha256=pjWyt1ZgpyfYKcCuh8pbg1NLoh6c6FQdLKUOGSeF6wA,11768
+gaea_operator/utils/model_template.py,sha256=hCRWpS-pchPl3EZfo7T5UgbFaJT-VT34bH_C6CVDJ0s,7440
 gaea_operator/utils/registry.py,sha256=QchfsCrwhk3i8gmtS16PAF4029TcdOdEeWUdo1ruAps,1680
 gaea_operator/utils/tensor.py,sha256=BLnnyKz79hOqZy-L7IeA4ffDX5DoWP9NvLzStdI6C8w,1000
 gaea_operator/utils/time.py,sha256=xNKc-rzCCwhh-hNlNO05J_TA6rCMKMepuZ3qzvcScLs,301
-gaea_operator-4.1.2.dev1.data/data/yaml/deploy_parameter.yaml,sha256=9HpozKsKup6_yGb_Snwbq03FB7uIIKi1A6JWd4VZJDg,590
-gaea_operator-4.1.2.dev1.data/data/yaml/object_detection.yaml,sha256=2V6AJBVa1nAE9FAosyz4z4Qv0ebw1IumYoRPUWo3Ebg,4864
-gaea_operator-4.1.2.dev1.data/data/yaml/parameter.yaml,sha256=Piznlbuazf9MdH2hcm1kSEyaiPFC-BRu80vYAGzV2N0,1499
-gaea_operator-4.1.2.dev1.data/data/yaml/parameter_c.yaml,sha256=ixzpW0XOnZKonf3GNdqiIQabci-H0Ww7YF7IW4t973M,1656
-gaea_operator-4.1.2.dev1.data/data/yaml/pipeline.yaml,sha256=vh8zW9w392AAJ9leeqWhjnTFPn_DXQ8jST9eWCV7lhM,9833
-gaea_operator-4.1.2.dev1.data/data/yaml/train_parameter.yaml,sha256=lrkuDhNQYGv5OvlnRlWRHd2aL8zm9x1fzU6b97-oZzY,13839
-gaea_operator-4.1.2.dev1.data/data/yaml/transform_parameter.yaml,sha256=538nOckpOAr5wQ5zJ5IvfeanP6TIpmVvPKw0chlhNGQ,1212
-gaea_operator-4.1.2.dev1.dist-info/METADATA,sha256=BXoV6gpbUXNHG_ZmbJdP4bMlILGMvVb57hsyhP1aYjI,2244
-gaea_operator-4.1.2.dev1.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
-gaea_operator-4.1.2.dev1.dist-info/top_level.txt,sha256=1-ONMzqexKnQ2qOurelrROodwfO1B8jTzpzbERvNycY,14
-gaea_operator-4.1.2.dev1.dist-info/RECORD,,
+gaea_operator-4.1.2.dev4.data/data/yaml/deploy_parameter.yaml,sha256=9HpozKsKup6_yGb_Snwbq03FB7uIIKi1A6JWd4VZJDg,590
+gaea_operator-4.1.2.dev4.data/data/yaml/object_detection.yaml,sha256=2V6AJBVa1nAE9FAosyz4z4Qv0ebw1IumYoRPUWo3Ebg,4864
+gaea_operator-4.1.2.dev4.data/data/yaml/parameter.yaml,sha256=Piznlbuazf9MdH2hcm1kSEyaiPFC-BRu80vYAGzV2N0,1499
+gaea_operator-4.1.2.dev4.data/data/yaml/parameter_c.yaml,sha256=ML3RGr_GYBoEWhUT4Jk483Iq5eVRh20Aki-9fS4YWWs,4665
+gaea_operator-4.1.2.dev4.data/data/yaml/pipeline.yaml,sha256=d9IPkZVkmy7jcmmMlQEDYLzwsehLoqp4ZOboPcbD_sg,9743
+gaea_operator-4.1.2.dev4.data/data/yaml/train_parameter.yaml,sha256=AnMG-6w1D8vAz9d2RqK7g2qV476xKlDdPfGG32AJMd4,1254
+gaea_operator-4.1.2.dev4.data/data/yaml/transform_parameter.yaml,sha256=538nOckpOAr5wQ5zJ5IvfeanP6TIpmVvPKw0chlhNGQ,1212
+gaea_operator-4.1.2.dev4.dist-info/METADATA,sha256=qee0R_0XWTwQ-tUbFXcXcOL9uEgtdetI3WGDCJm8GKM,2833
+gaea_operator-4.1.2.dev4.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
+gaea_operator-4.1.2.dev4.dist-info/top_level.txt,sha256=1-ONMzqexKnQ2qOurelrROodwfO1B8jTzpzbERvNycY,14
+gaea_operator-4.1.2.dev4.dist-info/RECORD,,
```

